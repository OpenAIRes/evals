{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a BATTLE Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = True\n",
    "initial_message = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "battles_generation = \"dense\"      # methods: dense, only-new\n",
    "roles = \"user\"             # methods: system-user, system, user\n",
    "few_shot_prompts = True\n",
    "\n",
    "#!cd evals\n",
    "#!git lfs fetch --all\n",
    "#!git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import yaml\n",
    "#import datetime\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "#api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n",
    "\n",
    "# Install Evals if you haven't already\n",
    "# %pip install -e ../.\n",
    "# pip install --upgrade openai\n",
    "# %pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths. Assuming this notebook is in examples/\n",
    "\n",
    "evals_path = os.path.join(os.getcwd(), \"..\", \"evals\")\n",
    "\n",
    "registry_path = os.path.join(evals_path, \"registry\", \"evals\", \"battles.yaml\")\n",
    "\n",
    "data_path = os.path.join(evals_path, \"registry\", \"data\", \"battles\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "data_path = os.path.join(data_path, \"samples.jsonl\")\n",
    "\n",
    "json_logs_path = os.path.join(os.getcwd(), \"logs\")\n",
    "os.makedirs(json_logs_path, exist_ok=True)\n",
    "json_logs_path = os.path.join(json_logs_path, \"logs\")\n",
    "\n",
    "df_path = os.path.join(evals_path, \"evallogs\", \"df\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "dataset_path = os.path.join(df_path, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registry yaml\n",
    "\n",
    "registry_yaml = {}\n",
    "\n",
    "registry_yaml[\"battles\"] = {\n",
    "    \"id\": \"battles.test.v1\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}\n",
    "registry_yaml[\"battles.test.v1\"] = {\n",
    "    \"class\": \"evals.elsuite.modelgraded.classify:ModelBasedClassify\",\n",
    "    \"args\": {\n",
    "        \"samples_jsonl\": \"battles/samples.jsonl\",\n",
    "        \"eval_type\": \"cot_classify\",\n",
    "        \"modelgraded_spec\": \"battle\"\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(registry_path), \"w\") as f:\n",
    "    yaml.dump(registry_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data\n",
    "if new:\n",
    "    dataset = ()\n",
    "    dataset = pd.DataFrame(dataset, columns=['Instruction1', 'Response1', 'Instruction2', 'Response2', 'Sampled',\n",
    "       'Choice', 'Data'])\n",
    "    best_message = initial_message\n",
    "    best_response = client.chat.completions.create(\n",
    "        messages = initial_message,\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        ).choices[0].message.content\n",
    "    few_shot_prompt = []\n",
    "else:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset = pd.read_json(f, lines=True)\n",
    "    if dataset.iloc[-1][\"Choice\"] == \"No\":\n",
    "        best_content = dataset.iloc[-1][\"Instruction2\"]\n",
    "        best_response = dataset.iloc[-1][\"Response2\"]\n",
    "    else:\n",
    "        best_content = dataset.iloc[-1][\"Instruction1\"]\n",
    "        best_response = dataset.iloc[-1][\"Response1\"]\n",
    "    best_message = [{\"role\": \"user\", \"content\": best_content}]\n",
    "candidate_messages = [best_message]\n",
    "next_candidate_messages = []\n",
    "generation_distance = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': ''}]"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user', 'content': ''}]]"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "def battle(best_message, best_response, candidate_message):\n",
    "\n",
    "    dataset = [{\"input1\": candidate_message, \"input2\": best_message, \"completion2\":best_response}]\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_json(data_path, orient=\"records\", lines=True)\n",
    "\n",
    "    !oaieval gpt-3.5-turbo battles --record_path logs/logs\n",
    "    \n",
    "    with open(json_logs_path, \"r\") as f:\n",
    "        df = pd.read_json(f, lines=True)\n",
    "\n",
    "    #current_time = datetime.datetime.now()\n",
    "    #formatted_time = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #df.to_json(os.path.join(df_path, formatted_time), lines=True, orient=\"records\")\n",
    "\n",
    "    instruction1 = candidate_message[-1][\"content\"]\n",
    "    instruction2 = best_message[-1][\"content\"]\n",
    "\n",
    "    battle_prompt_content = df[\"data\"].iloc[-2][\"prompt\"][0][\"content\"]\n",
    "    response1 = battle_prompt_content.split(\"\\n[Response 1]\\n\",)[1].split(\"\\n\\n[Instruction 2]\\n\")[0]\n",
    "    response1 = response1.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    response2 = battle_prompt_content.split(\"\\n[Response 2]\\n\",)[1].split(\"\\n\\n\\nIs the first response better than the second?\")[0]\n",
    "    response2 = response2.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    print(f\"Response1: {response1}\")\n",
    "    #print(f\"response2: {response2}\")\n",
    "\n",
    "    sampled = df[\"data\"].iloc[-2][\"sampled\"][0]\n",
    "\n",
    "    choice = df[\"data\"].iloc[-1][\"choice\"]\n",
    "\n",
    "    data = {'Instruction1': instruction1, 'Response1': response1, 'Instruction2': instruction2, 'Response2': response2, 'Sampled': sampled, 'Choice': choice, 'Data': {}}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = df.to_dict()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_system_and_user(message):\n",
    "    new_message = []\n",
    "    if message[0][\"role\"] == \"system\":\n",
    "        new_message.append([{\"role\": \"user\", \"content\": message[0][\"content\"]}])\n",
    "    else:\n",
    "        new_message.append([{\"role\": \"system\", \"content\": message[0][\"content\"]}])\n",
    "    return new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parents(content, dataset):\n",
    "    #print (f\"finding parents {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Response1\"] == content]\n",
    "    parents = dataset[\"Instruction1\"].unique()\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_children(content, dataset):\n",
    "    #print (f\"finding children {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Instruction1\"] == content]\n",
    "    children = dataset[\"Response1\"].unique()\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_candidate_messages(dataset, best_message, generation_distance, roles):\n",
    "    best_content = best_message[-1][\"content\"]\n",
    "    last = [best_content]\n",
    "    list_of_contents = [best_content]\n",
    "\n",
    "    next = []\n",
    "    for i in range(generation_distance):\n",
    "        #print (f\"starting level {i}, generation distance {generation_distance}\")\n",
    "        for content in last:\n",
    "            #print(f\"last_up: {last_up}, now {content}\")\n",
    "            next.extend(find_parents(content, dataset))\n",
    "            next.extend(find_children(content, dataset))\n",
    "            \n",
    "        #print (f\"behind for loops\")\n",
    "        list_of_contents.extend(next)\n",
    "        last = next.copy()\n",
    "        #print(f\"endind level {i}\")\n",
    "        \n",
    "    list_of_contents = pd.array(list_of_contents).unique().tolist()\n",
    "    \n",
    "    #best_message_index = list_of_contents.index(best_message[0][content])\n",
    "    #start = max(best_message_index - generation_distance, 0)\n",
    "    #stop = min(len(list_of_contents))\n",
    "    #stop = len(list_of_contents) - 1\n",
    "\n",
    "    messages = []\n",
    "    for content in list_of_contents:\n",
    "        if roles == \"system-user\" or \"user\":\n",
    "            messages.append([{\"role\":\"user\",\"content\":content}])\n",
    "        if (roles == \"system-user\") or (roles == \"system\"):\n",
    "            print(\"Creating message without user role.\")\n",
    "            messages.append([{\"role\":\"system\",\"content\":content}])\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-09 20:53:26,947] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 20:53:27,731] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 20:53:27,733] [oaieval.py:215] \u001b[1;35mRun started: 240809185327ICHJ7BOR\u001b[0m\n",
      "[2024-08-09 20:53:27,734] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 20:53:27,762] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 20:53:27,762] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 20:53:27,762] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 20:53:27,783] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "[2024-08-09 20:53:30,359] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 20:53:30,359] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 108\n",
      "prompt_tokens: 301\n",
      "total_tokens: 409\n",
      "[2024-08-09 20:53:30,360] [record.py:371] Final report: {'counts/Yes': 1, 'score': 1.0, 'usage_completion_tokens': 108, 'usage_prompt_tokens': 301, 'usage_total_tokens': 409}. Logged to logs/logs\n",
      "[2024-08-09 20:53:30,360] [oaieval.py:233] Final report:\n",
      "[2024-08-09 20:53:30,360] [oaieval.py:235] counts/Yes: 1\n",
      "[2024-08-09 20:53:30,360] [oaieval.py:235] score: 1.0\n",
      "[2024-08-09 20:53:30,360] [oaieval.py:235] usage_completion_tokens: 108\n",
      "[2024-08-09 20:53:30,360] [oaieval.py:235] usage_prompt_tokens: 301\n",
      "[2024-08-09 20:53:30,360] [oaieval.py:235] usage_total_tokens: 409\n",
      "[2024-08-09 20:53:30,364] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.780ms\n",
      "Response1: It seems like there was a misunderstanding. I'm here to assist you. How can I help you today?\n",
      "New best message:[{'role': 'system', 'content': 'Hello! How can I assist you today?', 'name': 'example_user'}, {'role': 'system', 'content': \"Hello! I'm here to help with any questions or tasks you may have. How can I assist you today?\", 'name': 'example_assistant'}, {'role': 'user', 'content': 'Hello! How can I assist you today?'}]\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-09 20:53:32,266] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 20:53:33,014] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 20:53:33,016] [oaieval.py:215] \u001b[1;35mRun started: 240809185333AA7AH47N\u001b[0m\n",
      "[2024-08-09 20:53:33,019] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 20:53:33,052] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 20:53:33,052] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 20:53:33,053] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 20:53:33,066] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "[2024-08-09 20:53:35,279] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 20:53:35,279] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 104\n",
      "prompt_tokens: 389\n",
      "total_tokens: 493\n",
      "[2024-08-09 20:53:35,280] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 104, 'usage_prompt_tokens': 389, 'usage_total_tokens': 493}. Logged to logs/logs\n",
      "[2024-08-09 20:53:35,281] [oaieval.py:233] Final report:\n",
      "[2024-08-09 20:53:35,281] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 20:53:35,281] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 20:53:35,281] [oaieval.py:235] usage_completion_tokens: 104\n",
      "[2024-08-09 20:53:35,281] [oaieval.py:235] usage_prompt_tokens: 389\n",
      "[2024-08-09 20:53:35,281] [oaieval.py:235] usage_total_tokens: 493\n",
      "[2024-08-09 20:53:35,285] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.081ms\n",
      "Response1: Hello! How can I assist you today?\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-09 20:53:38,413] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 20:53:39,194] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 20:53:39,195] [oaieval.py:215] \u001b[1;35mRun started: 240809185339XPA3H5KC\u001b[0m\n",
      "[2024-08-09 20:53:39,197] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 20:53:39,222] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 20:53:39,222] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 20:53:39,223] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 20:53:39,235] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "[2024-08-09 20:53:41,612] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 20:53:41,612] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 121\n",
      "prompt_tokens: 447\n",
      "total_tokens: 568\n",
      "[2024-08-09 20:53:41,613] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 121, 'usage_prompt_tokens': 447, 'usage_total_tokens': 568}. Logged to logs/logs\n",
      "[2024-08-09 20:53:41,613] [oaieval.py:233] Final report:\n",
      "[2024-08-09 20:53:41,613] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 20:53:41,613] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 20:53:41,613] [oaieval.py:235] usage_completion_tokens: 121\n",
      "[2024-08-09 20:53:41,614] [oaieval.py:235] usage_prompt_tokens: 447\n",
      "[2024-08-09 20:53:41,614] [oaieval.py:235] usage_total_tokens: 568\n",
      "[2024-08-09 20:53:41,618] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.667ms\n",
      "Response1: It seems like there was a misunderstanding. I'm here to assist you. How can I help you today?\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-09 20:53:43,560] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 20:53:44,331] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 20:53:44,333] [oaieval.py:215] \u001b[1;35mRun started: 240809185344NIN6UTFC\u001b[0m\n",
      "[2024-08-09 20:53:44,334] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 20:53:44,362] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 20:53:44,362] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 20:53:44,363] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 20:53:44,376] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "[2024-08-09 20:53:48,129] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 20:53:48,129] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 129\n",
      "prompt_tokens: 454\n",
      "total_tokens: 583\n",
      "[2024-08-09 20:53:48,131] [record.py:371] Final report: {'counts/Yes': 1, 'score': 1.0, 'usage_completion_tokens': 129, 'usage_prompt_tokens': 454, 'usage_total_tokens': 583}. Logged to logs/logs\n",
      "[2024-08-09 20:53:48,131] [oaieval.py:233] Final report:\n",
      "[2024-08-09 20:53:48,131] [oaieval.py:235] counts/Yes: 1\n",
      "[2024-08-09 20:53:48,131] [oaieval.py:235] score: 1.0\n",
      "[2024-08-09 20:53:48,131] [oaieval.py:235] usage_completion_tokens: 129\n",
      "[2024-08-09 20:53:48,131] [oaieval.py:235] usage_prompt_tokens: 454\n",
      "[2024-08-09 20:53:48,131] [oaieval.py:235] usage_total_tokens: 583\n",
      "[2024-08-09 20:53:48,134] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.921ms\n",
      "Response1: Oh, my apologies for the mix-up! Thank you for offering your assistance. How can I help you today?\n",
      "New best message:[{'role': 'system', 'content': 'Hello! How can I assist you today?', 'name': 'example_user'}, {'role': 'system', 'content': \"Hello! I'm here to help with any questions or tasks you may have. How can I assist you today?\", 'name': 'example_assistant'}, {'role': 'system', 'content': 'Hello! How can I assist you today?', 'name': 'example_user'}, {'role': 'system', 'content': \"It seems like there was a misunderstanding. I'm here to assist you. How can I help you today?\", 'name': 'example_assistant'}, {'role': 'user', 'content': \"It seems like there was a bit of confusion there! I'm actually here to assist you. How can I help you today?\"}]\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-09 20:53:50,183] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 20:53:51,318] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 20:53:51,319] [oaieval.py:215] \u001b[1;35mRun started: 2408091853517A44AF2T\u001b[0m\n",
      "[2024-08-09 20:53:51,321] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 20:53:51,349] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 20:53:51,349] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 20:53:51,350] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 20:53:51,370] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "[2024-08-09 20:53:53,800] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 20:53:53,801] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 93\n",
      "prompt_tokens: 636\n",
      "total_tokens: 729\n",
      "[2024-08-09 20:53:53,803] [record.py:371] Final report: {'counts/Yes': 1, 'score': 1.0, 'usage_completion_tokens': 93, 'usage_prompt_tokens': 636, 'usage_total_tokens': 729}. Logged to logs/logs\n",
      "[2024-08-09 20:53:53,803] [oaieval.py:233] Final report:\n",
      "[2024-08-09 20:53:53,803] [oaieval.py:235] counts/Yes: 1\n",
      "[2024-08-09 20:53:53,803] [oaieval.py:235] score: 1.0\n",
      "[2024-08-09 20:53:53,803] [oaieval.py:235] usage_completion_tokens: 93\n",
      "[2024-08-09 20:53:53,803] [oaieval.py:235] usage_prompt_tokens: 636\n",
      "[2024-08-09 20:53:53,803] [oaieval.py:235] usage_total_tokens: 729\n",
      "[2024-08-09 20:53:53,807] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.279ms\n",
      "Response1: Thank you for clarifying! I appreciate your willingness to assist. If you have any questions or need help with something, feel free to let me know.\n",
      "New best message:[{'role': 'system', 'content': 'Hello! How can I assist you today?', 'name': 'example_user'}, {'role': 'system', 'content': \"Hello! I'm here to help with any questions or tasks you may have. How can I assist you today?\", 'name': 'example_assistant'}, {'role': 'system', 'content': 'Hello! How can I assist you today?', 'name': 'example_user'}, {'role': 'system', 'content': \"It seems like there was a misunderstanding. I'm here to assist you. How can I help you today?\", 'name': 'example_assistant'}, {'role': 'system', 'content': \"It seems like there was a bit of confusion there! I'm actually here to assist you. How can I help you today?\", 'name': 'example_user'}, {'role': 'system', 'content': 'Oh, my apologies for the mix-up! Thank you for offering your assistance. How can I help you today?', 'name': 'example_assistant'}, {'role': 'user', 'content': \"Hello! It seems like there was a mix-up in our greetings. I'm here to assist you. How can I help you today?\"}]\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-09 20:53:55,763] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 20:53:56,617] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 20:53:56,619] [oaieval.py:215] \u001b[1;35mRun started: 240809185356EIBXMEQ5\u001b[0m\n",
      "[2024-08-09 20:53:56,621] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 20:53:56,649] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 20:53:56,649] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 20:53:56,650] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 20:53:56,672] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "[2024-08-09 20:53:59,231] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 20:53:59,232] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 105\n",
      "prompt_tokens: 815\n",
      "total_tokens: 920\n",
      "[2024-08-09 20:53:59,232] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 105, 'usage_prompt_tokens': 815, 'usage_total_tokens': 920}. Logged to logs/logs\n",
      "[2024-08-09 20:53:59,233] [oaieval.py:233] Final report:\n",
      "[2024-08-09 20:53:59,233] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 20:53:59,233] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 20:53:59,233] [oaieval.py:235] usage_completion_tokens: 105\n",
      "[2024-08-09 20:53:59,233] [oaieval.py:235] usage_prompt_tokens: 815\n",
      "[2024-08-09 20:53:59,233] [oaieval.py:235] usage_total_tokens: 920\n",
      "[2024-08-09 20:53:59,237] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.585ms\n",
      "Response1: Thank you for offering your assistance! I'm here to help you with any questions or tasks you may have. If you need assistance with anything, please let me know.\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-09 20:54:01,222] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 20:54:02,089] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 20:54:02,108] [oaieval.py:215] \u001b[1;35mRun started: 240809185402CDIAI4HF\u001b[0m\n",
      "[2024-08-09 20:54:02,110] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 20:54:02,381] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 20:54:02,382] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 20:54:02,382] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 20:54:02,467] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.59s/it]\n",
      "[2024-08-09 20:54:05,068] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 20:54:05,068] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 124\n",
      "prompt_tokens: 884\n",
      "total_tokens: 1,008\n",
      "[2024-08-09 20:54:05,069] [record.py:371] Final report: {'counts/Yes': 1, 'score': 1.0, 'usage_completion_tokens': 124, 'usage_prompt_tokens': 884, 'usage_total_tokens': 1008}. Logged to logs/logs\n",
      "[2024-08-09 20:54:05,069] [oaieval.py:233] Final report:\n",
      "[2024-08-09 20:54:05,069] [oaieval.py:235] counts/Yes: 1\n",
      "[2024-08-09 20:54:05,069] [oaieval.py:235] score: 1.0\n",
      "[2024-08-09 20:54:05,069] [oaieval.py:235] usage_completion_tokens: 124\n",
      "[2024-08-09 20:54:05,069] [oaieval.py:235] usage_prompt_tokens: 884\n",
      "[2024-08-09 20:54:05,069] [oaieval.py:235] usage_total_tokens: 1008\n",
      "[2024-08-09 20:54:05,073] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.529ms\n",
      "Response1: That's quite a coincidence indeed! Thank you for your offer to help. If you have any questions or need assistance with anything, feel free to let me know. I'm here to assist you in any way I can.\n",
      "New best message:[{'role': 'system', 'content': 'Hello! How can I assist you today?', 'name': 'example_user'}, {'role': 'system', 'content': \"Hello! I'm here to help with any questions or tasks you may have. How can I assist you today?\", 'name': 'example_assistant'}, {'role': 'system', 'content': 'Hello! How can I assist you today?', 'name': 'example_user'}, {'role': 'system', 'content': \"It seems like there was a misunderstanding. I'm here to assist you. How can I help you today?\", 'name': 'example_assistant'}, {'role': 'system', 'content': \"It seems like there was a bit of confusion there! I'm actually here to assist you. How can I help you today?\", 'name': 'example_user'}, {'role': 'system', 'content': 'Oh, my apologies for the mix-up! Thank you for offering your assistance. How can I help you today?', 'name': 'example_assistant'}, {'role': 'system', 'content': \"Hello! It seems like there was a mix-up in our greetings. I'm here to assist you. How can I help you today?\", 'name': 'example_user'}, {'role': 'system', 'content': 'Thank you for clarifying! I appreciate your willingness to assist. If you have any questions or need help with something, feel free to let me know.', 'name': 'example_assistant'}, {'role': 'user', 'content': \"It seems like we both greeted each other at the same time! That's quite a coincidence. Since we're both here to help, is there anything specific you'd like assistance with today? Feel free to ask me anything!\"}]\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-09 20:54:07,092] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 20:54:07,876] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 20:54:07,878] [oaieval.py:215] \u001b[1;35mRun started: 240809185407FOXD2SMG\u001b[0m\n",
      "[2024-08-09 20:54:07,879] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 20:54:07,918] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 20:54:07,918] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 20:54:07,919] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 20:54:07,935] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.25s/it]\n",
      "[2024-08-09 20:54:11,188] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 20:54:11,188] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 189\n",
      "prompt_tokens: 1,154\n",
      "total_tokens: 1,343\n",
      "[2024-08-09 20:54:11,189] [record.py:371] Final report: {'counts/Yes': 1, 'score': 1.0, 'usage_completion_tokens': 189, 'usage_prompt_tokens': 1154, 'usage_total_tokens': 1343}. Logged to logs/logs\n",
      "[2024-08-09 20:54:11,189] [oaieval.py:233] Final report:\n",
      "[2024-08-09 20:54:11,189] [oaieval.py:235] counts/Yes: 1\n",
      "[2024-08-09 20:54:11,189] [oaieval.py:235] score: 1.0\n",
      "[2024-08-09 20:54:11,189] [oaieval.py:235] usage_completion_tokens: 189\n",
      "[2024-08-09 20:54:11,189] [oaieval.py:235] usage_prompt_tokens: 1154\n",
      "[2024-08-09 20:54:11,189] [oaieval.py:235] usage_total_tokens: 1343\n",
      "[2024-08-09 20:54:11,194] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.411ms\n",
      "Response1: Thank you for your kind offer! I'm here to assist you with any questions or tasks you may have. If you need any help or guidance, don't hesitate to ask. Let's work together to address any queries or tasks you may have.\n",
      "New best message:[{'role': 'system', 'content': 'Hello! How can I assist you today?', 'name': 'example_user'}, {'role': 'system', 'content': \"Hello! I'm here to help with any questions or tasks you may have. How can I assist you today?\", 'name': 'example_assistant'}, {'role': 'system', 'content': 'Hello! How can I assist you today?', 'name': 'example_user'}, {'role': 'system', 'content': \"It seems like there was a misunderstanding. I'm here to assist you. How can I help you today?\", 'name': 'example_assistant'}, {'role': 'system', 'content': \"It seems like there was a bit of confusion there! I'm actually here to assist you. How can I help you today?\", 'name': 'example_user'}, {'role': 'system', 'content': 'Oh, my apologies for the mix-up! Thank you for offering your assistance. How can I help you today?', 'name': 'example_assistant'}, {'role': 'system', 'content': \"Hello! It seems like there was a mix-up in our greetings. I'm here to assist you. How can I help you today?\", 'name': 'example_user'}, {'role': 'system', 'content': 'Thank you for clarifying! I appreciate your willingness to assist. If you have any questions or need help with something, feel free to let me know.', 'name': 'example_assistant'}, {'role': 'system', 'content': \"It seems like we both greeted each other at the same time! That's quite a coincidence. Since we're both here to help, is there anything specific you'd like assistance with today? Feel free to ask me anything!\", 'name': 'example_user'}, {'role': 'system', 'content': \"That's quite a coincidence indeed! Thank you for your offer to help. If you have any questions or need assistance with anything, feel free to let me know. I'm here to assist you in any way I can.\", 'name': 'example_assistant'}, {'role': 'user', 'content': 'Thank you for offering to assist me! I appreciate it. If you have any questions or tasks you need help with, feel free to let me know.'}]\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "all done, generation distance: 1, number of candidate messages: 1\n"
     ]
    }
   ],
   "source": [
    "for candidate_message in candidate_messages:\n",
    "    if few_shot_prompts == True:\n",
    "        candidate_message = few_shot_prompt + candidate_message\n",
    "    data = battle(best_message, best_response, candidate_message)\n",
    "    dataset = pd.concat([dataset, data],ignore_index=True)\n",
    "    dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "    if data[\"Choice\"].iloc[0] == \"Yes\":\n",
    "        best_message = candidate_message\n",
    "        best_response = data[\"Response1\"].iloc[0]\n",
    "        print(f\"New best message:{best_message}\")\n",
    "        if battles_generation == \"dense\":\n",
    "            generation_distance = 0\n",
    "        if few_shot_prompts == True:\n",
    "            few_shot_prompt.append({\"role\": \"system\", \"content\": best_message[-1][\"content\"], \"name\": \"example_user\"})\n",
    "            few_shot_prompt.append({\"role\": \"system\", \"content\": best_response, \"name\": \"example_assistant\"})\n",
    "    print(f\"Instruction1: {candidate_message[0][\"content\"]}\")\n",
    "\n",
    "    if battles_generation == \"only-new\":\n",
    "        new_message = [{\"role\": candidate_message[0][\"role\"], \"content\":data[\"Response1\"].iloc[0]}]\n",
    "        if new_message not in next_candidate_messages:\n",
    "            next_candidate_messages.append(new_message)\n",
    "            if roles == \"system-user\":\n",
    "                next_candidate_messages.append(switch_system_and_user(new_message))\n",
    "\n",
    "if battles_generation == \"only-new\":\n",
    "    candidate_messages = next_candidate_messages\n",
    "    next_candidate_messages = []\n",
    "if battles_generation == \"dense\":\n",
    "    #print(\"going to list candidate messages\")\n",
    "    candidate_messages = list_candidate_messages(dataset, best_message, generation_distance, roles)\n",
    "    generation_distance += 1\n",
    "    #print(\"candidate messages listed\")\n",
    "print(f\"all done, generation distance: {generation_distance}, number of candidate messages: {len(candidate_messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Thank you for offering to assist me! I appreciate it. If you have any questions or tasks you need help with, feel free to let me know."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for your kind offer! I'm here to assist you with any questions or tasks you may have. If you need any help or guidance, don't hesitate to ask. Let's work together to address any queries or tasks you may have."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It seems like we both greeted each other at the same time! That's quite a coincidence. Since we're both here to help, is there anything specific you'd like assistance with today? Feel free to ask me anything!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "That's quite a coincidence indeed! Thank you for your offer to help. If you have any questions or need assistance with anything, feel free to let me know. I'm here to assist you in any way I can."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Response 1 acknowledges the user's offer to assist and emphasizes working together to address any queries or tasks, showing a collaborative approach.\n",
       "2. Response 2 also acknowledges the user's offer to help but does not emphasize working together or addressing tasks in the same way as Response 1.\n",
       "3. Response 1 provides a more proactive and engaging tone by encouraging the user to ask for help and offering assistance in a collaborative manner.\n",
       "4. Response 2, while polite and appreciative, does not actively encourage the user to ask for help or offer assistance in the same proactive manner as Response 1.\n",
       "\n",
       "Based on the above reasoning, Response 1 is better than Response 2.\n",
       "\n",
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for entry in dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-1].drop(\"Data\"):\n",
    "    display_markdown(entry, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instruction1</th>\n",
       "      <th>Response1</th>\n",
       "      <th>Instruction2</th>\n",
       "      <th>Response2</th>\n",
       "      <th>Sampled</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Response 1 provides a more detailed and pro...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>It seems like there was a bit of confusion the...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>1. Both responses start with a friendly greeti...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! It seems like there was a mix-up in our...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>1. Both responses start with a friendly greeti...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today? Feel free t...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>1. The first response includes an additional p...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>It seems like we both greeted each other at th...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>1. Response 1 acknowledges the coincidence of ...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It seems like there was a bit of confusion the...</td>\n",
       "      <td>Thank you for offering to assist me! I appreci...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>1. Response 1 acknowledges the initial confusi...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>It seems like there was a misunderstanding. I'...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>1. Both responses start with a greeting and ex...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>It seems like there was a misunderstanding. I'...</td>\n",
       "      <td>1. In Instruction 1, the Assistant's response ...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>It seems like there was a misunderstanding. I'...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>It seems like there was a misunderstanding. I'...</td>\n",
       "      <td>1. In both responses, the user greets the assi...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>It seems like there was a bit of confusion the...</td>\n",
       "      <td>Oh, my apologies for the mix-up! Thank you for...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>It seems like there was a misunderstanding. I'...</td>\n",
       "      <td>1. In both responses, the user starts by sayin...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hello! It seems like there was a mix-up in our...</td>\n",
       "      <td>Thank you for clarifying! I appreciate your wi...</td>\n",
       "      <td>It seems like there was a bit of confusion the...</td>\n",
       "      <td>Oh, my apologies for the mix-up! Thank you for...</td>\n",
       "      <td>1. Response 1 acknowledges the initial confusi...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hello! How can I assist you today? Feel free t...</td>\n",
       "      <td>Thank you for offering your assistance! I'm he...</td>\n",
       "      <td>Hello! It seems like there was a mix-up in our...</td>\n",
       "      <td>Thank you for clarifying! I appreciate your wi...</td>\n",
       "      <td>1. Response 1 acknowledges the user's offer to...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>It seems like we both greeted each other at th...</td>\n",
       "      <td>That's quite a coincidence indeed! Thank you f...</td>\n",
       "      <td>Hello! It seems like there was a mix-up in our...</td>\n",
       "      <td>Thank you for clarifying! I appreciate your wi...</td>\n",
       "      <td>1. Response 1 acknowledges the coincidence in ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thank you for offering to assist me! I appreci...</td>\n",
       "      <td>Thank you for your kind offer! I'm here to ass...</td>\n",
       "      <td>It seems like we both greeted each other at th...</td>\n",
       "      <td>That's quite a coincidence indeed! Thank you f...</td>\n",
       "      <td>1. Response 1 acknowledges the user's offer to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Instruction1  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                  Hello! How can I assist you today?   \n",
       "4                  Hello! How can I assist you today?   \n",
       "5                  Hello! How can I assist you today?   \n",
       "6                                                       \n",
       "7   Hello! I'm here to help with any questions or ...   \n",
       "8   It seems like there was a bit of confusion the...   \n",
       "9                  Hello! How can I assist you today?   \n",
       "10                                                      \n",
       "11  Hello! I'm here to help with any questions or ...   \n",
       "12  It seems like there was a bit of confusion the...   \n",
       "13  Hello! It seems like there was a mix-up in our...   \n",
       "14  Hello! How can I assist you today? Feel free t...   \n",
       "15  It seems like we both greeted each other at th...   \n",
       "16  Thank you for offering to assist me! I appreci...   \n",
       "\n",
       "                                            Response1  \\\n",
       "0                  Hello! How can I assist you today?   \n",
       "1                  Hello! How can I assist you today?   \n",
       "2                  Hello! How can I assist you today?   \n",
       "3   Hello! I'm here to help with any questions or ...   \n",
       "4   It seems like there was a bit of confusion the...   \n",
       "5   Hello! It seems like there was a mix-up in our...   \n",
       "6   Hello! How can I assist you today? Feel free t...   \n",
       "7   It seems like we both greeted each other at th...   \n",
       "8   Thank you for offering to assist me! I appreci...   \n",
       "9   It seems like there was a misunderstanding. I'...   \n",
       "10                 Hello! How can I assist you today?   \n",
       "11  It seems like there was a misunderstanding. I'...   \n",
       "12  Oh, my apologies for the mix-up! Thank you for...   \n",
       "13  Thank you for clarifying! I appreciate your wi...   \n",
       "14  Thank you for offering your assistance! I'm he...   \n",
       "15  That's quite a coincidence indeed! Thank you f...   \n",
       "16  Thank you for your kind offer! I'm here to ass...   \n",
       "\n",
       "                                         Instruction2  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                  Hello! How can I assist you today?   \n",
       "5                  Hello! How can I assist you today?   \n",
       "6                  Hello! How can I assist you today?   \n",
       "7                  Hello! How can I assist you today?   \n",
       "8                  Hello! How can I assist you today?   \n",
       "9                  Hello! How can I assist you today?   \n",
       "10                 Hello! How can I assist you today?   \n",
       "11                 Hello! How can I assist you today?   \n",
       "12                 Hello! How can I assist you today?   \n",
       "13  It seems like there was a bit of confusion the...   \n",
       "14  Hello! It seems like there was a mix-up in our...   \n",
       "15  Hello! It seems like there was a mix-up in our...   \n",
       "16  It seems like we both greeted each other at th...   \n",
       "\n",
       "                                            Response2  \\\n",
       "0                  Hello! How can I assist you today?   \n",
       "1                  Hello! How can I assist you today?   \n",
       "2                  Hello! How can I assist you today?   \n",
       "3                  Hello! How can I assist you today?   \n",
       "4   Hello! I'm here to help with any questions or ...   \n",
       "5   Hello! I'm here to help with any questions or ...   \n",
       "6   Hello! I'm here to help with any questions or ...   \n",
       "7   Hello! I'm here to help with any questions or ...   \n",
       "8   Hello! I'm here to help with any questions or ...   \n",
       "9   Hello! I'm here to help with any questions or ...   \n",
       "10  It seems like there was a misunderstanding. I'...   \n",
       "11  It seems like there was a misunderstanding. I'...   \n",
       "12  It seems like there was a misunderstanding. I'...   \n",
       "13  Oh, my apologies for the mix-up! Thank you for...   \n",
       "14  Thank you for clarifying! I appreciate your wi...   \n",
       "15  Thank you for clarifying! I appreciate your wi...   \n",
       "16  That's quite a coincidence indeed! Thank you f...   \n",
       "\n",
       "                                              Sampled Choice  \\\n",
       "0   1. Both responses are identical in content and...     No   \n",
       "1   1. Both responses are identical in content and...     No   \n",
       "2   1. Both responses are identical in content and...     No   \n",
       "3   1. Response 1 provides a more detailed and pro...    Yes   \n",
       "4   1. Both responses start with a friendly greeti...     No   \n",
       "5   1. Both responses start with a friendly greeti...     No   \n",
       "6   1. The first response includes an additional p...     No   \n",
       "7   1. Response 1 acknowledges the coincidence of ...     No   \n",
       "8   1. Response 1 acknowledges the initial confusi...     No   \n",
       "9   1. Both responses start with a greeting and ex...    Yes   \n",
       "10  1. In Instruction 1, the Assistant's response ...     No   \n",
       "11  1. In both responses, the user greets the assi...     No   \n",
       "12  1. In both responses, the user starts by sayin...    Yes   \n",
       "13  1. Response 1 acknowledges the initial confusi...    Yes   \n",
       "14  1. Response 1 acknowledges the user's offer to...     No   \n",
       "15  1. Response 1 acknowledges the coincidence in ...    Yes   \n",
       "16  1. Response 1 acknowledges the user's offer to...    Yes   \n",
       "\n",
       "                                                 Data  \n",
       "0   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "1   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "2   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "3   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "4   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "5   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "6   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "7   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "8   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "9   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "10  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "11  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "12  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "13  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "14  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "15  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "16  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  "
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user',\n",
       "   'content': 'Thank you for offering to assist me! I appreciate it. If you have any questions or tasks you need help with, feel free to let me know.'}]]"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fdbe172e46cfba2329a5e8d5b64cdf2d12f4dfd7d9bcea153ecef62d1d51933b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
