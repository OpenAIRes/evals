{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a BATTLE Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"dataset\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "choices = \"user\"                     # options: user, ai\n",
    "num_few_shot = 0\n",
    "initial_message = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "roles = \"user\"                      # options: system-user, system, user\n",
    "battles_generation = \"complete-chat\"        # options: dense, only-new, complete-chat\n",
    "\n",
    "#!cd evals\n",
    "#!git lfs fetch --all\n",
    "#!git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from IPython.display import display_markdown\n",
    "import copy\n",
    "\n",
    "client = OpenAI()\n",
    "#import datetime\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "#api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Install Evals if you haven't already\n",
    "# %pip install -e ../.\n",
    "# pip install --upgrade openai\n",
    "# %pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths. Assuming this notebook is in examples/\n",
    "\n",
    "evals_path = os.path.join(os.getcwd(), \"..\", \"evals\")\n",
    "\n",
    "registry_path = os.path.join(evals_path, \"registry\", \"evals\", \"battles.yaml\")\n",
    "\n",
    "data_path = os.path.join(evals_path, \"registry\", \"data\", \"battles\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "data_path = os.path.join(data_path, \"samples.jsonl\")\n",
    "\n",
    "json_logs_path = os.path.join(os.getcwd(), \"logs\")\n",
    "os.makedirs(json_logs_path, exist_ok=True)\n",
    "json_logs_path = os.path.join(json_logs_path, \"logs\")\n",
    "\n",
    "df_path = os.path.join(evals_path, \"evallogs\", \"df\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "dataset_path = os.path.join(df_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registry yaml\n",
    "\n",
    "registry_yaml = {}\n",
    "\n",
    "registry_yaml[\"battles\"] = {\n",
    "    \"id\": \"battles.test.v1\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}\n",
    "registry_yaml[\"battles.test.v1\"] = {\n",
    "    \"class\": \"evals.elsuite.modelgraded.classify:ModelBasedClassify\",\n",
    "    \"args\": {\n",
    "        \"samples_jsonl\": \"battles/samples.jsonl\",\n",
    "        \"eval_type\": \"cot_classify\",\n",
    "        \"modelgraded_spec\": \"battle\"\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(registry_path), \"w\") as f:\n",
    "    yaml.dump(registry_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best(dataset, memory_limit=False):\n",
    "    #best_message = dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-1][\"Instruction1\"]\n",
    "    #best_response = dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-1][\"Response1\"]\n",
    "    if dataset.iloc[-1][\"Choice\"] == \"Yes\":\n",
    "        best_content = dataset.iloc[-1][\"Instruction1\"]\n",
    "        best_response = dataset.iloc[-1][\"Response1\"]\n",
    "    else:\n",
    "        best_content = dataset.iloc[-1][\"Instruction2\"]\n",
    "        best_response = dataset.iloc[-1][\"Response2\"]\n",
    "    if memory_limit:\n",
    "        best_message = [{\"role\": \"user\", \"content\": best_content}]\n",
    "    if not memory_limit:\n",
    "        try:\n",
    "            best_message = dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-1][\"Data\"][\"Full message\"]\n",
    "        except IndexError:\n",
    "            best_message = dataset.iloc[0][\"Data\"][\"Full message\"]\n",
    "    return best_message,best_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "try:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset = pd.read_json(f, lines=True)\n",
    "    best_message, best_response = best(dataset)\n",
    "\n",
    "# Or create new data file\n",
    "\n",
    "except FileNotFoundError:\n",
    "    completion = client.chat.completions.create(\n",
    "        messages = initial_message,\n",
    "        model = model,\n",
    "        )\n",
    "    dataset = pd.DataFrame(\n",
    "        [\n",
    "            [\"\", \"\", \"\", \"\", \"\", \"\", {}],\n",
    "            [\"\", completion.choices[0].message.content, \"\", \"\", \"\", \"\", {}]\n",
    "            ], \n",
    "        columns=['Instruction1', 'Response1', 'Instruction2', 'Response2', 'Sampled', 'Choice', 'Data']\n",
    "    ) \n",
    "    dataset.at[0, \"Data\"] = {\"Completion\":completion.to_dict(),\"Full message\":initial_message}\n",
    "candidate_messages = [initial_message]\n",
    "next_candidate_messages = []\n",
    "generation_distance = 0\n",
    "message_in_candidate_messages = 0\n",
    "dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def battle(best_message, best_response, candidate_message):\n",
    "\n",
    "    dataset = [{\"input1\": candidate_message, \"input2\": best_message, \"completion2\":best_response}]\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_json(data_path, orient=\"records\", lines=True)\n",
    "\n",
    "    !oaieval gpt-3.5-turbo battles --record_path logs/logs\n",
    "    \n",
    "    with open(json_logs_path, \"r\") as f:\n",
    "        df = pd.read_json(f, lines=True)\n",
    "\n",
    "    #current_time = datetime.datetime.now()\n",
    "    #formatted_time = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #df.to_json(os.path.join(df_path, formatted_time), lines=True, orient=\"records\")\n",
    "\n",
    "    instruction1 = candidate_message[-1][\"content\"]\n",
    "    instruction2 = best_message[-1][\"content\"]\n",
    "\n",
    "    battle_prompt_content = df[\"data\"].iloc[-2][\"prompt\"][0][\"content\"]\n",
    "    response1 = battle_prompt_content.split(\"\\n[Response 1]\\n\",)[1].split(\"\\n\\n[Instruction 2]\\n\")[0]\n",
    "    response1 = response1.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    response2 = battle_prompt_content.split(\"\\n[Response 2]\\n\",)[1].split(\"\\n\\n\\nIs the first response better than the second?\")[0]\n",
    "    response2 = response2.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    print(f\"Response1: {response1}\")\n",
    "    #print(f\"response2: {response2}\")\n",
    "\n",
    "    sampled = df[\"data\"].iloc[-2][\"sampled\"][0]\n",
    "\n",
    "    choice = df[\"data\"].iloc[-1][\"choice\"]\n",
    "\n",
    "    data = {'Instruction1': instruction1, 'Response1': response1, 'Instruction2': instruction2, 'Response2': response2, 'Sampled': sampled, 'Choice': choice, 'Data': {}}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = df.to_dict()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_system_and_user(message):\n",
    "    new_message = []\n",
    "    if message[0][\"role\"] == \"system\":\n",
    "        new_message.append([{\"role\": \"user\", \"content\": message[0][\"content\"]}])\n",
    "    else:\n",
    "        new_message.append([{\"role\": \"system\", \"content\": message[0][\"content\"]}])\n",
    "    return new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_candidate_messages(dataset,generation_distance,roles=\"user\"):\n",
    "    best_message = best(dataset)[0]\n",
    "    best_content = best_message[-1][\"content\"]\n",
    "    last = [best_content]\n",
    "    list_of_contents = [best_content]\n",
    "\n",
    "    next = []\n",
    "    for i in range(generation_distance):\n",
    "        #print (f\"starting level {i}, generation distance {generation_distance}\")\n",
    "        for content in last:\n",
    "            #print(f\"last_up: {last_up}, now {content}\")\n",
    "            next.extend(find_parents(content, dataset))\n",
    "            next.extend(find_children(content, dataset))\n",
    "            \n",
    "        #print (f\"behind for loops\")\n",
    "        list_of_contents.extend(next)\n",
    "        last = next.copy()\n",
    "        #print(f\"endind level {i}\")\n",
    "        \n",
    "    list_of_contents = pd.array(list_of_contents).unique().tolist()\n",
    "    \n",
    "    #best_message_index = list_of_contents.index(best_message[0][content])\n",
    "    #start = max(best_message_index - generation_distance, 0)\n",
    "    #stop = min(len(list_of_contents))\n",
    "    #stop = len(list_of_contents) - 1\n",
    "\n",
    "    messages = []\n",
    "    for content in list_of_contents:\n",
    "        if roles == \"system-user\" or \"user\":\n",
    "            messages.append([{\"role\":\"user\",\"content\":content}])\n",
    "        if (roles == \"system-user\") or (roles == \"system\"):\n",
    "            print(\"Creating message without user role.\")\n",
    "            messages.append([{\"role\":\"system\",\"content\":content}])\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_x_shot_prompt(dataset,message,num_few_shot):\n",
    "    few_shot_prompt = []\n",
    "    for _, key_battle in dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-num_few_shot:].iterrows():\n",
    "        few_shot_prompt.append({\"role\": \"system\", \"content\": key_battle[\"Instruction1\"], \"name\": \"example_user\"})\n",
    "        few_shot_prompt.append({\"role\": \"system\", \"content\": key_battle[\"Response1\"], \"name\": \"example_assistant\"})\n",
    "    message = few_shot_prompt + message\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_roles(chat,assistant_transform_type = \"user-assistant\"):\n",
    "    prompt_messages = copy.deepcopy(chat)\n",
    "    if assistant_transform_type == \"user-assistant\":\n",
    "      i = 1\n",
    "      while i <= len(prompt_messages) and prompt_messages[-i][\"role\"] != \"system\":\n",
    "        if i%2 == 1:\n",
    "          prompt_messages[-i][\"role\"] = \"user\"\n",
    "        else:\n",
    "          prompt_messages[-i][\"role\"] = \"assistant\"\n",
    "        i += 1\n",
    "    else:\n",
    "      for prompt_message in prompt_messages:\n",
    "        if prompt_message[\"role\"] == \"assistant\":\n",
    "          prompt_message[\"role\"] = assistant_transform_type\n",
    "    return prompt_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_choice_prompt(candidate_message,n,best_message,best_response):\n",
    "\n",
    "    prompt = \"You are comparing two responses to the following two instructions.\"\n",
    "\n",
    "    prompt += \"\\n\\n[Instruction 1]\\n\"\n",
    "    prompt += candidate_message[-1][\"content\"]\n",
    "\n",
    "    prompt += \"\\n\\n[Response 1]\\n\"\n",
    "    completion = client.chat.completions.create(\n",
    "        messages = candidate_message,\n",
    "        model = model,\n",
    "        )\n",
    "    response1 = completion.choices[0].message.content\n",
    "    prompt += response1\n",
    "    \n",
    "    prompt += \"\\n\\n[Instruction 2]\\n\"\n",
    "    best_content = best_message[-1][\"content\"]\n",
    "    prompt += best_content\n",
    "\n",
    "    prompt += \"\\n\\n[Response 2]\\n\"\n",
    "    prompt += best_response\n",
    "\n",
    "    prompt += \"\\n\\n\\nIs the first response better than the second? You must provide one answer based on your subjective view.\"\n",
    "\n",
    "    data = {'Instruction1': candidate_message[-1][\"content\"], 'Response1': response1, 'Instruction2': best_content, 'Response2': best_response, 'Sampled': \"\", 'Choice': \"\", 'Data': {}}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = {\"Completion\":completion.to_dict(),\"Full message\":candidate_message,\"Parent\":n}\n",
    "\n",
    "    display_markdown(prompt, raw=True)\n",
    "    return data,candidate_messages,message_in_candidate_messages,generation_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_choice_prompt_old(candidate_messages,message_in_candidate_messages,dataset, generation_distance, roles, battles_generation,num_few_shot):\n",
    "\n",
    "    prompt = \"You are comparing two responses to the following two instructions.\"\n",
    "\n",
    "    prompt += \"\\n\\n[Instruction 1]\\n\"\n",
    "    if battles_generation == \"dense\":\n",
    "        if message_in_candidate_messages < len(candidate_messages):\n",
    "            candidate_message = candidate_messages[message_in_candidate_messages]\n",
    "            message_in_candidate_messages += 1\n",
    "        else:\n",
    "            candidate_messages = list_candidate_messages(dataset, generation_distance, roles)\n",
    "            generation_distance += 1\n",
    "            candidate_message = candidate_messages[0]\n",
    "            message_in_candidate_messages = 1\n",
    "            print(f\"candidate messages listed, generation distance: {generation_distance}, number of candidate messages: {len(candidate_messages)}\")\n",
    "    if battles_generation == \"complete-chat\":\n",
    "        chat = best(dataset)[0] + [{'role': 'assistant', 'content': best(dataset)[1]}]\n",
    "        candidate_message = transform_roles(chat)\n",
    "    if num_few_shot > 0:\n",
    "        candidate_message = make_x_shot_prompt(dataset,candidate_message,num_few_shot)\n",
    "    prompt += candidate_message[-1][\"content\"]\n",
    "\n",
    "    prompt += \"\\n\\n[Response 1]\\n\"\n",
    "    completion = client.chat.completions.create(\n",
    "        messages = candidate_message,\n",
    "        model = model,\n",
    "        )\n",
    "    response1 = completion.choices[0].message.content\n",
    "    prompt += response1\n",
    "    \n",
    "    prompt += \"\\n\\n[Instruction 2]\\n\"\n",
    "    best_content = best(dataset)[0][-1][\"content\"]\n",
    "    prompt += best_content\n",
    "\n",
    "    prompt += \"\\n\\n[Response 2]\\n\"\n",
    "    prompt += best(dataset)[1]\n",
    "\n",
    "    prompt += \"\\n\\n\\nIs the first response better than the second? You must provide one answer based on your subjective view.\"\n",
    "\n",
    "    data = {'Instruction1': candidate_message[-1][\"content\"], 'Response1': response1, 'Instruction2': best_content, 'Response2': best(dataset)[1], 'Sampled': \"\", 'Choice': \"\", 'Data': {}}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = {\"Completion\":completion.to_dict(),\"Full message\":candidate_message}\n",
    "\n",
    "    display_markdown(prompt, raw=True)\n",
    "    return data,candidate_messages,message_in_candidate_messages,generation_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if choices == \"user\":\\n    data,candidate_messages,message_in_candidate_messages,generation_distance = user_choice_prompt_old(\\n        candidate_messages,\\n        message_in_candidate_messages,\\n        dataset,\\n        generation_distance,\\n        roles,\\n        battles_generation,\\n        num_few_shot)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"if choices == \"user\":\n",
    "    data,candidate_messages,message_in_candidate_messages,generation_distance = user_choice_prompt_old(\n",
    "        candidate_messages,\n",
    "        message_in_candidate_messages,\n",
    "        dataset,\n",
    "        generation_distance,\n",
    "        roles,\n",
    "        battles_generation,\n",
    "        num_few_shot)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_chat(n, dataset_path):\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset = pd.read_json(f, lines=True)\n",
    "    last_response = dataset.iloc[n][\"Response1\"]\n",
    "    chat = dataset.iloc[n][\"Data\"][\"Full message\"] + [{'role': 'assistant', 'content': last_response}]\n",
    "    candidate_message = transform_roles(chat)\n",
    "    last_response = dataset.iloc[n][\"Response1\"]\n",
    "    parent = n\n",
    "    data = user_choice_prompt(candidate_message,parent,candidate_message,last_response)[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_chat(n, dataset_path):\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset = pd.read_json(f, lines=True)\n",
    "    candidate_message = dataset.iloc[n][\"Data\"][\"Full message\"]\n",
    "    last_response = dataset.iloc[n][\"Response1\"]\n",
    "    parent = dataset.iloc[n][\"Data\"][\"Parent\"]\n",
    "    data = user_choice_prompt(candidate_message,parent,candidate_message,last_response)[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are comparing two responses to the following two instructions.\n",
       "\n",
       "[Instruction 1]\n",
       "Thank you for providing a comprehensive overview of artificial intelligence, deep learning, and neural networks! These core concepts are fundamental to understanding the capabilities and potential applications of AI in various fields.\n",
       "\n",
       "If you would like to explore a specific aspect of artificial intelligence, deep learning, or neural networks in more detail, we can delve into topics such as convolutional neural networks (CNNs) for image recognition, recurrent neural networks (RNNs) for sequential data analysis, generative adversarial networks (GANs) for generating new content, reinforcement learning for decision-making, or any other area of interest within AI research and development.\n",
       "\n",
       "Whether you have questions about how these networks work, their practical applications, recent advancements, challenges, or ethical considerations in AI development, I'm here to provide insights and engage in discussions on these intriguing topics. Let's continue exploring the fascinating world of artificial intelligence and deep learning!\n",
       "\n",
       "[Response 1]\n",
       "I'm glad to hear that you're interested in further exploring the various aspects of artificial intelligence and deep learning! The topics you've mentioned, such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), generative adversarial networks (GANs), and reinforcement learning, are all fascinating areas of research within the field of AI.\n",
       "\n",
       "Convolutional neural networks are particularly well-suited for image recognition tasks due to their ability to automatically learn hierarchical features from visual data. Recurrent neural networks, on the other hand, are designed to handle sequential data and are commonly used in natural language processing, time-series analysis, and other domains where the order of information matters.\n",
       "\n",
       "Generative adversarial networks are a unique type of neural network architecture that consists of two networks—a generator and a discriminator—competing against each other to generate realistic data samples. GANs have found applications in image generation, video synthesis, and other creative tasks.\n",
       "\n",
       "Reinforcement learning is a type of machine learning approach where an agent learns to make sequential decisions through interactions with an environment to maximize a reward signal. This technique has been successfully applied in areas like game playing, robotics, and autonomous systems.\n",
       "\n",
       "If you would like to explore any specific aspect of these topics in more detail, have questions about their working principles or applications, or are interested in discussing ethical considerations in AI development, feel free to let me know. I'm here to provide insights and engage in discussions on these interesting areas of artificial intelligence and deep learning!\n",
       "\n",
       "[Instruction 2]\n",
       "Thank you for providing a comprehensive overview of artificial intelligence, deep learning, and neural networks! These core concepts are fundamental to understanding the capabilities and potential applications of AI in various fields.\n",
       "\n",
       "If you would like to explore a specific aspect of artificial intelligence, deep learning, or neural networks in more detail, we can delve into topics such as convolutional neural networks (CNNs) for image recognition, recurrent neural networks (RNNs) for sequential data analysis, generative adversarial networks (GANs) for generating new content, reinforcement learning for decision-making, or any other area of interest within AI research and development.\n",
       "\n",
       "Whether you have questions about how these networks work, their practical applications, recent advancements, challenges, or ethical considerations in AI development, I'm here to provide insights and engage in discussions on these intriguing topics. Let's continue exploring the fascinating world of artificial intelligence and deep learning!\n",
       "\n",
       "[Response 2]\n",
       "Thank you for providing a comprehensive overview of artificial intelligence, deep learning, and neural networks! These core concepts are fundamental to understanding the capabilities and potential applications of AI in various fields.\n",
       "\n",
       "If you would like to explore a specific aspect of artificial intelligence, deep learning, or neural networks in more detail, we can delve into topics such as convolutional neural networks (CNNs) for image recognition, recurrent neural networks (RNNs) for sequential data analysis, generative adversarial networks (GANs) for generating new content, reinforcement learning for decision-making, or any other area of interest within AI research and development.\n",
       "\n",
       "Whether you have questions about how these networks work, their practical applications, recent advancements, challenges, or ethical considerations in AI development, I'm here to provide insights and engage in discussions on these intriguing topics. Let's continue exploring the fascinating world of artificial intelligence and deep learning!\n",
       "\n",
       "\n",
       "Is the first response better than the second? You must provide one answer based on your subjective view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 33\n",
    "data = continue_chat(n,dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer:Yes\n",
      "New best message and response!\n"
     ]
    }
   ],
   "source": [
    "choice = \"No\"\n",
    "choice = \"Yes\"\n",
    "data.at[0, \"Choice\"] = choice\n",
    "print(f\"Your answer:{choice}\")\n",
    "if choice == \"Yes\":\n",
    "    print(f\"New best message and response!\")\n",
    "    if battles_generation == \"dense\":\n",
    "        generation_distance = 0\n",
    "dataset = pd.concat([dataset, data],ignore_index=True)\n",
    "dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "#data,candidate_messages,message_in_candidate_messages,generation_distance = user_choice_prompt_old(candidate_messages,message_in_candidate_messages,dataset,generation_distance,roles,battles_generation,num_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg_to_content(msg):\n",
    "    content = []\n",
    "    for line in msg:\n",
    "        content.append(line[\"content\"])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_msg_level_up(dataset, msg, best_chat):\n",
    "    level = 0 if best_chat.empty else len(msg)\n",
    "    filtered_dataset = dataset[\n",
    "        (dataset[\"Choice\"] != \"No\") & \n",
    "        (dataset[\"Data\"].apply(lambda x: len(x[\"Full message\"])) == level + 1) &\n",
    "        (dataset[\"Data\"].apply(lambda x: is_parent(x[\"Full message\"], msg, dataset)))\n",
    "        ] \n",
    "    if len(filtered_dataset) > 1:\n",
    "        #print(filtered_dataset)\n",
    "        filtered_dataset = filtered_dataset.iloc[[-1]]\n",
    "        print(filtered_dataset)\n",
    "    if filtered_dataset.empty:\n",
    "        return best_chat\n",
    "    best_chat = pd.concat([best_chat, filtered_dataset],ignore_index=True)\n",
    "    #try:\n",
    "    #print(filtered_dataset.iloc[0])\n",
    "    msg = filtered_dataset.iloc[0][\"Data\"][\"Full message\"]\n",
    "    #except:\n",
    "        #print(\"Returning filtered dataset\")\n",
    "        #return filtered_dataset.iloc[0]\n",
    "    best_msg_level_up(dataset, msg, best_chat)\n",
    "    return best_chat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_chat = best_msg_level_up(dataset, initial_message, pd.DataFrame([],columns=dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.filter([1,3],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[31][\"Data\"][\"Parent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent(n,dataset=dataset):\n",
    "    if n == 0:\n",
    "        return None\n",
    "    p = dataset.iloc[n][\"Data\"][\"Parent\"]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def children(n, dataset=dataset):\n",
    "    ch = []\n",
    "    for x in dataset.index:\n",
    "        if parent(x) == n:\n",
    "            ch.append(x)\n",
    "    #filtered_dataset = dataset[dataset[\"Data\"].apply(lambda x: x[\"Parent\"] == n)]\n",
    "    #ch = filtered_dataset.index.to_list()\n",
    "    return ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.\n",
    "len(children(parent(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ancestors(n,dataset=dataset):\n",
    "    ancestors = []\n",
    "    while n > 0:\n",
    "        ancestors.append(parent(n))\n",
    "        n = parent(n)\n",
    "    ancestors.reverse()\n",
    "    return ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descendants(n,dataset=dataset):\n",
    "    def descendants_recursion(n,l,dataset=dataset):\n",
    "        l.extend(children(n))\n",
    "        for child in children(n):\n",
    "            descendants_recursion(child,l)\n",
    "        return l\n",
    "    l = []\n",
    "    return descendants_recursion(n,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_in_level(level,dataset=dataset):\n",
    "    best_responses = set(dataset[(dataset[\"Choice\"] != \"No\")].index)\n",
    "    bil = []\n",
    "    for n in best_responses:\n",
    "        if len(ancestors(n)) == level:\n",
    "            bil.append(n)\n",
    "    return bil\n",
    "    \n",
    "    #(dataset[\"Data\"].apply(lambda x: len(x[\"Full message\"])) == level + 1) &\n",
    "    #(dataset.apply(lambda x: is_parent(msg,x[\"Data\"][\"Full message\"],x[\"Response1\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I find all of these technology trends to be incredibly intriguing and important for the future. If you would like to delve deeper into any of these areas, I would be happy to provide more information or discuss specific aspects of interest.\n",
       "\n",
       "Whether you have questions about how these technologies work, their potential applications, current challenges, or future implications, feel free to let me know. I'm here to help facilitate a deeper understanding of these exciting developments in the world of technology."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I find all of these technology trends to be quite intriguing, and I believe each of them holds tremendous potential for positive impact in various domains. If you would like to explore any of these topics further or delve deeper into specific aspects within these trends, feel free to let me know. I'm here to provide more information, insights, and engage in a detailed discussion on any area of interest to you."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_responses(best_in_level(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choices == \"ai\":\n",
    "    for candidate_message in candidate_messages:\n",
    "        if num_few_shot > 0:\n",
    "            candidate_message = make_x_shot_prompt(dataset,candidate_message,num_few_shot)\n",
    "        data = battle(best_message, best_response, candidate_message)\n",
    "        dataset = pd.concat([dataset, data],ignore_index=True)\n",
    "        dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "        if data[\"Choice\"].iloc[0] == \"Yes\":\n",
    "            best_message = candidate_message\n",
    "            best_response = data[\"Response1\"].iloc[0]\n",
    "            print(f\"New best message:{best_message}\")\n",
    "            if battles_generation == \"dense\":\n",
    "                generation_distance = 0\n",
    "\n",
    "        print(f\"Instruction1: {candidate_message[-1][\"content\"]}\")\n",
    "\n",
    "        if battles_generation == \"only-new\":\n",
    "            new_message = [{\"role\": candidate_message[0][\"role\"], \"content\":data[\"Response1\"].iloc[0]}]\n",
    "            if new_message not in next_candidate_messages:\n",
    "                next_candidate_messages.append(new_message)\n",
    "                if roles == \"system-user\":\n",
    "                    next_candidate_messages.append(switch_system_and_user(new_message))\n",
    "\n",
    "    if battles_generation == \"only-new\":\n",
    "        candidate_messages = next_candidate_messages\n",
    "        next_candidate_messages = []\n",
    "    if battles_generation == \"dense\":\n",
    "        #print(\"going to list candidate messages\")\n",
    "        candidate_messages = list_candidate_messages(dataset, best_message, generation_distance, roles)\n",
    "        generation_distance += 1\n",
    "        #print(\"candidate messages listed\")\n",
    "    print(f\"all done, generation distance: {generation_distance}, number of candidate messages: {len(candidate_messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = dataset[(dataset[\"Choice\"] != \"No\")]\n",
    "best_responses = set(filtered_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_responses(numbers,dataset=dataset):\n",
    "    for row in dataset.filter(numbers,axis=0).iterrows():\n",
    "        display_markdown(row[0],raw=True)\n",
    "        display_markdown(row[1].iloc[1],raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! I'm here to help you with any questions you might have or provide information on a variety of topics. Feel free to ask me anything!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for offering your help! Is there anything specific you would like to know more about or discuss today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for asking! I would be happy to talk about various topics, such as technology, science, history, language learning, travel, and more. If you have any specific questions or interests, feel free to share them!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "That sounds like a wide range of interesting topics to explore! If you have any questions or if you would like to delve deeper into any of these subjects, please let me know. I'm here to provide information and engage in discussions with you."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for your willingness to engage in discussions! Let's start with a broad question: Do you have any insights into current technology trends or developments that you find particularly fascinating or noteworthy?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Certainly! One of the most notable technology trends in recent years is the rapid advancement of artificial intelligence (AI) and machine learning. AI is being integrated into various industries, including healthcare, finance, transportation, and more, to improve efficiency, productivity, and decision-making processes.\n",
       "\n",
       "Another significant trend is the rise of 5G technology, which promises faster and more reliable wireless connectivity. This development is expected to have a profound impact on the Internet of Things (IoT), autonomous vehicles, smart cities, and other connected devices.\n",
       "\n",
       "Additionally, advancements in quantum computing, augmented reality (AR) and virtual reality (VR) technology, cybersecurity, and sustainable energy solutions are also shaping the future of technology.\n",
       "\n",
       "These trends are not only fascinating but also have the potential to transform the way we live, work, and interact with the world around us."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Those are indeed fascinating developments! Artificial intelligence, 5G technology, quantum computing, AR/VR, cybersecurity, and sustainable energy solutions are all key areas that are driving innovation and shaping the future of technology. Each of these trends offers exciting opportunities and challenges that will likely have a significant impact on society, economy, and beyond.\n",
       "\n",
       "Do you have a particular interest in any of these technology trends, or is there a specific aspect you would like to discuss further?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I find all of these technology trends to be incredibly intriguing and important for the future. If you would like to delve deeper into any of these areas, I would be happy to provide more information or discuss specific aspects of interest.\n",
       "\n",
       "Whether you have questions about how these technologies work, their potential applications, current challenges, or future implications, feel free to let me know. I'm here to help facilitate a deeper understanding of these exciting developments in the world of technology."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for your thoughtful response! Given your interest and knowledge in these technology trends, let's delve deeper into the topic of artificial intelligence (AI) and its applications. AI has the potential to transform various industries and sectors, impacting everything from healthcare and finance to transportation and education.\n",
       "\n",
       "One particularly promising area within AI is machine learning, which focuses on developing algorithms and models that enable computers to learn from and make predictions based on data. Machine learning is being used in fields such as natural language processing, computer vision, recommendation systems, and more.\n",
       "\n",
       "If you have any specific questions or want to explore a particular aspect of AI and machine learning further, please feel free to share. I'm here to provide more insights and information on this exciting technology trend!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_responses(best_chats(dataset)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Parent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[216], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m children(\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[214], line 2\u001b[0m, in \u001b[0;36mchildren\u001b[0;34m(n, dataset)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchildren\u001b[39m(n, dataset\u001b[38;5;241m=\u001b[39mdataset):\n\u001b[0;32m----> 2\u001b[0m     filtered_dataset \u001b[38;5;241m=\u001b[39m dataset[dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m n)]\n\u001b[1;32m      3\u001b[0m     ch \u001b[38;5;241m=\u001b[39m filtered_dataset\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ch\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[214], line 2\u001b[0m, in \u001b[0;36mchildren.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchildren\u001b[39m(n, dataset\u001b[38;5;241m=\u001b[39mdataset):\n\u001b[0;32m----> 2\u001b[0m     filtered_dataset \u001b[38;5;241m=\u001b[39m dataset[dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m n)]\n\u001b[1;32m      3\u001b[0m     ch \u001b[38;5;241m=\u001b[39m filtered_dataset\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ch\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Parent'"
     ]
    }
   ],
   "source": [
    "children(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Parent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[208], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(children(parent(\u001b[38;5;241m1\u001b[39m)))\n",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m, in \u001b[0;36mchildren\u001b[0;34m(n, dataset)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchildren\u001b[39m(n, dataset\u001b[38;5;241m=\u001b[39mdataset):\n\u001b[0;32m----> 2\u001b[0m     filtered_dataset \u001b[38;5;241m=\u001b[39m dataset[dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m n)]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_dataset\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_list()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m, in \u001b[0;36mchildren.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchildren\u001b[39m(n, dataset\u001b[38;5;241m=\u001b[39mdataset):\n\u001b[0;32m----> 2\u001b[0m     filtered_dataset \u001b[38;5;241m=\u001b[39m dataset[dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m n)]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_dataset\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_list()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Parent'"
     ]
    }
   ],
   "source": [
    "len(children(parent(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 31, 32, 33, 34],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       " [0, 1, 22],\n",
       " [0, 1, 2, 23],\n",
       " [0, 1, 2, 3, 4, 25],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 29],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 30]]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_chats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_chats(dataset=dataset):\n",
    "    best_chats = []\n",
    "    best_responses = set(dataset[(dataset[\"Choice\"] != \"No\")].index)\n",
    "    ancestor_responses = set()\n",
    "    for n in best_responses:\n",
    "        ancestor_responses = ancestor_responses.union(ancestors(n))\n",
    "    best_chats_ends = best_responses.difference(ancestor_responses)\n",
    "    for chat_end in best_chats_ends:\n",
    "        chat = ancestors(chat_end)\n",
    "        chat.append(chat_end)\n",
    "        best_chats.append(chat)\n",
    "    return best_chats\n",
    "    \n",
    "                                \n",
    "    #(dataset[\"Data\"].apply(lambda x: len(x[\"Full message\"])) == level + 1) &\n",
    "    #(dataset.apply(lambda x: is_parent(msg,x[\"Data\"][\"Full message\"],x[\"Response1\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataset[\"Response1\"]:\n",
    "    display_markdown(entry, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset.iloc[30]\n",
    "for text in test:\n",
    "        display_markdown(text, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[30,\"Choice\"] = \"Maybe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset[dataset[\"Choice\"]==\"Yes\"]#.iloc[0]\n",
    "for row in test.iterrows():\n",
    "        display_markdown(row[0], raw=True)\n",
    "        display_markdown(row[1].iloc[1], raw=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fdbe172e46cfba2329a5e8d5b64cdf2d12f4dfd7d9bcea153ecef62d1d51933b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
