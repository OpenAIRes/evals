{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a BATTLE Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"dataset\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "choices = \"user\"                     # options: user, ai\n",
    "num_few_shot = 4\n",
    "initial_message = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "roles = \"user\"                      # options: system-user, system, user\n",
    "battles_generation = \"dense\"        # options: dense, only-new\n",
    "\n",
    "#!cd evals\n",
    "#!git lfs fetch --all\n",
    "#!git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "client = OpenAI()\n",
    "#import datetime\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "#api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Install Evals if you haven't already\n",
    "# %pip install -e ../.\n",
    "# pip install --upgrade openai\n",
    "# %pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths. Assuming this notebook is in examples/\n",
    "\n",
    "evals_path = os.path.join(os.getcwd(), \"..\", \"evals\")\n",
    "\n",
    "registry_path = os.path.join(evals_path, \"registry\", \"evals\", \"battles.yaml\")\n",
    "\n",
    "data_path = os.path.join(evals_path, \"registry\", \"data\", \"battles\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "data_path = os.path.join(data_path, \"samples.jsonl\")\n",
    "\n",
    "json_logs_path = os.path.join(os.getcwd(), \"logs\")\n",
    "os.makedirs(json_logs_path, exist_ok=True)\n",
    "json_logs_path = os.path.join(json_logs_path, \"logs\")\n",
    "\n",
    "df_path = os.path.join(evals_path, \"evallogs\", \"df\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "dataset_path = os.path.join(df_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registry yaml\n",
    "\n",
    "registry_yaml = {}\n",
    "\n",
    "registry_yaml[\"battles\"] = {\n",
    "    \"id\": \"battles.test.v1\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}\n",
    "registry_yaml[\"battles.test.v1\"] = {\n",
    "    \"class\": \"evals.elsuite.modelgraded.classify:ModelBasedClassify\",\n",
    "    \"args\": {\n",
    "        \"samples_jsonl\": \"battles/samples.jsonl\",\n",
    "        \"eval_type\": \"cot_classify\",\n",
    "        \"modelgraded_spec\": \"battle\"\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(registry_path), \"w\") as f:\n",
    "    yaml.dump(registry_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "try:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset = pd.read_json(f, lines=True)\n",
    "    if dataset.iloc[-1][\"Choice\"] == \"No\":\n",
    "        best_content = dataset.iloc[-1][\"Instruction2\"]\n",
    "        best_response = dataset.iloc[-1][\"Response2\"]\n",
    "    else:\n",
    "        best_content = dataset.iloc[-1][\"Instruction1\"]\n",
    "        best_response = dataset.iloc[-1][\"Response1\"]\n",
    "    best_message = [{\"role\": \"user\", \"content\": best_content}]\n",
    "\n",
    "# Or create new data file\n",
    "\n",
    "except FileNotFoundError:\n",
    "    dataset = []\n",
    "    dataset = pd.DataFrame(dataset, columns=['Instruction1', 'Response1', 'Instruction2', 'Response2', 'Sampled', 'Choice', 'Data'])\n",
    "    best_message = initial_message\n",
    "    best_response = client.chat.completions.create(\n",
    "        messages = initial_message,\n",
    "        model = model,\n",
    "        ).choices[0].message.content\n",
    "    \n",
    "candidate_messages = [best_message]\n",
    "next_candidate_messages = []\n",
    "generation_distance = 0\n",
    "message_in_candidate_messages = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "def battle(best_message, best_response, candidate_message):\n",
    "\n",
    "    dataset = [{\"input1\": candidate_message, \"input2\": best_message, \"completion2\":best_response}]\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_json(data_path, orient=\"records\", lines=True)\n",
    "\n",
    "    !oaieval gpt-3.5-turbo battles --record_path logs/logs\n",
    "    \n",
    "    with open(json_logs_path, \"r\") as f:\n",
    "        df = pd.read_json(f, lines=True)\n",
    "\n",
    "    #current_time = datetime.datetime.now()\n",
    "    #formatted_time = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #df.to_json(os.path.join(df_path, formatted_time), lines=True, orient=\"records\")\n",
    "\n",
    "    instruction1 = candidate_message[-1][\"content\"]\n",
    "    instruction2 = best_message[-1][\"content\"]\n",
    "\n",
    "    battle_prompt_content = df[\"data\"].iloc[-2][\"prompt\"][0][\"content\"]\n",
    "    response1 = battle_prompt_content.split(\"\\n[Response 1]\\n\",)[1].split(\"\\n\\n[Instruction 2]\\n\")[0]\n",
    "    response1 = response1.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    response2 = battle_prompt_content.split(\"\\n[Response 2]\\n\",)[1].split(\"\\n\\n\\nIs the first response better than the second?\")[0]\n",
    "    response2 = response2.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    print(f\"Response1: {response1}\")\n",
    "    #print(f\"response2: {response2}\")\n",
    "\n",
    "    sampled = df[\"data\"].iloc[-2][\"sampled\"][0]\n",
    "\n",
    "    choice = df[\"data\"].iloc[-1][\"choice\"]\n",
    "\n",
    "    data = {'Instruction1': instruction1, 'Response1': response1, 'Instruction2': instruction2, 'Response2': response2, 'Sampled': sampled, 'Choice': choice, 'Data': {}}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = df.to_dict()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_system_and_user(message):\n",
    "    new_message = []\n",
    "    if message[0][\"role\"] == \"system\":\n",
    "        new_message.append([{\"role\": \"user\", \"content\": message[0][\"content\"]}])\n",
    "    else:\n",
    "        new_message.append([{\"role\": \"system\", \"content\": message[0][\"content\"]}])\n",
    "    return new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parents(content, dataset):\n",
    "    #print (f\"finding parents {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Response1\"] == content]\n",
    "    parents = dataset[\"Instruction1\"].unique()\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_children(content, dataset):\n",
    "    #print (f\"finding children {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Instruction1\"] == content]\n",
    "    children = dataset[\"Response1\"].unique()\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_candidate_messages(dataset, best_message, generation_distance, roles):\n",
    "    best_content = best_message[-1][\"content\"]\n",
    "    last = [best_content]\n",
    "    list_of_contents = [best_content]\n",
    "\n",
    "    next = []\n",
    "    for i in range(generation_distance):\n",
    "        #print (f\"starting level {i}, generation distance {generation_distance}\")\n",
    "        for content in last:\n",
    "            #print(f\"last_up: {last_up}, now {content}\")\n",
    "            next.extend(find_parents(content, dataset))\n",
    "            next.extend(find_children(content, dataset))\n",
    "            \n",
    "        #print (f\"behind for loops\")\n",
    "        list_of_contents.extend(next)\n",
    "        last = next.copy()\n",
    "        #print(f\"endind level {i}\")\n",
    "        \n",
    "    list_of_contents = pd.array(list_of_contents).unique().tolist()\n",
    "    \n",
    "    #best_message_index = list_of_contents.index(best_message[0][content])\n",
    "    #start = max(best_message_index - generation_distance, 0)\n",
    "    #stop = min(len(list_of_contents))\n",
    "    #stop = len(list_of_contents) - 1\n",
    "\n",
    "    messages = []\n",
    "    for content in list_of_contents:\n",
    "        if roles == \"system-user\" or \"user\":\n",
    "            messages.append([{\"role\":\"user\",\"content\":content}])\n",
    "        if (roles == \"system-user\") or (roles == \"system\"):\n",
    "            print(\"Creating message without user role.\")\n",
    "            messages.append([{\"role\":\"system\",\"content\":content}])\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_x_shot_prompt(dataset,message,num_few_shot):\n",
    "    few_shot_prompt = []\n",
    "    for _, key_battle in dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-num_few_shot:].iterrows():\n",
    "        few_shot_prompt.append({\"role\": \"system\", \"content\": key_battle[\"Instruction1\"], \"name\": \"example_user\"})\n",
    "        few_shot_prompt.append({\"role\": \"system\", \"content\": key_battle[\"Response1\"], \"name\": \"example_assistant\"})\n",
    "    message = few_shot_prompt + message\n",
    "    return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choices == \"user\":\n",
    "\n",
    "    prompt = \"You are comparing two responses to the following two instructions.\"\n",
    "\n",
    "    prompt += \"\\n\\n[Instruction 1]\\n\"\n",
    "    prompt += candidate_message[-1][\"content\"]\n",
    "\n",
    "    prompt += \"\\n\\n[Response 1]\\n\"\n",
    "    if message_in_candidate_messages <= len(candidate_messages):\n",
    "        candidate_message = candidate_messages[message_in_candidate_messages]\n",
    "        message_in_candidate_messages += 1\n",
    "    else:\n",
    "        if battles_generation == \"dense\":\n",
    "            candidate_messages = list_candidate_messages(dataset, best_message, generation_distance, roles)\n",
    "            generation_distance += 1\n",
    "            candidate_message = candidate_messages[0]\n",
    "            message_in_candidate_messages = 1\n",
    "            print(f\"candidate messages listed, generation distance: {generation_distance}, number of candidate messages: {len(candidate_messages)}\")\n",
    "        else:\n",
    "            print(\"Code not completed!\")\n",
    "    completion = client.chat.completions.create(\n",
    "        messages = candidate_message,\n",
    "        model = model,\n",
    "        )\n",
    "    response1 = completion.choices[0].message.content\n",
    "    prompt += response1\n",
    "    \n",
    "    prompt += \"\\n\\n[Instruction 2]\\n\"\n",
    "    prompt += best_message[-1][\"content\"]\n",
    "\n",
    "    prompt += \"\\n\\n[Response 2]\\n\"\n",
    "    prompt += best_response\n",
    "\n",
    "    prompt += \"\\n\\n\\nIs the first response better than the second? You must provide one answer based on your subjective view.\"\n",
    "\n",
    "    data = {'Instruction1': candidate_message[-1][\"content\"], 'Response1': response1, 'Instruction2': best_message[-1][\"content\"], 'Response2': best_response, 'Sampled': {}, 'Choice': \"\", 'Data': {}}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = completion.to_dict()\n",
    "\n",
    "    display_markdown(prompt, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = \"No\"\n",
    "#choice = \"Yes\"\n",
    "data.at[0, \"Data\"] = choice\n",
    "if choice == \"Yes\":\n",
    "    best_message = candidate_message\n",
    "    best_response = data[\"Response1\"].iloc[0]\n",
    "    print(f\"New best message and response!\")\n",
    "    if battles_generation == \"dense\":\n",
    "        generation_distance = 0\n",
    "dataset = pd.concat([dataset, data],ignore_index=True)\n",
    "dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-10 10:23:15,386] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-10 10:23:16,645] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-10 10:23:16,647] [oaieval.py:215] \u001b[1;35mRun started: 24081008231646NWPOLA\u001b[0m\n",
      "[2024-08-10 10:23:16,649] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-10 10:23:16,674] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-10 10:23:16,674] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-10 10:23:16,675] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-10 10:23:16,688] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "[2024-08-10 10:23:19,313] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-10 10:23:19,313] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 139\n",
      "prompt_tokens: 545\n",
      "total_tokens: 684\n",
      "[2024-08-10 10:23:19,315] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 139, 'usage_prompt_tokens': 545, 'usage_total_tokens': 684}. Logged to logs/logs\n",
      "[2024-08-10 10:23:19,316] [oaieval.py:233] Final report:\n",
      "[2024-08-10 10:23:19,316] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-10 10:23:19,316] [oaieval.py:235] score: 0.0\n",
      "[2024-08-10 10:23:19,316] [oaieval.py:235] usage_completion_tokens: 139\n",
      "[2024-08-10 10:23:19,316] [oaieval.py:235] usage_prompt_tokens: 545\n",
      "[2024-08-10 10:23:19,316] [oaieval.py:235] usage_total_tokens: 684\n",
      "[2024-08-10 10:23:19,325] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=6.454ms\n",
      "Response1: Thank you for offering your help! If you have any questions or need assistance with anything, feel free to ask. I'm here to help you.\n",
      "Instruction1: Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\n",
      "[2024-08-10 10:23:22,645] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-10 10:23:23,516] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-10 10:23:23,518] [oaieval.py:215] \u001b[1;35mRun started: 240810082323GE3WZFRD\u001b[0m\n",
      "[2024-08-10 10:23:23,519] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-10 10:23:23,546] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-10 10:23:23,547] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-10 10:23:23,547] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-10 10:23:23,563] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "[2024-08-10 10:23:25,829] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-10 10:23:25,830] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 103\n",
      "prompt_tokens: 520\n",
      "total_tokens: 623\n",
      "[2024-08-10 10:23:25,830] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 103, 'usage_prompt_tokens': 520, 'usage_total_tokens': 623}. Logged to logs/logs\n",
      "[2024-08-10 10:23:25,831] [oaieval.py:233] Final report:\n",
      "[2024-08-10 10:23:25,831] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-10 10:23:25,831] [oaieval.py:235] score: 0.0\n",
      "[2024-08-10 10:23:25,831] [oaieval.py:235] usage_completion_tokens: 103\n",
      "[2024-08-10 10:23:25,831] [oaieval.py:235] usage_prompt_tokens: 520\n",
      "[2024-08-10 10:23:25,831] [oaieval.py:235] usage_total_tokens: 623\n",
      "[2024-08-10 10:23:25,834] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.108ms\n",
      "Response1: I'm here to assist you! If you have any questions, need help with a task, or just want to chat, feel free to let me know. How can I assist you today?\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-10 10:23:27,805] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-10 10:23:28,586] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-10 10:23:28,588] [oaieval.py:215] \u001b[1;35mRun started: 240810082328J3TJ66BU\u001b[0m\n",
      "[2024-08-10 10:23:28,589] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-10 10:23:28,617] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-10 10:23:28,617] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-10 10:23:28,618] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-10 10:23:28,639] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "[2024-08-10 10:23:30,936] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-10 10:23:30,937] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 102\n",
      "prompt_tokens: 568\n",
      "total_tokens: 670\n",
      "[2024-08-10 10:23:30,938] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 102, 'usage_prompt_tokens': 568, 'usage_total_tokens': 670}. Logged to logs/logs\n",
      "[2024-08-10 10:23:30,938] [oaieval.py:233] Final report:\n",
      "[2024-08-10 10:23:30,938] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-10 10:23:30,938] [oaieval.py:235] score: 0.0\n",
      "[2024-08-10 10:23:30,938] [oaieval.py:235] usage_completion_tokens: 102\n",
      "[2024-08-10 10:23:30,938] [oaieval.py:235] usage_prompt_tokens: 568\n",
      "[2024-08-10 10:23:30,938] [oaieval.py:235] usage_total_tokens: 670\n",
      "[2024-08-10 10:23:30,942] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.604ms\n",
      "Response1: Thank you for your kind offer! I appreciate your willingness to assist. If I have any questions or need help, I'll be sure to reach out to you. Let's work together to make this conversation productive and enjoyable.\n",
      "Instruction1: Thank you for offering your help! If you have any questions or need assistance with anything, feel free to ask. I'm here to help you.\n",
      "all done, generation distance: 3, number of candidate messages: 6\n"
     ]
    }
   ],
   "source": [
    "if choices == \"ai\":\n",
    "    for candidate_message in candidate_messages:\n",
    "        if num_few_shot > 0:\n",
    "            candidate_message = make_x_shot_prompt(dataset,candidate_message,num_few_shot)\n",
    "        data = battle(best_message, best_response, candidate_message)\n",
    "        dataset = pd.concat([dataset, data],ignore_index=True)\n",
    "        dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "        if data[\"Choice\"].iloc[0] == \"Yes\":\n",
    "            best_message = candidate_message\n",
    "            best_response = data[\"Response1\"].iloc[0]\n",
    "            print(f\"New best message:{best_message}\")\n",
    "            if battles_generation == \"dense\":\n",
    "                generation_distance = 0\n",
    "\n",
    "        print(f\"Instruction1: {candidate_message[-1][\"content\"]}\")\n",
    "\n",
    "        if battles_generation == \"only-new\":\n",
    "            new_message = [{\"role\": candidate_message[0][\"role\"], \"content\":data[\"Response1\"].iloc[0]}]\n",
    "            if new_message not in next_candidate_messages:\n",
    "                next_candidate_messages.append(new_message)\n",
    "                if roles == \"system-user\":\n",
    "                    next_candidate_messages.append(switch_system_and_user(new_message))\n",
    "\n",
    "    if battles_generation == \"only-new\":\n",
    "        candidate_messages = next_candidate_messages\n",
    "        next_candidate_messages = []\n",
    "    if battles_generation == \"dense\":\n",
    "        #print(\"going to list candidate messages\")\n",
    "        candidate_messages = list_candidate_messages(dataset, best_message, generation_distance, roles)\n",
    "        generation_distance += 1\n",
    "        #print(\"candidate messages listed\")\n",
    "    print(f\"all done, generation distance: {generation_distance}, number of candidate messages: {len(candidate_messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for offering your help! If you have any questions or need assistance with anything, feel free to ask. I'm here to help you."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. The first response acknowledges the offer of help and expresses gratitude, creating a positive interaction.\n",
       "2. The first response also reiterates the willingness to assist and encourages the user to ask for help if needed.\n",
       "3. The second response is more direct and simply asks how the assistant can assist without acknowledging the initial offer of help.\n",
       "\n",
       "Based on the above points, the first response is better than the second.\n",
       "\n",
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for entry in dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-1].drop(\"Data\"):\n",
    "    display_markdown(entry, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instruction1</th>\n",
       "      <th>Response1</th>\n",
       "      <th>Instruction2</th>\n",
       "      <th>Response2</th>\n",
       "      <th>Sampled</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Response 1 provides a more personalized and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Response 1 provides a more detailed and pro...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses start with a friendly greeti...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Response 1 provides a more proactive and he...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses start with a friendly greeti...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>Thank you for offering your help! If you have ...</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. The first response acknowledges the offer o...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>Thank you for offering your help! If you have ...</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>Thank you for offering your help! If you have ...</td>\n",
       "      <td>1. Both responses are very similar in content ...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Instruction1  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                  Hello! How can I assist you today?   \n",
       "4                                                       \n",
       "5                  Hello! How can I assist you today?   \n",
       "6   Hello! I'm here to help with any questions or ...   \n",
       "7                                                       \n",
       "8                  Hello! How can I assist you today?   \n",
       "9   Hello! I'm here to help with any questions or ...   \n",
       "10  Hello! I'm here to help with any questions or ...   \n",
       "11  Hello! I'm here to help with any questions or ...   \n",
       "\n",
       "                                            Response1  \\\n",
       "0                  Hello! How can I assist you today?   \n",
       "1                  Hello! How can I assist you today?   \n",
       "2                  Hello! How can I assist you today?   \n",
       "3   Hello! I'm here to help with any questions or ...   \n",
       "4                  Hello! How can I assist you today?   \n",
       "5   Hello! I'm here to help with any questions or ...   \n",
       "6                  Hello! How can I assist you today?   \n",
       "7                  Hello! How can I assist you today?   \n",
       "8   Hello! I'm here to help with any questions or ...   \n",
       "9                  Hello! How can I assist you today?   \n",
       "10  Thank you for offering your help! If you have ...   \n",
       "11  Thank you for offering your help! If you have ...   \n",
       "\n",
       "                                         Instruction2  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "5                                                       \n",
       "6                                                       \n",
       "7                                                       \n",
       "8                                                       \n",
       "9                                                       \n",
       "10  Hello! I'm here to help with any questions or ...   \n",
       "11  Hello! I'm here to help with any questions or ...   \n",
       "\n",
       "                                            Response2  \\\n",
       "0                  Hello! How can I assist you today?   \n",
       "1                  Hello! How can I assist you today?   \n",
       "2                  Hello! How can I assist you today?   \n",
       "3                  Hello! How can I assist you today?   \n",
       "4                  Hello! How can I assist you today?   \n",
       "5                  Hello! How can I assist you today?   \n",
       "6                  Hello! How can I assist you today?   \n",
       "7                  Hello! How can I assist you today?   \n",
       "8                  Hello! How can I assist you today?   \n",
       "9                  Hello! How can I assist you today?   \n",
       "10                 Hello! How can I assist you today?   \n",
       "11  Thank you for offering your help! If you have ...   \n",
       "\n",
       "                                              Sampled Choice  \\\n",
       "0   1. Both responses are identical in content and...     No   \n",
       "1   1. Both responses are identical in content and...     No   \n",
       "2   1. Both responses are identical in content and...     No   \n",
       "3   1. Response 1 provides a more personalized and...     No   \n",
       "4   1. Both responses are identical in content and...     No   \n",
       "5   1. Response 1 provides a more detailed and pro...     No   \n",
       "6   1. Both responses start with a friendly greeti...     No   \n",
       "7   1. Both responses are identical in content and...     No   \n",
       "8   1. Response 1 provides a more proactive and he...     No   \n",
       "9   1. Both responses start with a friendly greeti...    Yes   \n",
       "10  1. The first response acknowledges the offer o...    Yes   \n",
       "11  1. Both responses are very similar in content ...     No   \n",
       "\n",
       "                                                 Data  \n",
       "0   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "1   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "2   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "3   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "4   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "5   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "6   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "7   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "8   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "9   {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "10  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "11  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  "
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user',\n",
       "   'content': \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\"}],\n",
       " [{'role': 'user', 'content': 'Hello! How can I assist you today?'}],\n",
       " [{'role': 'user',\n",
       "   'content': \"Thank you for offering your help! If you have any questions or need assistance with anything, feel free to ask. I'm here to help you.\"}]]"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1. Both responses are identical in content and structure.\\n2. There is no distinguishable difference between the two responses.\\n3. Both responses follow the same format and tone.\\n\\nNo\\n\\nNo',\n",
       "       '1. Both responses are identical in content and structure.\\n2. There is no distinguishable difference between the two responses.\\n3. Therefore, neither response is better than the other.\\n\\nNo\\n\\nNo',\n",
       "       '1. Response 1 provides a more personalized and proactive approach by stating that the person is there to help with any questions or tasks.\\n2. Response 2 is more generic and does not offer any specific assistance right away.\\n\\nNo\\n\\nNo',\n",
       "       '1. Response 1 provides a more detailed and proactive offer of assistance compared to Response 2, which is more generic.\\n2. Response 1 shows a willingness to help with any questions or tasks, making it more customer-focused.\\n3. Response 2 is a bit more abrupt and lacks the same level of engagement as Response 1.\\n\\nNo\\nNo',\n",
       "       '1. Both responses start with a friendly greeting, \"Hello!\"\\n2. Response 1 includes the phrase \"I\\'m here to help with any questions or tasks you may have,\" which shows a proactive approach to assisting.\\n3. Response 2 skips the additional information and directly asks how they can assist, which is more concise.\\n\\nBased on the additional information provided in Response 1, it can be considered slightly better than Response 2.\\n\\nNo\\n\\nNo',\n",
       "       '1. Response 1 provides a more proactive and helpful tone by offering to assist with any questions or tasks the person may have.\\n2. Response 2 is more passive and simply asks how they can assist without offering any specific help upfront.\\n\\nNo\\nNo',\n",
       "       '1. Both responses start with a friendly greeting, \"Hello!\"\\n2. Response 1 includes the phrase \"I\\'m here to help with any questions or tasks you may have,\" which shows a proactive approach to assisting.\\n3. Response 2 skips the additional information and directly asks how they can assist, which is more concise.\\n\\nBased on the additional information provided in Response 1, it can be considered better than Response 2.\\n\\nYes\\n\\nYes',\n",
       "       '1. The first response acknowledges the offer of help and expresses gratitude, creating a positive interaction.\\n2. The first response also reiterates the willingness to assist and encourages the user to ask for help if needed.\\n3. The second response is more direct and simply asks how the assistant can assist without acknowledging the initial offer of help.\\n\\nBased on the above points, the first response is better than the second.\\n\\nYes',\n",
       "       \"1. Both responses are very similar in content and tone, expressing gratitude for the offer of help and willingness to assist with any questions or tasks.\\n2. The wording in both responses is polite and professional, making the user feel welcomed and supported.\\n3. There is no significant difference in the effectiveness or appropriateness of the responses, as they both fulfill the purpose of acknowledging the user's offer to help and providing assistance.\\n\\nNo\",\n",
       "       '1. Both responses are very similar in content, with the only difference being the wording of the initial thank you message.\\n2. The first response uses the phrase \"Thank you for offering your help!\" which may come across as more polite and appreciative compared to the second response.\\n3. The second response is more direct and to the point, simply stating \"I\\'m here to help you\" without the initial thank you message.\\n4. Overall, the first response may create a slightly warmer and more welcoming tone compared to the second response.\\n\\nNo',\n",
       "       \"1. Response 1 is more detailed and personalized compared to Response 2.\\n2. Response 1 acknowledges the user's offer to help and provides multiple options for assistance, making it more engaging.\\n3. Response 2 is a generic thank you message without any specific offer of assistance or engagement with the user.\\n\\nNo\",\n",
       "       '1. The first response includes additional expressions of gratitude and willingness to work together, which can help establish a positive and collaborative tone in the conversation.\\n2. The second response is more straightforward and to the point, lacking the extra elements of appreciation and collaboration present in the first response.\\n\\nNo'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Sampled\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fdbe172e46cfba2329a5e8d5b64cdf2d12f4dfd7d9bcea153ecef62d1d51933b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
