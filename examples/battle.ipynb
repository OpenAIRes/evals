{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a BATTLE Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = True\n",
    "initial_message = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "battles_generation = \"dense\"      # methods: dense, only-new\n",
    "roles = \"system-user\"             # methods: system-user, system, user\n",
    "\n",
    "#!cd evals\n",
    "#!git lfs fetch --all\n",
    "#!git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import yaml\n",
    "#import datetime\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "#api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n",
    "\n",
    "# Install Evals if you haven't already\n",
    "# %pip install -e ../.\n",
    "# pip install --upgrade openai\n",
    "# %pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths. Assuming this notebook is in examples/\n",
    "\n",
    "evals_path = os.path.join(os.getcwd(), \"..\", \"evals\")\n",
    "\n",
    "registry_path = os.path.join(evals_path, \"registry\", \"evals\", \"battles.yaml\")\n",
    "\n",
    "data_path = os.path.join(evals_path, \"registry\", \"data\", \"battles\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "data_path = os.path.join(data_path, \"samples.jsonl\")\n",
    "\n",
    "json_logs_path = os.path.join(os.getcwd(), \"logs\")\n",
    "os.makedirs(json_logs_path, exist_ok=True)\n",
    "json_logs_path = os.path.join(json_logs_path, \"logs\")\n",
    "\n",
    "df_path = os.path.join(evals_path, \"evallogs\", \"df\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "dataset_path = os.path.join(df_path, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registry yaml\n",
    "\n",
    "registry_yaml = {}\n",
    "\n",
    "registry_yaml[\"battles\"] = {\n",
    "    \"id\": \"battles.test.v1\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}\n",
    "registry_yaml[\"battles.test.v1\"] = {\n",
    "    \"class\": \"evals.elsuite.modelgraded.classify:ModelBasedClassify\",\n",
    "    \"args\": {\n",
    "        \"samples_jsonl\": \"battles/samples.jsonl\",\n",
    "        \"eval_type\": \"cot_classify\",\n",
    "        \"modelgraded_spec\": \"battle\"\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(registry_path), \"w\") as f:\n",
    "    yaml.dump(registry_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data\n",
    "if new:\n",
    "    dataset = ()\n",
    "    dataset = pd.DataFrame(dataset, columns=['Instruction1', 'Response1', 'Instruction2', 'Response2', 'Sampled',\n",
    "       'Choice', 'Data'])\n",
    "    best_message = initial_message\n",
    "    best_response = client.chat.completions.create(\n",
    "        messages = initial_message,\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        ).choices[0].message.content\n",
    "else:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset = pd.read_json(f, lines=True)\n",
    "    if dataset.iloc[-1][\"Choice\"] == \"No\":\n",
    "        best_content = dataset.iloc[-1][\"Instruction2\"]\n",
    "        best_response = dataset.iloc[-1][\"Response2\"]\n",
    "    else:\n",
    "        best_content = dataset.iloc[-1][\"Instruction1\"]\n",
    "        best_response = dataset.iloc[-1][\"Response1\"]\n",
    "    best_message = [{\"role\": \"user\", \"content\": best_content}]\n",
    "candidate_messages = [best_message]\n",
    "next_candidate_messages = []\n",
    "generation_distance = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def battle(best_message, best_response, candidate_message):\n",
    "\n",
    "    dataset = [{\"input1\": candidate_message, \"input2\": best_message, \"completion2\":best_response}]\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_json(data_path, orient=\"records\", lines=True)\n",
    "\n",
    "    !oaieval gpt-3.5-turbo battles --record_path logs/logs\n",
    "    \n",
    "    with open(json_logs_path, \"r\") as f:\n",
    "        df = pd.read_json(f, lines=True)\n",
    "\n",
    "    #current_time = datetime.datetime.now()\n",
    "    #formatted_time = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #df.to_json(os.path.join(df_path, formatted_time), lines=True, orient=\"records\")\n",
    "\n",
    "    instruction1 = candidate_message[0][\"content\"]\n",
    "    instruction2 = best_message[0][\"content\"]\n",
    "\n",
    "    battle_prompt_content = df[\"data\"].iloc[-2][\"prompt\"][0][\"content\"]\n",
    "    response1 = battle_prompt_content.split(\"\\n[Response 1]\\n\",)[1].split(\"\\n\\n[Instruction 2]\\n\")[0]\n",
    "    response1 = response1.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    response2 = battle_prompt_content.split(\"\\n[Response 2]\\n\",)[1].split(\"\\n\\n\\nIs the first response better than the second?\")[0]\n",
    "    response2 = response2.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    print(f\"Response1: {response1}\")\n",
    "    #print(f\"response2: {response2}\")\n",
    "\n",
    "    sampled = df[\"data\"].iloc[-2][\"sampled\"][0]\n",
    "\n",
    "    choice = df[\"data\"].iloc[-1][\"choice\"]\n",
    "\n",
    "    data = {'Instruction1': instruction1, 'Response1': response1, 'Instruction2': instruction2, 'Response2': response2, 'Sampled': sampled, 'Choice': choice, 'Data': {}}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = df.to_dict()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_system_and_user(message):\n",
    "    new_message = []\n",
    "    if message[0][\"role\"] == \"system\":\n",
    "        new_message.append([{\"role\": \"user\", \"content\": message[0][\"content\"]}])\n",
    "    else:\n",
    "        new_message.append([{\"role\": \"system\", \"content\": message[0][\"content\"]}])\n",
    "    return new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parents(content, dataset):\n",
    "    print (f\"finding parents {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Response1\"] == content]\n",
    "    parents = dataset[\"Instruction1\"].unique()\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_children(content, dataset):\n",
    "    print (f\"finding children {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Instruction1\"] == content]\n",
    "    children = dataset[\"Response1\"].unique()\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_candidate_messages(dataset, best_message, generation_distance):\n",
    "    best_content = best_message[0][\"content\"]\n",
    "    last = [best_content]\n",
    "    list_of_contents = [best_content]\n",
    "\n",
    "    next = []\n",
    "    for i in range(generation_distance):\n",
    "        print (f\"starting level {i}, generation distance {generation_distance}\")\n",
    "        for content in last:\n",
    "            #print(f\"last_up: {last_up}, now {content}\")\n",
    "            next.extend(find_parents(content, dataset))\n",
    "            next.extend(find_children(content, dataset))\n",
    "            \n",
    "        print (f\"behind for loops\")\n",
    "        list_of_contents.extend(next)\n",
    "        last = next.copy()\n",
    "        print(f\"endind level {i}\")\n",
    "        \n",
    "    list_of_contents = pd.array(list_of_contents).unique().tolist()\n",
    "    \n",
    "    #best_message_index = list_of_contents.index(best_message[0][content])\n",
    "    #start = max(best_message_index - generation_distance, 0)\n",
    "    #stop = min(len(list_of_contents))\n",
    "    #stop = len(list_of_contents) - 1\n",
    "\n",
    "    messages = []\n",
    "    for content in list_of_contents:\n",
    "        if roles == \"system-user\" or \"user\":\n",
    "            messages.append([{\"role\":\"user\",\"content\":content}])\n",
    "        if roles == \"system-user\" or \"system\":\n",
    "            messages.append([{\"role\":\"system\",\"content\":content}])\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-09 10:53:16,649] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:53:18,629] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:53:18,635] [oaieval.py:215] \u001b[1;35mRun started: 240809085318JOWMY25E\u001b[0m\n",
      "[2024-08-09 10:53:18,637] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:53:18,675] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:53:18,675] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:53:18,676] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:53:18,702] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "[2024-08-09 10:53:21,140] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:53:21,140] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 100\n",
      "prompt_tokens: 285\n",
      "total_tokens: 385\n",
      "[2024-08-09 10:53:21,140] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 100, 'usage_prompt_tokens': 285, 'usage_total_tokens': 385}. Logged to logs/logs\n",
      "[2024-08-09 10:53:21,141] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:53:21,141] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:53:21,141] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:53:21,141] [oaieval.py:235] usage_completion_tokens: 100\n",
      "[2024-08-09 10:53:21,141] [oaieval.py:235] usage_prompt_tokens: 285\n",
      "[2024-08-09 10:53:21,141] [oaieval.py:235] usage_total_tokens: 385\n",
      "[2024-08-09 10:53:21,144] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.651ms\n",
      "Response1: If you have any questions or concerns about your order, feel free to ask and I will do my best to provide you with the information you need.\n",
      "Instruction1: Of course! I'd be happy to help. Please provide me with your order number and any specific details about your question so I can assist you further.\n",
      "[2024-08-09 10:53:23,693] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:53:25,679] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:53:25,681] [oaieval.py:215] \u001b[1;35mRun started: 2408090853252K2LJAIE\u001b[0m\n",
      "[2024-08-09 10:53:25,683] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:53:25,714] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:53:25,715] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:53:25,715] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:53:25,744] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "[2024-08-09 10:53:28,289] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:53:28,289] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 131\n",
      "prompt_tokens: 285\n",
      "total_tokens: 416\n",
      "[2024-08-09 10:53:28,290] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 131, 'usage_prompt_tokens': 285, 'usage_total_tokens': 416}. Logged to logs/logs\n",
      "[2024-08-09 10:53:28,290] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:53:28,290] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:53:28,290] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:53:28,290] [oaieval.py:235] usage_completion_tokens: 131\n",
      "[2024-08-09 10:53:28,290] [oaieval.py:235] usage_prompt_tokens: 285\n",
      "[2024-08-09 10:53:28,290] [oaieval.py:235] usage_total_tokens: 416\n",
      "[2024-08-09 10:53:28,294] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.846ms\n",
      "Response1: Sure, I can help you with that. Please provide me with your order number and any specific details about your question so I can assist you further.\n",
      "Instruction1: Of course! I'd be happy to help. Please provide me with your order number and any specific details about your question so I can assist you further.\n",
      "[2024-08-09 10:53:31,994] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:53:32,784] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:53:32,789] [oaieval.py:215] \u001b[1;35mRun started: 240809085332JXV5AMGD\u001b[0m\n",
      "[2024-08-09 10:53:32,792] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:53:32,827] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:53:32,827] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:53:32,827] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:53:32,839] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "[2024-08-09 10:53:35,048] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:53:35,048] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 110\n",
      "prompt_tokens: 255\n",
      "total_tokens: 365\n",
      "[2024-08-09 10:53:35,049] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 110, 'usage_prompt_tokens': 255, 'usage_total_tokens': 365}. Logged to logs/logs\n",
      "[2024-08-09 10:53:35,049] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:53:35,049] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:53:35,049] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:53:35,049] [oaieval.py:235] usage_completion_tokens: 110\n",
      "[2024-08-09 10:53:35,049] [oaieval.py:235] usage_prompt_tokens: 255\n",
      "[2024-08-09 10:53:35,049] [oaieval.py:235] usage_total_tokens: 365\n",
      "[2024-08-09 10:53:35,053] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.836ms\n",
      "Response1: Of course! I'd be happy to help. Please provide me with your order number and any details about your question so I can assist you further.\n",
      "Instruction1: I have a question about my recent order. Can you help me with that?\n",
      "[2024-08-09 10:53:37,059] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:53:37,845] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:53:37,846] [oaieval.py:215] \u001b[1;35mRun started: 240809085337GK3PA2QG\u001b[0m\n",
      "[2024-08-09 10:53:37,848] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:53:37,871] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:53:37,871] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:53:37,872] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:53:37,882] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.69s/it]\n",
      "[2024-08-09 10:53:40,581] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:53:40,581] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 141\n",
      "prompt_tokens: 265\n",
      "total_tokens: 406\n",
      "[2024-08-09 10:53:40,582] [record.py:371] Final report: {'counts/Yes': 1, 'score': 1.0, 'usage_completion_tokens': 141, 'usage_prompt_tokens': 265, 'usage_total_tokens': 406}. Logged to logs/logs\n",
      "[2024-08-09 10:53:40,582] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:53:40,582] [oaieval.py:235] counts/Yes: 1\n",
      "[2024-08-09 10:53:40,582] [oaieval.py:235] score: 1.0\n",
      "[2024-08-09 10:53:40,582] [oaieval.py:235] usage_completion_tokens: 141\n",
      "[2024-08-09 10:53:40,582] [oaieval.py:235] usage_prompt_tokens: 265\n",
      "[2024-08-09 10:53:40,582] [oaieval.py:235] usage_total_tokens: 406\n",
      "[2024-08-09 10:53:40,585] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.748ms\n",
      "Response1: Of course! I'd be happy to help you with any questions you have about your recent order. Please provide me with your order number or any other relevant details so I can assist you more effectively.\n",
      "New best message:[{'role': 'system', 'content': 'I have a question about my recent order. Can you help me with that?'}]\n",
      "Instruction1: I have a question about my recent order. Can you help me with that?\n",
      "[2024-08-09 10:53:42,794] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:53:44,149] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:53:44,151] [oaieval.py:215] \u001b[1;35mRun started: 2408090853447G37KJQP\u001b[0m\n",
      "[2024-08-09 10:53:44,153] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:53:44,179] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:53:44,180] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:53:44,180] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:53:44,202] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "[2024-08-09 10:53:47,737] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:53:47,737] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 122\n",
      "prompt_tokens: 297\n",
      "total_tokens: 419\n",
      "[2024-08-09 10:53:47,738] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 122, 'usage_prompt_tokens': 297, 'usage_total_tokens': 419}. Logged to logs/logs\n",
      "[2024-08-09 10:53:47,738] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:53:47,738] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:53:47,738] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:53:47,738] [oaieval.py:235] usage_completion_tokens: 122\n",
      "[2024-08-09 10:53:47,738] [oaieval.py:235] usage_prompt_tokens: 297\n",
      "[2024-08-09 10:53:47,738] [oaieval.py:235] usage_total_tokens: 419\n",
      "[2024-08-09 10:53:47,745] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=4.993ms\n",
      "Response1: \n",
      "\n",
      "Thank you for your offer to help. I have a question about the estimated delivery date for my order. Can you provide me with an update on when I can expect to receive it?\n",
      "Instruction1: If you have any questions or concerns about your order, feel free to ask and I will do my best to provide you with the information you need.\n",
      "[2024-08-09 10:53:49,838] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:53:50,951] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:53:50,954] [oaieval.py:215] \u001b[1;35mRun started: 240809085350IUNBZCZ3\u001b[0m\n",
      "[2024-08-09 10:53:50,955] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:53:50,990] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:53:50,991] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:53:50,991] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:53:51,005] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "[2024-08-09 10:53:53,042] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:53:53,043] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 87\n",
      "prompt_tokens: 270\n",
      "total_tokens: 357\n",
      "[2024-08-09 10:53:53,043] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 87, 'usage_prompt_tokens': 270, 'usage_total_tokens': 357}. Logged to logs/logs\n",
      "[2024-08-09 10:53:53,044] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:53:53,044] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:53:53,044] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:53:53,044] [oaieval.py:235] usage_completion_tokens: 87\n",
      "[2024-08-09 10:53:53,044] [oaieval.py:235] usage_prompt_tokens: 270\n",
      "[2024-08-09 10:53:53,044] [oaieval.py:235] usage_total_tokens: 357\n",
      "[2024-08-09 10:53:53,051] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=3.071ms\n",
      "Response1: How can I assist you with your order today?\n",
      "Instruction1: If you have any questions or concerns about your order, feel free to ask and I will do my best to provide you with the information you need.\n",
      "[2024-08-09 10:53:55,192] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:53:55,985] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:53:55,986] [oaieval.py:215] \u001b[1;35mRun started: 240809085355MCROS2QL\u001b[0m\n",
      "[2024-08-09 10:53:55,988] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:53:56,013] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:53:56,013] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:53:56,014] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:53:56,026] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.67s/it]\n",
      "[2024-08-09 10:53:58,703] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:53:58,703] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 141\n",
      "prompt_tokens: 288\n",
      "total_tokens: 429\n",
      "[2024-08-09 10:53:58,704] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 141, 'usage_prompt_tokens': 288, 'usage_total_tokens': 429}. Logged to logs/logs\n",
      "[2024-08-09 10:53:58,704] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:53:58,704] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:53:58,704] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:53:58,704] [oaieval.py:235] usage_completion_tokens: 141\n",
      "[2024-08-09 10:53:58,704] [oaieval.py:235] usage_prompt_tokens: 288\n",
      "[2024-08-09 10:53:58,704] [oaieval.py:235] usage_total_tokens: 429\n",
      "[2024-08-09 10:53:58,707] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.844ms\n",
      "Response1: If you have any concerns or issues with your order, please let me know so I can address them promptly. Thank you for reaching out.\n",
      "Instruction1: Sure, I can help you with that. Please provide me with your order number and any specific details about your question so I can assist you further.\n",
      "[2024-08-09 10:54:00,631] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:54:01,531] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:54:01,533] [oaieval.py:215] \u001b[1;35mRun started: 240809085401EIKA4B3K\u001b[0m\n",
      "[2024-08-09 10:54:01,535] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:54:01,564] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:54:01,564] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:54:01,565] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:54:01,582] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "[2024-08-09 10:54:04,232] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:54:04,233] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 113\n",
      "prompt_tokens: 303\n",
      "total_tokens: 416\n",
      "[2024-08-09 10:54:04,233] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 113, 'usage_prompt_tokens': 303, 'usage_total_tokens': 416}. Logged to logs/logs\n",
      "[2024-08-09 10:54:04,233] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:54:04,233] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:54:04,233] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:54:04,233] [oaieval.py:235] usage_completion_tokens: 113\n",
      "[2024-08-09 10:54:04,234] [oaieval.py:235] usage_prompt_tokens: 303\n",
      "[2024-08-09 10:54:04,234] [oaieval.py:235] usage_total_tokens: 416\n",
      "[2024-08-09 10:54:04,239] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=3.755ms\n",
      "Response1: If you don't have your order number, you can also provide me with the name on the order, the date of purchase, or any other relevant information that can help me locate your order and address your question.\n",
      "Instruction1: Sure, I can help you with that. Please provide me with your order number and any specific details about your question so I can assist you further.\n",
      "[2024-08-09 10:54:06,710] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:54:07,532] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:54:07,533] [oaieval.py:215] \u001b[1;35mRun started: 2408090854075JJCQSOD\u001b[0m\n",
      "[2024-08-09 10:54:07,535] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:54:07,558] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:54:07,559] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:54:07,559] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:54:07,569] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "[2024-08-09 10:54:09,829] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:54:09,829] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 95\n",
      "prompt_tokens: 264\n",
      "total_tokens: 359\n",
      "[2024-08-09 10:54:09,830] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 95, 'usage_prompt_tokens': 264, 'usage_total_tokens': 359}. Logged to logs/logs\n",
      "[2024-08-09 10:54:09,830] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:54:09,830] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:54:09,830] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:54:09,830] [oaieval.py:235] usage_completion_tokens: 95\n",
      "[2024-08-09 10:54:09,830] [oaieval.py:235] usage_prompt_tokens: 264\n",
      "[2024-08-09 10:54:09,830] [oaieval.py:235] usage_total_tokens: 359\n",
      "[2024-08-09 10:54:09,834] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.945ms\n",
      "Response1: I'm sorry, I don't have an order number as I am an AI assistant. How can I assist you with your order today?\n",
      "Instruction1: Thank you for providing your order number. How can I assist you with your order today?\n",
      "[2024-08-09 10:54:12,085] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:54:12,869] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:54:12,871] [oaieval.py:215] \u001b[1;35mRun started: 240809085412QDBDKYBF\u001b[0m\n",
      "[2024-08-09 10:54:12,872] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:54:12,897] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:54:12,897] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:54:12,897] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:54:12,909] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.78s/it]\n",
      "[2024-08-09 10:54:15,696] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:54:15,696] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 160\n",
      "prompt_tokens: 283\n",
      "total_tokens: 443\n",
      "[2024-08-09 10:54:15,698] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 160, 'usage_prompt_tokens': 283, 'usage_total_tokens': 443}. Logged to logs/logs\n",
      "[2024-08-09 10:54:15,698] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:54:15,698] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:54:15,698] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:54:15,698] [oaieval.py:235] usage_completion_tokens: 160\n",
      "[2024-08-09 10:54:15,698] [oaieval.py:235] usage_prompt_tokens: 283\n",
      "[2024-08-09 10:54:15,698] [oaieval.py:235] usage_total_tokens: 443\n",
      "[2024-08-09 10:54:15,705] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=3.478ms\n",
      "Response1: I'm sorry, I am an AI assistant and I do not have the capability to access or track order numbers. However, if you have any questions or need assistance with your order, please let me know how I can help you.\n",
      "Instruction1: Thank you for providing your order number. How can I assist you with your order today?\n",
      "[2024-08-09 10:54:21,407] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:54:31,664] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:54:31,668] [oaieval.py:215] \u001b[1;35mRun started: 240809085431JR72BAZM\u001b[0m\n",
      "[2024-08-09 10:54:31,674] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:54:31,754] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:54:31,755] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:54:31,757] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:54:31,802] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.64s/it]\n",
      "[2024-08-09 10:54:35,473] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:54:35,473] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 98\n",
      "prompt_tokens: 278\n",
      "total_tokens: 376\n",
      "[2024-08-09 10:54:35,474] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 98, 'usage_prompt_tokens': 278, 'usage_total_tokens': 376}. Logged to logs/logs\n",
      "[2024-08-09 10:54:35,475] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:54:35,475] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:54:35,475] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:54:35,475] [oaieval.py:235] usage_completion_tokens: 98\n",
      "[2024-08-09 10:54:35,475] [oaieval.py:235] usage_prompt_tokens: 278\n",
      "[2024-08-09 10:54:35,475] [oaieval.py:235] usage_total_tokens: 376\n",
      "[2024-08-09 10:54:35,486] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=3.588ms\n",
      "Response1: Thank you for offering to help. I have a question about the shipping of my order. Can you provide me with an estimated delivery date?\n",
      "Instruction1: If you have any questions or concerns about your order, feel free to ask and I will do my best to assist you.\n",
      "[2024-08-09 10:54:43,295] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:54:44,332] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:54:44,335] [oaieval.py:215] \u001b[1;35mRun started: 240809085444D5AQFFGP\u001b[0m\n",
      "[2024-08-09 10:54:44,359] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:54:44,480] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:54:44,481] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:54:44,481] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:54:44,536] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "[2024-08-09 10:54:48,085] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:54:48,085] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 82\n",
      "prompt_tokens: 260\n",
      "total_tokens: 342\n",
      "[2024-08-09 10:54:48,086] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 82, 'usage_prompt_tokens': 260, 'usage_total_tokens': 342}. Logged to logs/logs\n",
      "[2024-08-09 10:54:48,086] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:54:48,086] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:54:48,086] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:54:48,086] [oaieval.py:235] usage_completion_tokens: 82\n",
      "[2024-08-09 10:54:48,086] [oaieval.py:235] usage_prompt_tokens: 260\n",
      "[2024-08-09 10:54:48,086] [oaieval.py:235] usage_total_tokens: 342\n",
      "[2024-08-09 10:54:48,091] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.815ms\n",
      "Response1: How can I help you with your order today?\n",
      "Instruction1: If you have any questions or concerns about your order, feel free to ask and I will do my best to assist you.\n",
      "all done, generation distance: 1, number of candidate messages: 2\n"
     ]
    }
   ],
   "source": [
    "for candidate_message in candidate_messages:\n",
    "    data = battle(best_message, best_response, candidate_message)\n",
    "    dataset = pd.concat([dataset, data],ignore_index=True)\n",
    "    dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "    if data[\"Choice\"].iloc[0] == \"Yes\":\n",
    "        best_message = candidate_message\n",
    "        best_response = data[\"Response1\"].iloc[0]\n",
    "        print(f\"New best message:{best_message}\")\n",
    "        if battles_generation == \"dense\":\n",
    "            generation_distance = 0\n",
    "    print(f\"Instruction1: {candidate_message[0][\"content\"]}\")\n",
    "\n",
    "    if battles_generation == \"only-new\":\n",
    "        new_message = [{\"role\": candidate_message[0][\"role\"], \"content\":data[\"Response1\"].iloc[0]}]\n",
    "        if new_message not in next_candidate_messages:\n",
    "            next_candidate_messages.append(new_message)\n",
    "            if roles == \"system-user\":\n",
    "                next_candidate_messages.append(switch_system_and_user(new_message))\n",
    "\n",
    "if battles_generation == \"only-new\":\n",
    "    candidate_messages = next_candidate_messages\n",
    "    next_candidate_messages = []\n",
    "if battles_generation == \"dense\":\n",
    "    #print(\"going to list candidate messages\")\n",
    "    candidate_messages = list_candidate_messages(dataset, best_message, generation_distance)\n",
    "    generation_distance += 1\n",
    "    #print(\"candidate messages listed\")\n",
    "print(f\"all done, generation distance: {generation_distance}, number of candidate messages: {len(candidate_messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instruction1</th>\n",
       "      <th>Response1</th>\n",
       "      <th>Instruction2</th>\n",
       "      <th>Response2</th>\n",
       "      <th>Sampled</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Thank you for providing your order number. How...</td>\n",
       "      <td>I'm sorry, I don't have an order number. I was...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>1. Response 1 acknowledges the lack of an orde...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Thank you for providing your order number. How...</td>\n",
       "      <td>I'm sorry, but I am unable to assist with spec...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>1. Response 1 states that they are unable to a...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>1. Both responses start with the same positive...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help you with any q...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>1. Both responses start with \"Of course! I'd b...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>1. Both responses start with the same positive...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help you with your ...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>1. Response 1 acknowledges the request for hel...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Of course! I'd be happy to help you with your ...</td>\n",
       "      <td>1. Response 1 directly asks for help with a re...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>1. Response 1 directly mirrors the language us...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>1. Response 1 in Instruction 1 asks for specif...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>Sure, I can help you with that. Please provide...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Both responses acknowledge the request for ...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Of course! I'd be happy to help you with any q...</td>\n",
       "      <td>Thank you for reaching out! How can I assist y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Response 1 does not directly address the re...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Of course! I'd be happy to help you with any q...</td>\n",
       "      <td>If you have any questions or need assistance w...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Instruction 1 asks for the order number or ...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any specific questions or concerns...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Response 1 does not specifically ask for th...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>Sure, I can help you with that. Can you please...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Response 1 directly addresses the request f...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Of course! I'd be happy to help you with any q...</td>\n",
       "      <td>Thank you for reaching out! How can I assist y...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Response 1 does not directly address the re...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Of course! I'd be happy to help you with any q...</td>\n",
       "      <td>If you have any questions or need assistance w...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. The first response does not specifically as...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Of course! I'd be happy to help you with your ...</td>\n",
       "      <td>Thank you for reaching out! Can you please pro...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Response 1 directly asks for the order numb...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Of course! I'd be happy to help you with your ...</td>\n",
       "      <td>Sure, I can help you with that. Please provide...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Response 1 directly addresses the request f...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any specific concerns or issues wi...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Response 1 uses the word \"concerns\" which i...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>Thank you for providing your order number. How...</td>\n",
       "      <td>Of course! I'd be happy to help. Please provid...</td>\n",
       "      <td>If you have any questions or concerns about yo...</td>\n",
       "      <td>1. Response 1 directly acknowledges the reques...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Instruction1  \\\n",
       "125  Thank you for providing your order number. How...   \n",
       "126  Thank you for providing your order number. How...   \n",
       "127  I have a question about my recent order. Can y...   \n",
       "128  I have a question about my recent order. Can y...   \n",
       "129  I have a question about my recent order. Can y...   \n",
       "130  I have a question about my recent order. Can y...   \n",
       "131  Hello! I'm here to assist you with any questio...   \n",
       "132  Hello! I'm here to assist you with any questio...   \n",
       "133  Of course! I'd be happy to help. Please provid...   \n",
       "134  Of course! I'd be happy to help. Please provid...   \n",
       "135  Of course! I'd be happy to help you with any q...   \n",
       "136  Of course! I'd be happy to help you with any q...   \n",
       "137  Of course! I'd be happy to help. Please provid...   \n",
       "138  Of course! I'd be happy to help. Please provid...   \n",
       "139  Of course! I'd be happy to help you with any q...   \n",
       "140  Of course! I'd be happy to help you with any q...   \n",
       "141  Of course! I'd be happy to help you with your ...   \n",
       "142  Of course! I'd be happy to help you with your ...   \n",
       "143  Of course! I'd be happy to help. Please provid...   \n",
       "144  Of course! I'd be happy to help. Please provid...   \n",
       "\n",
       "                                             Response1  \\\n",
       "125  I'm sorry, I don't have an order number. I was...   \n",
       "126  I'm sorry, but I am unable to assist with spec...   \n",
       "127  Of course! I'd be happy to help. Please provid...   \n",
       "128  Of course! I'd be happy to help you with any q...   \n",
       "129  Of course! I'd be happy to help. Please provid...   \n",
       "130  Of course! I'd be happy to help you with your ...   \n",
       "131  I have a question about my recent order. Can y...   \n",
       "132                 Hello! How can I assist you today?   \n",
       "133  If you have any questions or concerns about yo...   \n",
       "134  Sure, I can help you with that. Please provide...   \n",
       "135  Thank you for reaching out! How can I assist y...   \n",
       "136  If you have any questions or need assistance w...   \n",
       "137  If you have any specific questions or concerns...   \n",
       "138  Sure, I can help you with that. Can you please...   \n",
       "139  Thank you for reaching out! How can I assist y...   \n",
       "140  If you have any questions or need assistance w...   \n",
       "141  Thank you for reaching out! Can you please pro...   \n",
       "142  Sure, I can help you with that. Please provide...   \n",
       "143  If you have any specific concerns or issues wi...   \n",
       "144  Thank you for providing your order number. How...   \n",
       "\n",
       "                                          Instruction2  \\\n",
       "125  I have a question about my recent order. Can y...   \n",
       "126  I have a question about my recent order. Can y...   \n",
       "127  I have a question about my recent order. Can y...   \n",
       "128  I have a question about my recent order. Can y...   \n",
       "129  I have a question about my recent order. Can y...   \n",
       "130  I have a question about my recent order. Can y...   \n",
       "131  I have a question about my recent order. Can y...   \n",
       "132  Hello! I'm here to assist you with any questio...   \n",
       "133  Hello! I'm here to assist you with any questio...   \n",
       "134  Of course! I'd be happy to help. Please provid...   \n",
       "135  Of course! I'd be happy to help. Please provid...   \n",
       "136  Of course! I'd be happy to help. Please provid...   \n",
       "137  Of course! I'd be happy to help. Please provid...   \n",
       "138  Of course! I'd be happy to help. Please provid...   \n",
       "139  Of course! I'd be happy to help. Please provid...   \n",
       "140  Of course! I'd be happy to help. Please provid...   \n",
       "141  Of course! I'd be happy to help. Please provid...   \n",
       "142  Of course! I'd be happy to help. Please provid...   \n",
       "143  Of course! I'd be happy to help. Please provid...   \n",
       "144  Of course! I'd be happy to help. Please provid...   \n",
       "\n",
       "                                             Response2  \\\n",
       "125  Of course! I'd be happy to help. Please provid...   \n",
       "126  Of course! I'd be happy to help. Please provid...   \n",
       "127  Of course! I'd be happy to help. Please provid...   \n",
       "128  Of course! I'd be happy to help. Please provid...   \n",
       "129  Of course! I'd be happy to help. Please provid...   \n",
       "130  Of course! I'd be happy to help. Please provid...   \n",
       "131  Of course! I'd be happy to help you with your ...   \n",
       "132  I have a question about my recent order. Can y...   \n",
       "133  I have a question about my recent order. Can y...   \n",
       "134  If you have any questions or concerns about yo...   \n",
       "135  If you have any questions or concerns about yo...   \n",
       "136  If you have any questions or concerns about yo...   \n",
       "137  If you have any questions or concerns about yo...   \n",
       "138  If you have any questions or concerns about yo...   \n",
       "139  If you have any questions or concerns about yo...   \n",
       "140  If you have any questions or concerns about yo...   \n",
       "141  If you have any questions or concerns about yo...   \n",
       "142  If you have any questions or concerns about yo...   \n",
       "143  If you have any questions or concerns about yo...   \n",
       "144  If you have any questions or concerns about yo...   \n",
       "\n",
       "                                               Sampled Choice  \\\n",
       "125  1. Response 1 acknowledges the lack of an orde...     No   \n",
       "126  1. Response 1 states that they are unable to a...     No   \n",
       "127  1. Both responses start with the same positive...     No   \n",
       "128  1. Both responses start with \"Of course! I'd b...     No   \n",
       "129  1. Both responses start with the same positive...     No   \n",
       "130  1. Response 1 acknowledges the request for hel...    Yes   \n",
       "131  1. Response 1 directly asks for help with a re...    Yes   \n",
       "132  1. Response 1 directly mirrors the language us...     No   \n",
       "133  1. Response 1 in Instruction 1 asks for specif...    Yes   \n",
       "134  1. Both responses acknowledge the request for ...     No   \n",
       "135  1. Response 1 does not directly address the re...     No   \n",
       "136  1. Instruction 1 asks for the order number or ...     No   \n",
       "137  1. Response 1 does not specifically ask for th...     No   \n",
       "138  1. Response 1 directly addresses the request f...     No   \n",
       "139  1. Response 1 does not directly address the re...     No   \n",
       "140  1. The first response does not specifically as...     No   \n",
       "141  1. Response 1 directly asks for the order numb...     No   \n",
       "142  1. Response 1 directly addresses the request f...     No   \n",
       "143  1. Response 1 uses the word \"concerns\" which i...     No   \n",
       "144  1. Response 1 directly acknowledges the reques...     No   \n",
       "\n",
       "                                                  Data  \n",
       "125  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "126  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "127  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "128  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "129  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "130  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "131  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "132  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "133  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "134  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "135  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "136  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "137  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "138  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "139  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "140  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "141  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "142  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "143  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "144  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  "
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I have a question about my recent order. Can you help me with that?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Of course! I'd be happy to help you with any questions you have about your recent order. Please provide me with your order number or any other relevant details so I can assist you more effectively."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Of course! I'd be happy to help. Please provide me with your order number and any specific details about your question so I can assist you further."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for providing your order number. How can I assist you with your order today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Response 1 acknowledges the customer's question and expresses willingness to help.\n",
       "2. Response 1 asks for relevant details to assist the customer more effectively.\n",
       "3. Response 2 also acknowledges the customer's request for help.\n",
       "4. Response 2 asks for the order number and specific details about the question.\n",
       "\n",
       "Based on the steps above, Response 1 is better than Response 2 as it not only expresses willingness to help but also asks for relevant details upfront to assist the customer more effectively.\n",
       "\n",
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for entry in dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-1].drop(\"Data\"):\n",
    "    display_markdown(entry, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user',\n",
       "   'content': \"Of course! I'd be happy to help. Please provide me with your order number and any specific details about your question so I can assist you further.\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"Of course! I'd be happy to help. Please provide me with your order number and any specific details about your question so I can assist you further.\"}]]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fdbe172e46cfba2329a5e8d5b64cdf2d12f4dfd7d9bcea153ecef62d1d51933b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
