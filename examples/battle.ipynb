{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a BATTLE Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = True\n",
    "num_few_shot = 4\n",
    "initial_message = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "roles = \"user\"             # methods: system-user, system, user\n",
    "battles_generation = \"dense\"      # methods: dense, only-new\n",
    "\n",
    "#!cd evals\n",
    "#!git lfs fetch --all\n",
    "#!git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import yaml\n",
    "#import datetime\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "#api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n",
    "\n",
    "# Install Evals if you haven't already\n",
    "# %pip install -e ../.\n",
    "# pip install --upgrade openai\n",
    "# %pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths. Assuming this notebook is in examples/\n",
    "\n",
    "evals_path = os.path.join(os.getcwd(), \"..\", \"evals\")\n",
    "\n",
    "registry_path = os.path.join(evals_path, \"registry\", \"evals\", \"battles.yaml\")\n",
    "\n",
    "data_path = os.path.join(evals_path, \"registry\", \"data\", \"battles\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "data_path = os.path.join(data_path, \"samples.jsonl\")\n",
    "\n",
    "json_logs_path = os.path.join(os.getcwd(), \"logs\")\n",
    "os.makedirs(json_logs_path, exist_ok=True)\n",
    "json_logs_path = os.path.join(json_logs_path, \"logs\")\n",
    "\n",
    "df_path = os.path.join(evals_path, \"evallogs\", \"df\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "dataset_path = os.path.join(df_path, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registry yaml\n",
    "\n",
    "registry_yaml = {}\n",
    "\n",
    "registry_yaml[\"battles\"] = {\n",
    "    \"id\": \"battles.test.v1\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}\n",
    "registry_yaml[\"battles.test.v1\"] = {\n",
    "    \"class\": \"evals.elsuite.modelgraded.classify:ModelBasedClassify\",\n",
    "    \"args\": {\n",
    "        \"samples_jsonl\": \"battles/samples.jsonl\",\n",
    "        \"eval_type\": \"cot_classify\",\n",
    "        \"modelgraded_spec\": \"battle\"\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(registry_path), \"w\") as f:\n",
    "    yaml.dump(registry_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data\n",
    "if new:\n",
    "    dataset = ()\n",
    "    dataset = pd.DataFrame(dataset, columns=['Instruction1', 'Response1', 'Instruction2', 'Response2', 'Sampled',\n",
    "       'Choice', 'Data'])\n",
    "    best_message = initial_message\n",
    "    best_response = client.chat.completions.create(\n",
    "        messages = initial_message,\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        ).choices[0].message.content\n",
    "else:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset = pd.read_json(f, lines=True)\n",
    "    if dataset.iloc[-1][\"Choice\"] == \"No\":\n",
    "        best_content = dataset.iloc[-1][\"Instruction2\"]\n",
    "        best_response = dataset.iloc[-1][\"Response2\"]\n",
    "    else:\n",
    "        best_content = dataset.iloc[-1][\"Instruction1\"]\n",
    "        best_response = dataset.iloc[-1][\"Response1\"]\n",
    "    best_message = [{\"role\": \"user\", \"content\": best_content}]\n",
    "candidate_messages = [best_message]\n",
    "next_candidate_messages = []\n",
    "generation_distance = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "def battle(best_message, best_response, candidate_message):\n",
    "\n",
    "    dataset = [{\"input1\": candidate_message, \"input2\": best_message, \"completion2\":best_response}]\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_json(data_path, orient=\"records\", lines=True)\n",
    "\n",
    "    !oaieval gpt-3.5-turbo battles --record_path logs/logs\n",
    "    \n",
    "    with open(json_logs_path, \"r\") as f:\n",
    "        df = pd.read_json(f, lines=True)\n",
    "\n",
    "    #current_time = datetime.datetime.now()\n",
    "    #formatted_time = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #df.to_json(os.path.join(df_path, formatted_time), lines=True, orient=\"records\")\n",
    "\n",
    "    instruction1 = candidate_message[-1][\"content\"]\n",
    "    instruction2 = best_message[-1][\"content\"]\n",
    "\n",
    "    battle_prompt_content = df[\"data\"].iloc[-2][\"prompt\"][0][\"content\"]\n",
    "    response1 = battle_prompt_content.split(\"\\n[Response 1]\\n\",)[1].split(\"\\n\\n[Instruction 2]\\n\")[0]\n",
    "    response1 = response1.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    response2 = battle_prompt_content.split(\"\\n[Response 2]\\n\",)[1].split(\"\\n\\n\\nIs the first response better than the second?\")[0]\n",
    "    response2 = response2.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    print(f\"Response1: {response1}\")\n",
    "    #print(f\"response2: {response2}\")\n",
    "\n",
    "    sampled = df[\"data\"].iloc[-2][\"sampled\"][0]\n",
    "\n",
    "    choice = df[\"data\"].iloc[-1][\"choice\"]\n",
    "\n",
    "    data = {'Instruction1': instruction1, 'Response1': response1, 'Instruction2': instruction2, 'Response2': response2, 'Sampled': sampled, 'Choice': choice, 'Data': {}}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = df.to_dict()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_system_and_user(message):\n",
    "    new_message = []\n",
    "    if message[0][\"role\"] == \"system\":\n",
    "        new_message.append([{\"role\": \"user\", \"content\": message[0][\"content\"]}])\n",
    "    else:\n",
    "        new_message.append([{\"role\": \"system\", \"content\": message[0][\"content\"]}])\n",
    "    return new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parents(content, dataset):\n",
    "    #print (f\"finding parents {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Response1\"] == content]\n",
    "    parents = dataset[\"Instruction1\"].unique()\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_children(content, dataset):\n",
    "    #print (f\"finding children {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Instruction1\"] == content]\n",
    "    children = dataset[\"Response1\"].unique()\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_candidate_messages(dataset, best_message, generation_distance, roles):\n",
    "    best_content = best_message[-1][\"content\"]\n",
    "    last = [best_content]\n",
    "    list_of_contents = [best_content]\n",
    "\n",
    "    next = []\n",
    "    for i in range(generation_distance):\n",
    "        #print (f\"starting level {i}, generation distance {generation_distance}\")\n",
    "        for content in last:\n",
    "            #print(f\"last_up: {last_up}, now {content}\")\n",
    "            next.extend(find_parents(content, dataset))\n",
    "            next.extend(find_children(content, dataset))\n",
    "            \n",
    "        #print (f\"behind for loops\")\n",
    "        list_of_contents.extend(next)\n",
    "        last = next.copy()\n",
    "        #print(f\"endind level {i}\")\n",
    "        \n",
    "    list_of_contents = pd.array(list_of_contents).unique().tolist()\n",
    "    \n",
    "    #best_message_index = list_of_contents.index(best_message[0][content])\n",
    "    #start = max(best_message_index - generation_distance, 0)\n",
    "    #stop = min(len(list_of_contents))\n",
    "    #stop = len(list_of_contents) - 1\n",
    "\n",
    "    messages = []\n",
    "    for content in list_of_contents:\n",
    "        if roles == \"system-user\" or \"user\":\n",
    "            messages.append([{\"role\":\"user\",\"content\":content}])\n",
    "        if (roles == \"system-user\") or (roles == \"system\"):\n",
    "            print(\"Creating message without user role.\")\n",
    "            messages.append([{\"role\":\"system\",\"content\":content}])\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-09 23:12:55,267] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 23:12:56,119] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 23:12:56,121] [oaieval.py:215] \u001b[1;35mRun started: 240809211256TQHBLPWC\u001b[0m\n",
      "[2024-08-09 23:12:56,122] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 23:12:56,150] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 23:12:56,151] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 23:12:56,151] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 23:12:56,168] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "[2024-08-09 23:12:59,054] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 23:12:59,054] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 128\n",
      "prompt_tokens: 329\n",
      "total_tokens: 457\n",
      "[2024-08-09 23:12:59,055] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 128, 'usage_prompt_tokens': 329, 'usage_total_tokens': 457}. Logged to logs/logs\n",
      "[2024-08-09 23:12:59,055] [oaieval.py:233] Final report:\n",
      "[2024-08-09 23:12:59,055] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 23:12:59,055] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 23:12:59,055] [oaieval.py:235] usage_completion_tokens: 128\n",
      "[2024-08-09 23:12:59,055] [oaieval.py:235] usage_prompt_tokens: 329\n",
      "[2024-08-09 23:12:59,056] [oaieval.py:235] usage_total_tokens: 457\n",
      "[2024-08-09 23:12:59,059] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.782ms\n",
      "Response1: It seems like there was a mix-up in our greetings! I'm here to assist you with any questions or tasks you may have. Just let me know how I can help you today.\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "all done, generation distance: 2, number of candidate messages: 5\n"
     ]
    }
   ],
   "source": [
    "for candidate_message in candidate_messages:\n",
    "    if num_few_shot > 0:\n",
    "        few_shot_prompt = []\n",
    "        for _, key_battle in dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-num_few_shot:].iterrows():\n",
    "            few_shot_prompt.append({\"role\": \"system\", \"content\": key_battle[\"Instruction1\"], \"name\": \"example_user\"})\n",
    "            few_shot_prompt.append({\"role\": \"system\", \"content\": key_battle[\"Response1\"], \"name\": \"example_assistant\"})\n",
    "        candidate_message = few_shot_prompt + candidate_message\n",
    "    data = battle(best_message, best_response, candidate_message)\n",
    "    dataset = pd.concat([dataset, data],ignore_index=True)\n",
    "    dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "    if data[\"Choice\"].iloc[0] == \"Yes\":\n",
    "        best_message = candidate_message\n",
    "        best_response = data[\"Response1\"].iloc[0]\n",
    "        print(f\"New best message:{best_message}\")\n",
    "        if battles_generation == \"dense\":\n",
    "            generation_distance = 0\n",
    "\n",
    "    print(f\"Instruction1: {candidate_message[-1][\"content\"]}\")\n",
    "\n",
    "    if battles_generation == \"only-new\":\n",
    "        new_message = [{\"role\": candidate_message[0][\"role\"], \"content\":data[\"Response1\"].iloc[0]}]\n",
    "        if new_message not in next_candidate_messages:\n",
    "            next_candidate_messages.append(new_message)\n",
    "            if roles == \"system-user\":\n",
    "                next_candidate_messages.append(switch_system_and_user(new_message))\n",
    "\n",
    "if battles_generation == \"only-new\":\n",
    "    candidate_messages = next_candidate_messages\n",
    "    next_candidate_messages = []\n",
    "if battles_generation == \"dense\":\n",
    "    #print(\"going to list candidate messages\")\n",
    "    candidate_messages = list_candidate_messages(dataset, best_message, generation_distance, roles)\n",
    "    generation_distance += 1\n",
    "    #print(\"candidate messages listed\")\n",
    "print(f\"all done, generation distance: {generation_distance}, number of candidate messages: {len(candidate_messages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you today."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Response 1 provides a more detailed and proactive approach by offering help with any questions or tasks the person may have.\n",
       "2. Response 2 is more straightforward and direct, simply asking how they can assist without offering additional information.\n",
       "\n",
       "Based on the above points, Response 1 is better than Response 2.\n",
       "\n",
       "Yes\n",
       "\n",
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for entry in dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-1].drop(\"Data\"):\n",
    "    display_markdown(entry, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instruction1</th>\n",
       "      <th>Response1</th>\n",
       "      <th>Instruction2</th>\n",
       "      <th>Response2</th>\n",
       "      <th>Sampled</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm just here to chat and help with any...</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Response 1 includes additional information ...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Response 1 provides a more detailed and pro...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hello! I'm just here to chat and help with any...</td>\n",
       "      <td>That's great to hear! I'm here to assist you w...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>1. Response 1 is more detailed and personalize...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Instruction1  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                 Hello! How can I assist you today?   \n",
       "4                                                      \n",
       "5                 Hello! How can I assist you today?   \n",
       "6  Hello! I'm just here to chat and help with any...   \n",
       "\n",
       "                                           Response1  \\\n",
       "0                 Hello! How can I assist you today?   \n",
       "1                 Hello! How can I assist you today?   \n",
       "2                 Hello! How can I assist you today?   \n",
       "3  Hello! I'm just here to chat and help with any...   \n",
       "4                 Hello! How can I assist you today?   \n",
       "5  Hello! I'm here to help with any questions or ...   \n",
       "6  That's great to hear! I'm here to assist you w...   \n",
       "\n",
       "                         Instruction2  \\\n",
       "0                                       \n",
       "1                                       \n",
       "2                                       \n",
       "3                                       \n",
       "4                                       \n",
       "5                                       \n",
       "6  Hello! How can I assist you today?   \n",
       "\n",
       "                                           Response2  \\\n",
       "0                 Hello! How can I assist you today?   \n",
       "1                 Hello! How can I assist you today?   \n",
       "2                 Hello! How can I assist you today?   \n",
       "3                 Hello! How can I assist you today?   \n",
       "4                 Hello! How can I assist you today?   \n",
       "5                 Hello! How can I assist you today?   \n",
       "6  Hello! I'm here to help with any questions or ...   \n",
       "\n",
       "                                             Sampled Choice  \\\n",
       "0  1. Both responses are identical in content and...     No   \n",
       "1  1. Both responses are identical in content and...     No   \n",
       "2  1. Both responses are identical in content and...     No   \n",
       "3  1. Response 1 includes additional information ...     No   \n",
       "4  1. Both responses are identical in content and...     No   \n",
       "5  1. Response 1 provides a more detailed and pro...    Yes   \n",
       "6  1. Response 1 is more detailed and personalize...     No   \n",
       "\n",
       "                                                Data  \n",
       "0  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "1  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "2  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "3  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "4  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "5  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "6  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  "
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user', 'content': 'Hello! How can I assist you today?'}]]"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fdbe172e46cfba2329a5e8d5b64cdf2d12f4dfd7d9bcea153ecef62d1d51933b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
