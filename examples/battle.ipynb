{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a BATTLE Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = True\n",
    "initial_message = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "battles_generation = \"dense\"      # methods: dense, only-new\n",
    "roles = \"system-user\"             # methods: system-user, system, user\n",
    "\n",
    "#!cd evals\n",
    "#!git lfs fetch --all\n",
    "#!git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import yaml\n",
    "#import datetime\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "#api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n",
    "\n",
    "# Install Evals if you haven't already\n",
    "# %pip install -e ../.\n",
    "# pip install --upgrade openai\n",
    "# %pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths. Assuming this notebook is in examples/\n",
    "\n",
    "evals_path = os.path.join(os.getcwd(), \"..\", \"evals\")\n",
    "\n",
    "registry_path = os.path.join(evals_path, \"registry\", \"evals\", \"battles.yaml\")\n",
    "\n",
    "data_path = os.path.join(evals_path, \"registry\", \"data\", \"battles\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "data_path = os.path.join(data_path, \"samples.jsonl\")\n",
    "\n",
    "json_logs_path = os.path.join(os.getcwd(), \"logs\")\n",
    "os.makedirs(json_logs_path, exist_ok=True)\n",
    "json_logs_path = os.path.join(json_logs_path, \"logs\")\n",
    "\n",
    "df_path = os.path.join(evals_path, \"evallogs\", \"df\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "dataset_path = os.path.join(df_path, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registry yaml\n",
    "\n",
    "registry_yaml = {}\n",
    "\n",
    "registry_yaml[\"battles\"] = {\n",
    "    \"id\": \"battles.test.v1\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}\n",
    "registry_yaml[\"battles.test.v1\"] = {\n",
    "    \"class\": \"evals.elsuite.modelgraded.classify:ModelBasedClassify\",\n",
    "    \"args\": {\n",
    "        \"samples_jsonl\": \"battles/samples.jsonl\",\n",
    "        \"eval_type\": \"cot_classify\",\n",
    "        \"modelgraded_spec\": \"battle\"\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(registry_path), \"w\") as f:\n",
    "    yaml.dump(registry_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data\n",
    "if new:\n",
    "    dataset = ()\n",
    "    dataset = pd.DataFrame(dataset, columns=['Instruction1', 'Response1', 'Instruction2', 'Response2', 'Sampled',\n",
    "       'Choice', 'Data'])\n",
    "    best_message = initial_message\n",
    "    best_response = client.chat.completions.create(\n",
    "        messages = initial_message,\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        ).choices[0].message.content\n",
    "else:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset = pd.read_json(f, lines=True)\n",
    "    if dataset.iloc[-1][\"Choice\"] == \"No\":\n",
    "        best_content = dataset.iloc[-1][\"Instruction2\"]\n",
    "        best_response = dataset.iloc[-1][\"Response2\"]\n",
    "    else:\n",
    "        best_content = dataset.iloc[-1][\"Instruction1\"]\n",
    "        best_response = dataset.iloc[-1][\"Response1\"]\n",
    "    best_message = [{\"role\": \"user\", \"content\": best_content}]\n",
    "candidate_messages = [best_message]\n",
    "next_candidate_messages = []\n",
    "generation_distance = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def battle(best_message, best_response, candidate_message):\n",
    "\n",
    "    dataset = [{\"input1\": candidate_message, \"input2\": best_message, \"completion2\":best_response}]\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_json(data_path, orient=\"records\", lines=True)\n",
    "\n",
    "    !oaieval gpt-3.5-turbo battles --record_path logs/logs\n",
    "    \n",
    "    with open(json_logs_path, \"r\") as f:\n",
    "        df = pd.read_json(f, lines=True)\n",
    "\n",
    "    #current_time = datetime.datetime.now()\n",
    "    #formatted_time = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #df.to_json(os.path.join(df_path, formatted_time), lines=True, orient=\"records\")\n",
    "\n",
    "    instruction1 = candidate_message[0][\"content\"]\n",
    "    instruction2 = best_message[0][\"content\"]\n",
    "\n",
    "    battle_prompt_content = df[\"data\"].iloc[-2][\"prompt\"][0][\"content\"]\n",
    "    response1 = battle_prompt_content.split(\"\\n[Response 1]\\n\",)[1].split(\"\\n\\n[Instruction 2]\\n\")[0]\n",
    "    response1 = response1.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    response2 = battle_prompt_content.split(\"\\n[Response 2]\\n\",)[1].split(\"\\n\\n\\nIs the first response better than the second?\")[0]\n",
    "    response2 = response2.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    print(f\"Response1: {response1}\")\n",
    "    #print(f\"response2: {response2}\")\n",
    "\n",
    "    sampled = df[\"data\"].iloc[-2][\"sampled\"][0]\n",
    "\n",
    "    choice = df[\"data\"].iloc[-1][\"choice\"]\n",
    "\n",
    "    data = {'Instruction1': instruction1, 'Response1': response1, 'Instruction2': instruction2, 'Response2': response2, 'Sampled': sampled, 'Choice': choice, 'Data': {}}\n",
    "    data = pd.DataFrame([data])\n",
    "    data.at[0, \"Data\"] = df.to_dict()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_system_and_user(message):\n",
    "    new_message = []\n",
    "    if message[0][\"role\"] == \"system\":\n",
    "        new_message.append([{\"role\": \"user\", \"content\": message[0][\"content\"]}])\n",
    "    else:\n",
    "        new_message.append([{\"role\": \"system\", \"content\": message[0][\"content\"]}])\n",
    "    return new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parents(content, dataset):\n",
    "    print (f\"finding parents {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Response1\"] == content]\n",
    "    parents = dataset[\"Instruction1\"].unique()\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_children(content, dataset):\n",
    "    print (f\"finding children {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Instruction1\"] == content]\n",
    "    children = dataset[\"Response1\"].unique()\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_candidate_messages(dataset, best_message, generation_distance):\n",
    "    best_content = best_message[0][\"content\"]\n",
    "    last_up = [best_content]\n",
    "    last_down = [best_content]\n",
    "    list_of_contents = [best_content]\n",
    "\n",
    "    next_up = []\n",
    "    next_down = []\n",
    "    for i in range(generation_distance):\n",
    "        print (f\"starting level {i}, generation distance {generation_distance}\")\n",
    "        for content in last_up:\n",
    "            #print(f\"last_up: {last_up}, now {content}\")\n",
    "            next_up.extend(find_parents(content, dataset))\n",
    "        for content in last_down:\n",
    "            #print(f\"last_up: {last_down}, now {content}\")\n",
    "            next_down.extend(find_children(content, dataset))\n",
    "        print (f\"behind for loops\")\n",
    "        list_of_contents.extend(next_up)\n",
    "        list_of_contents.extend(next_down)\n",
    "        last_up = next_up.copy()\n",
    "        last_down = next_down.copy()\n",
    "        print(f\"endind level {i}\")\n",
    "        \n",
    "\n",
    "    list_of_contents = pd.array(list_of_contents).unique().tolist()\n",
    "    \n",
    "    #best_message_index = list_of_contents.index(best_message[0][content])\n",
    "    #start = max(best_message_index - generation_distance, 0)\n",
    "    #stop = min(len(list_of_contents))\n",
    "    #stop = len(list_of_contents) - 1\n",
    "\n",
    "    messages = []\n",
    "    for content in list_of_contents:\n",
    "        if roles == \"system-user\" or \"user\":\n",
    "            messages.append([{\"role\":\"user\",\"content\":content}])\n",
    "        if roles == \"system-user\" or \"system\":\n",
    "            messages.append([{\"role\":\"system\",\"content\":content}])\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-09 09:58:54,140] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:58:54,947] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:58:54,952] [oaieval.py:215] \u001b[1;35mRun started: 2408090758545O4GDFMN\u001b[0m\n",
      "[2024-08-09 09:58:54,954] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:58:54,979] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:58:54,980] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:58:54,980] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:58:55,007] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "[2024-08-09 09:58:57,223] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:58:57,223] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 110\n",
      "prompt_tokens: 263\n",
      "total_tokens: 373\n",
      "[2024-08-09 09:58:57,224] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 110, 'usage_prompt_tokens': 263, 'usage_total_tokens': 373}. Logged to logs/logs\n",
      "[2024-08-09 09:58:57,225] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:58:57,225] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:58:57,225] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:58:57,225] [oaieval.py:235] usage_completion_tokens: 110\n",
      "[2024-08-09 09:58:57,225] [oaieval.py:235] usage_prompt_tokens: 263\n",
      "[2024-08-09 09:58:57,225] [oaieval.py:235] usage_total_tokens: 373\n",
      "[2024-08-09 09:58:57,228] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.798ms\n",
      "Response1: Hello! I'm here to assist you with any questions or topics you'd like to discuss. Feel free to ask me anything!\n",
      "Instruction1: Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\n",
      "[2024-08-09 09:58:59,247] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:00,211] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:00,212] [oaieval.py:215] \u001b[1;35mRun started: 240809075900ND4OPPPH\u001b[0m\n",
      "[2024-08-09 09:59:00,214] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:00,247] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:00,247] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:00,247] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:00,264] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "[2024-08-09 09:59:02,662] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:02,662] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 104\n",
      "prompt_tokens: 257\n",
      "total_tokens: 361\n",
      "[2024-08-09 09:59:02,666] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 104, 'usage_prompt_tokens': 257, 'usage_total_tokens': 361}. Logged to logs/logs\n",
      "[2024-08-09 09:59:02,666] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:02,666] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:02,666] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:02,666] [oaieval.py:235] usage_completion_tokens: 104\n",
      "[2024-08-09 09:59:02,666] [oaieval.py:235] usage_prompt_tokens: 257\n",
      "[2024-08-09 09:59:02,666] [oaieval.py:235] usage_total_tokens: 361\n",
      "[2024-08-09 09:59:02,676] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=8.554ms\n",
      "Response1: Hello! I'm here to help with any questions you have. What would you like to know?\n",
      "Instruction1: Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\n",
      "[2024-08-09 09:59:05,960] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:06,976] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:06,979] [oaieval.py:215] \u001b[1;35mRun started: 2408090759066JUWH2MH\u001b[0m\n",
      "[2024-08-09 09:59:06,981] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:07,023] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:07,026] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:07,026] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:07,054] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "[2024-08-09 09:59:09,514] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:09,514] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 108\n",
      "prompt_tokens: 235\n",
      "total_tokens: 343\n",
      "[2024-08-09 09:59:09,515] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 108, 'usage_prompt_tokens': 235, 'usage_total_tokens': 343}. Logged to logs/logs\n",
      "[2024-08-09 09:59:09,515] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:09,515] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:09,515] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:09,515] [oaieval.py:235] usage_completion_tokens: 108\n",
      "[2024-08-09 09:59:09,515] [oaieval.py:235] usage_prompt_tokens: 235\n",
      "[2024-08-09 09:59:09,515] [oaieval.py:235] usage_total_tokens: 343\n",
      "[2024-08-09 09:59:09,519] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.815ms\n",
      "Response1: Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-09 09:59:11,702] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:12,619] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:12,621] [oaieval.py:215] \u001b[1;35mRun started: 240809075912YN2UTYTG\u001b[0m\n",
      "[2024-08-09 09:59:12,623] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:12,668] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:12,668] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:12,669] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:12,685] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "[2024-08-09 09:59:14,838] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:14,838] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 82\n",
      "prompt_tokens: 218\n",
      "total_tokens: 300\n",
      "[2024-08-09 09:59:14,839] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 82, 'usage_prompt_tokens': 218, 'usage_total_tokens': 300}. Logged to logs/logs\n",
      "[2024-08-09 09:59:14,839] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:14,839] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:14,839] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:14,839] [oaieval.py:235] usage_completion_tokens: 82\n",
      "[2024-08-09 09:59:14,839] [oaieval.py:235] usage_prompt_tokens: 218\n",
      "[2024-08-09 09:59:14,839] [oaieval.py:235] usage_total_tokens: 300\n",
      "[2024-08-09 09:59:14,845] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=3.881ms\n",
      "Response1: Hello! How can I assist you today?\n",
      "Instruction1: Hello! How can I assist you today?\n",
      "[2024-08-09 09:59:17,407] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:18,488] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:18,490] [oaieval.py:215] \u001b[1;35mRun started: 240809075918SFTIQBUX\u001b[0m\n",
      "[2024-08-09 09:59:18,493] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:18,528] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:18,528] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:18,529] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:18,549] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "[2024-08-09 09:59:21,287] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:21,287] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 85\n",
      "prompt_tokens: 255\n",
      "total_tokens: 340\n",
      "[2024-08-09 09:59:21,288] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 85, 'usage_prompt_tokens': 255, 'usage_total_tokens': 340}. Logged to logs/logs\n",
      "[2024-08-09 09:59:21,288] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:21,288] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:21,288] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:21,289] [oaieval.py:235] usage_completion_tokens: 85\n",
      "[2024-08-09 09:59:21,290] [oaieval.py:235] usage_prompt_tokens: 255\n",
      "[2024-08-09 09:59:21,290] [oaieval.py:235] usage_total_tokens: 340\n",
      "[2024-08-09 09:59:21,302] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=8.439ms\n",
      "Response1: I have a question about my recent order. Can you help me with that?\n",
      "Instruction1: Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\n",
      "[2024-08-09 09:59:23,585] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:24,460] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:24,462] [oaieval.py:215] \u001b[1;35mRun started: 2408090759243ECCFDLI\u001b[0m\n",
      "[2024-08-09 09:59:24,464] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:24,499] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:24,500] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:24,502] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:24,516] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.70s/it]\n",
      "[2024-08-09 09:59:27,225] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:27,226] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 86\n",
      "prompt_tokens: 248\n",
      "total_tokens: 334\n",
      "[2024-08-09 09:59:27,227] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 86, 'usage_prompt_tokens': 248, 'usage_total_tokens': 334}. Logged to logs/logs\n",
      "[2024-08-09 09:59:27,227] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:27,227] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:27,227] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:27,227] [oaieval.py:235] usage_completion_tokens: 86\n",
      "[2024-08-09 09:59:27,227] [oaieval.py:235] usage_prompt_tokens: 248\n",
      "[2024-08-09 09:59:27,227] [oaieval.py:235] usage_total_tokens: 334\n",
      "[2024-08-09 09:59:27,230] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.648ms\n",
      "Response1: Hello! How can I assist you today?\n",
      "Instruction1: Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\n",
      "[2024-08-09 09:59:29,626] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:30,454] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:30,456] [oaieval.py:215] \u001b[1;35mRun started: 240809075930OQ4DDXZX\u001b[0m\n",
      "[2024-08-09 09:59:30,459] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:30,492] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:30,492] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:30,493] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:30,508] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "[2024-08-09 09:59:32,856] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:32,856] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 89\n",
      "prompt_tokens: 263\n",
      "total_tokens: 352\n",
      "[2024-08-09 09:59:32,857] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 89, 'usage_prompt_tokens': 263, 'usage_total_tokens': 352}. Logged to logs/logs\n",
      "[2024-08-09 09:59:32,857] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:32,857] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:32,857] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:32,857] [oaieval.py:235] usage_completion_tokens: 89\n",
      "[2024-08-09 09:59:32,857] [oaieval.py:235] usage_prompt_tokens: 263\n",
      "[2024-08-09 09:59:32,857] [oaieval.py:235] usage_total_tokens: 352\n",
      "[2024-08-09 09:59:32,863] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=4.285ms\n",
      "Response1: I can help with a variety of topics such as general information, recommendations, definitions, explanations, and more. Just let me know what you're curious about!\n",
      "Instruction1: Hello! I'm here to help with any questions you have. What would you like to know?\n",
      "[2024-08-09 09:59:34,957] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:35,857] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:35,859] [oaieval.py:215] \u001b[1;35mRun started: 2408090759354HILCSLK\u001b[0m\n",
      "[2024-08-09 09:59:35,861] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:35,890] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:35,891] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:35,891] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:35,912] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "[2024-08-09 09:59:38,491] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:38,491] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 113\n",
      "prompt_tokens: 240\n",
      "total_tokens: 353\n",
      "[2024-08-09 09:59:38,492] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 113, 'usage_prompt_tokens': 240, 'usage_total_tokens': 353}. Logged to logs/logs\n",
      "[2024-08-09 09:59:38,492] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:38,492] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:38,492] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:38,492] [oaieval.py:235] usage_completion_tokens: 113\n",
      "[2024-08-09 09:59:38,492] [oaieval.py:235] usage_prompt_tokens: 240\n",
      "[2024-08-09 09:59:38,492] [oaieval.py:235] usage_total_tokens: 353\n",
      "[2024-08-09 09:59:38,496] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.367ms\n",
      "Response1: Hello! How can I assist you today?\n",
      "Instruction1: Hello! I'm here to help with any questions you have. What would you like to know?\n",
      "[2024-08-09 09:59:40,561] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:41,343] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:41,345] [oaieval.py:215] \u001b[1;35mRun started: 240809075941WOWWMDOR\u001b[0m\n",
      "[2024-08-09 09:59:41,347] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:41,395] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:41,395] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:41,396] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:41,418] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "[2024-08-09 09:59:43,611] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:43,611] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 95\n",
      "prompt_tokens: 200\n",
      "total_tokens: 295\n",
      "[2024-08-09 09:59:43,612] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 95, 'usage_prompt_tokens': 200, 'usage_total_tokens': 295}. Logged to logs/logs\n",
      "[2024-08-09 09:59:43,612] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:43,613] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:43,613] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:43,613] [oaieval.py:235] usage_completion_tokens: 95\n",
      "[2024-08-09 09:59:43,613] [oaieval.py:235] usage_prompt_tokens: 200\n",
      "[2024-08-09 09:59:43,613] [oaieval.py:235] usage_total_tokens: 295\n",
      "[2024-08-09 09:59:43,616] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.839ms\n",
      "Response1: Hello! How can I assist you today?\n",
      "Instruction1: \n",
      "[2024-08-09 09:59:45,868] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:46,642] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:46,643] [oaieval.py:215] \u001b[1;35mRun started: 240809075946BM5NBI5S\u001b[0m\n",
      "[2024-08-09 09:59:46,649] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:46,680] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:46,681] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:46,681] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:46,708] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "[2024-08-09 09:59:48,625] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:48,625] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 76\n",
      "prompt_tokens: 200\n",
      "total_tokens: 276\n",
      "[2024-08-09 09:59:48,626] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 76, 'usage_prompt_tokens': 200, 'usage_total_tokens': 276}. Logged to logs/logs\n",
      "[2024-08-09 09:59:48,626] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:48,626] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:48,626] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:48,626] [oaieval.py:235] usage_completion_tokens: 76\n",
      "[2024-08-09 09:59:48,626] [oaieval.py:235] usage_prompt_tokens: 200\n",
      "[2024-08-09 09:59:48,626] [oaieval.py:235] usage_total_tokens: 276\n",
      "[2024-08-09 09:59:48,630] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.212ms\n",
      "Response1: Hello! How can I assist you today?\n",
      "Instruction1: \n",
      "[2024-08-09 09:59:50,770] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:51,726] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:51,728] [oaieval.py:215] \u001b[1;35mRun started: 240809075951SJJEGLT7\u001b[0m\n",
      "[2024-08-09 09:59:51,732] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:51,768] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:51,769] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:51,769] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:51,795] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.07s/it]\n",
      "[2024-08-09 09:59:54,874] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 09:59:54,874] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 95\n",
      "prompt_tokens: 252\n",
      "total_tokens: 347\n",
      "[2024-08-09 09:59:54,875] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 95, 'usage_prompt_tokens': 252, 'usage_total_tokens': 347}. Logged to logs/logs\n",
      "[2024-08-09 09:59:54,875] [oaieval.py:233] Final report:\n",
      "[2024-08-09 09:59:54,875] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 09:59:54,875] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 09:59:54,875] [oaieval.py:235] usage_completion_tokens: 95\n",
      "[2024-08-09 09:59:54,875] [oaieval.py:235] usage_prompt_tokens: 252\n",
      "[2024-08-09 09:59:54,876] [oaieval.py:235] usage_total_tokens: 347\n",
      "[2024-08-09 09:59:54,879] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.873ms\n",
      "Response1: Hello! How can I assist you today?\n",
      "Instruction1: Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\n",
      "[2024-08-09 09:59:56,861] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 09:59:57,822] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 09:59:57,824] [oaieval.py:215] \u001b[1;35mRun started: 240809075957P43MQRJQ\u001b[0m\n",
      "[2024-08-09 09:59:57,828] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 09:59:57,865] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 09:59:57,865] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 09:59:57,866] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 09:59:57,893] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "[2024-08-09 10:00:00,302] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:00:00,302] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 100\n",
      "prompt_tokens: 252\n",
      "total_tokens: 352\n",
      "[2024-08-09 10:00:00,303] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 100, 'usage_prompt_tokens': 252, 'usage_total_tokens': 352}. Logged to logs/logs\n",
      "[2024-08-09 10:00:00,303] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:00:00,303] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:00:00,303] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:00:00,303] [oaieval.py:235] usage_completion_tokens: 100\n",
      "[2024-08-09 10:00:00,303] [oaieval.py:235] usage_prompt_tokens: 252\n",
      "[2024-08-09 10:00:00,303] [oaieval.py:235] usage_total_tokens: 352\n",
      "[2024-08-09 10:00:00,306] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.847ms\n",
      "Response1: Hello! How can I assist you today?\n",
      "Instruction1: Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\n",
      "[2024-08-09 10:00:02,601] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:00:03,348] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:00:03,351] [oaieval.py:215] \u001b[1;35mRun started: 240809080003CBZUIM5F\u001b[0m\n",
      "[2024-08-09 10:00:03,354] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:00:03,386] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:00:03,386] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:00:03,387] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:00:03,400] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "[2024-08-09 10:00:05,521] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:00:05,522] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 81\n",
      "prompt_tokens: 254\n",
      "total_tokens: 335\n",
      "[2024-08-09 10:00:05,522] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 81, 'usage_prompt_tokens': 254, 'usage_total_tokens': 335}. Logged to logs/logs\n",
      "[2024-08-09 10:00:05,523] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:00:05,523] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:00:05,523] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:00:05,523] [oaieval.py:235] usage_completion_tokens: 81\n",
      "[2024-08-09 10:00:05,523] [oaieval.py:235] usage_prompt_tokens: 254\n",
      "[2024-08-09 10:00:05,523] [oaieval.py:235] usage_total_tokens: 335\n",
      "[2024-08-09 10:00:05,527] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.929ms\n",
      "Response1: Of course! I'd be happy to help. Please provide me with your order number and any specific details about your question so I can assist you further.\n",
      "Instruction1: I have a question about my recent order. Can you help me with that?\n",
      "[2024-08-09 10:00:07,522] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:00:08,224] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:00:08,226] [oaieval.py:215] \u001b[1;35mRun started: 240809080008X2K2NLW5\u001b[0m\n",
      "[2024-08-09 10:00:08,227] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:00:08,250] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:00:08,251] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:00:08,251] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:00:08,266] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.98s/it]\n",
      "[2024-08-09 10:00:11,255] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:00:11,255] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 113\n",
      "prompt_tokens: 262\n",
      "total_tokens: 375\n",
      "[2024-08-09 10:00:11,256] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 113, 'usage_prompt_tokens': 262, 'usage_total_tokens': 375}. Logged to logs/logs\n",
      "[2024-08-09 10:00:11,256] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:00:11,256] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:00:11,256] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:00:11,256] [oaieval.py:235] usage_completion_tokens: 113\n",
      "[2024-08-09 10:00:11,256] [oaieval.py:235] usage_prompt_tokens: 262\n",
      "[2024-08-09 10:00:11,256] [oaieval.py:235] usage_total_tokens: 375\n",
      "[2024-08-09 10:00:11,303] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=2.415ms\n",
      "Response1: Of course! I'd be happy to help you with any questions you have about your recent order. Please provide me with your order number or any relevant details so I can assist you more effectively.\n",
      "Instruction1: I have a question about my recent order. Can you help me with that?\n",
      "[2024-08-09 10:00:13,394] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:00:14,103] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:00:14,104] [oaieval.py:215] \u001b[1;35mRun started: 2408090800146JIVKNR7\u001b[0m\n",
      "[2024-08-09 10:00:14,106] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:00:14,134] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:00:14,135] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:00:14,135] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:00:14,150] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "[2024-08-09 10:00:17,098] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:00:17,098] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 152\n",
      "prompt_tokens: 354\n",
      "total_tokens: 506\n",
      "[2024-08-09 10:00:17,098] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 152, 'usage_prompt_tokens': 354, 'usage_total_tokens': 506}. Logged to logs/logs\n",
      "[2024-08-09 10:00:17,099] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:00:17,099] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:00:17,099] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:00:17,099] [oaieval.py:235] usage_completion_tokens: 152\n",
      "[2024-08-09 10:00:17,099] [oaieval.py:235] usage_prompt_tokens: 354\n",
      "[2024-08-09 10:00:17,099] [oaieval.py:235] usage_total_tokens: 506\n",
      "[2024-08-09 10:00:17,104] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=3.256ms\n",
      "Response1: Some possible topics I can help with include:\n",
      "\n",
      "1. Technology and gadgets\n",
      "2. Travel destinations and tips\n",
      "3. Health and wellness advice\n",
      "4. Book and movie recommendations\n",
      "5. Cooking and recipes\n",
      "6. Career and job search tips\n",
      "7. Relationship advice\n",
      "8. Fitness and exercise routines\n",
      "9. Financial planning and budgeting\n",
      "10. Self-improvement and personal development\n",
      "\n",
      "Feel free to ask me anything related to these topics or any other subject you're interested in!\n",
      "Instruction1: I can help with a variety of topics such as general information, recommendations, definitions, explanations, and more. Just let me know what you're curious about!\n",
      "[2024-08-09 10:00:19,291] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-09 10:00:20,053] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-09 10:00:20,055] [oaieval.py:215] \u001b[1;35mRun started: 240809080020V25SPRIT\u001b[0m\n",
      "[2024-08-09 10:00:20,056] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-09 10:00:20,080] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-09 10:00:20,080] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-09 10:00:20,080] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-09 10:00:20,091] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "[2024-08-09 10:00:22,212] [oaieval.py:275] Found 2/2 sampling events with usage data\n",
      "[2024-08-09 10:00:22,212] [oaieval.py:283] Token usage from 2 sampling events:\n",
      "completion_tokens: 79\n",
      "prompt_tokens: 266\n",
      "total_tokens: 345\n",
      "[2024-08-09 10:00:22,213] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 79, 'usage_prompt_tokens': 266, 'usage_total_tokens': 345}. Logged to logs/logs\n",
      "[2024-08-09 10:00:22,213] [oaieval.py:233] Final report:\n",
      "[2024-08-09 10:00:22,213] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-09 10:00:22,213] [oaieval.py:235] score: 0.0\n",
      "[2024-08-09 10:00:22,213] [oaieval.py:235] usage_completion_tokens: 79\n",
      "[2024-08-09 10:00:22,213] [oaieval.py:235] usage_prompt_tokens: 266\n",
      "[2024-08-09 10:00:22,213] [oaieval.py:235] usage_total_tokens: 345\n",
      "[2024-08-09 10:00:22,218] [record.py:360] Logged 3 rows of events to logs/logs: insert_time=1.721ms\n",
      "Response1: Feel free to ask me anything you're curious about!\n",
      "Instruction1: I can help with a variety of topics such as general information, recommendations, definitions, explanations, and more. Just let me know what you're curious about!\n",
      "starting level 0, generation distance 3\n",
      "finding parents Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\n",
      "finding children Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\n",
      "behind for loops\n",
      "endind level 0\n",
      "starting level 1, generation distance 3\n",
      "finding parents Hello! How can I assist you today?\n",
      "finding children Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\n",
      "finding children Hello! I'm here to help with any questions you have. What would you like to know?\n",
      "finding children Hello! I'm here to assist you with any questions or topics you'd like to discuss. Feel free to ask me anything!\n",
      "behind for loops\n",
      "endind level 1\n",
      "starting level 2, generation distance 3\n",
      "finding parents Hello! How can I assist you today?\n",
      "finding parents \n",
      "finding parents Hello! How can I assist you today?\n",
      "finding parents Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\n",
      "finding parents Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\n",
      "finding parents Hello! I'm here to help with any questions you have. What would you like to know?\n",
      "finding children Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\n",
      "finding children Hello! I'm here to help with any questions you have. What would you like to know?\n",
      "finding children Hello! I'm here to assist you with any questions or topics you'd like to discuss. Feel free to ask me anything!\n",
      "finding children I have a question about my recent order. Can you help me with that?\n",
      "finding children Hello! How can I assist you today?\n",
      "finding children I can help with a variety of topics such as general information, recommendations, definitions, explanations, and more. Just let me know what you're curious about!\n",
      "finding children Hello! How can I assist you today?\n",
      "behind for loops\n",
      "endind level 2\n",
      "all done, generation distance 4\n"
     ]
    }
   ],
   "source": [
    "for candidate_message in candidate_messages:\n",
    "    data = battle(best_message, best_response, candidate_message)\n",
    "    dataset = pd.concat([dataset, data],ignore_index=True)\n",
    "    dataset.to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "    if data[\"Choice\"].iloc[0] == \"Yes\":\n",
    "        best_message = candidate_message\n",
    "        best_response = data[\"Response1\"].iloc[0]\n",
    "        print(f\"New best message:{best_message}\")\n",
    "        if battles_generation == \"dense\":\n",
    "            generation_distance = 0\n",
    "    print(f\"Instruction1: {candidate_message[0][\"content\"]}\")\n",
    "\n",
    "    if battles_generation == \"only-new\":\n",
    "        new_message = [{\"role\": candidate_message[0][\"role\"], \"content\":data[\"Response1\"].iloc[0]}]\n",
    "        if new_message not in next_candidate_messages:\n",
    "            next_candidate_messages.append(new_message)\n",
    "            if roles == \"system-user\":\n",
    "                next_candidate_messages.append(switch_system_and_user(new_message))\n",
    "\n",
    "if battles_generation == \"only-new\":\n",
    "    candidate_messages = next_candidate_messages\n",
    "    next_candidate_messages = []\n",
    "if battles_generation == \"dense\":\n",
    "    #print(\"going to list candidate messages\")\n",
    "    candidate_messages = list_candidate_messages(dataset, best_message, generation_distance)\n",
    "    generation_distance += 1\n",
    "    #print(\"candidate messages listed\")\n",
    "print(f\"all done, generation distance {generation_distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instruction1</th>\n",
       "      <th>Response1</th>\n",
       "      <th>Instruction2</th>\n",
       "      <th>Response2</th>\n",
       "      <th>Sampled</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. Both responses are very similar in content ...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to help with any questions you...</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. Both responses acknowledge the purpose of b...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. Both responses are very similar in content ...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to help with any questions you...</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. Both responses acknowledge the purpose of h...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm here to help with any questions or ...</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. Both responses start with a friendly greeti...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. Both responses start with a friendly greeti...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>I have a question about my recent order. Can y...</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. Response 1 directly addresses the specific ...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. The first response in Instruction 1 is more...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Hello! I'm here to help with any questions you...</td>\n",
       "      <td>I can help with a variety of topics such as ge...</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. Response 1 provides a more detailed list of...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hello! I'm here to help with any questions you...</td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>Hello! I'm just here to chat and answer any qu...</td>\n",
       "      <td>Hello! I'm here to assist you with any questio...</td>\n",
       "      <td>1. Both responses start with a friendly greeti...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Instruction1  \\\n",
       "17  Hello! I'm just here to chat and answer any qu...   \n",
       "18  Hello! I'm just here to chat and answer any qu...   \n",
       "19  Hello! I'm just here to chat and answer any qu...   \n",
       "20  Hello! I'm just here to chat and answer any qu...   \n",
       "21                 Hello! How can I assist you today?   \n",
       "22                 Hello! How can I assist you today?   \n",
       "23  Hello! I'm here to assist you with any questio...   \n",
       "24  Hello! I'm here to assist you with any questio...   \n",
       "25  Hello! I'm here to help with any questions you...   \n",
       "26  Hello! I'm here to help with any questions you...   \n",
       "\n",
       "                                            Response1  \\\n",
       "17  Hello! I'm here to assist you with any questio...   \n",
       "18  Hello! I'm here to help with any questions you...   \n",
       "19  Hello! I'm here to assist you with any questio...   \n",
       "20  Hello! I'm here to help with any questions you...   \n",
       "21  Hello! I'm here to help with any questions or ...   \n",
       "22                 Hello! How can I assist you today?   \n",
       "23  I have a question about my recent order. Can y...   \n",
       "24                 Hello! How can I assist you today?   \n",
       "25  I can help with a variety of topics such as ge...   \n",
       "26                 Hello! How can I assist you today?   \n",
       "\n",
       "                                         Instruction2  \\\n",
       "17  Hello! I'm just here to chat and answer any qu...   \n",
       "18  Hello! I'm just here to chat and answer any qu...   \n",
       "19  Hello! I'm just here to chat and answer any qu...   \n",
       "20  Hello! I'm just here to chat and answer any qu...   \n",
       "21  Hello! I'm just here to chat and answer any qu...   \n",
       "22  Hello! I'm just here to chat and answer any qu...   \n",
       "23  Hello! I'm just here to chat and answer any qu...   \n",
       "24  Hello! I'm just here to chat and answer any qu...   \n",
       "25  Hello! I'm just here to chat and answer any qu...   \n",
       "26  Hello! I'm just here to chat and answer any qu...   \n",
       "\n",
       "                                            Response2  \\\n",
       "17  Hello! I'm here to assist you with any questio...   \n",
       "18  Hello! I'm here to assist you with any questio...   \n",
       "19  Hello! I'm here to assist you with any questio...   \n",
       "20  Hello! I'm here to assist you with any questio...   \n",
       "21  Hello! I'm here to assist you with any questio...   \n",
       "22  Hello! I'm here to assist you with any questio...   \n",
       "23  Hello! I'm here to assist you with any questio...   \n",
       "24  Hello! I'm here to assist you with any questio...   \n",
       "25  Hello! I'm here to assist you with any questio...   \n",
       "26  Hello! I'm here to assist you with any questio...   \n",
       "\n",
       "                                              Sampled Choice  \\\n",
       "17  1. Both responses are very similar in content ...     No   \n",
       "18  1. Both responses acknowledge the purpose of b...     No   \n",
       "19  1. Both responses are very similar in content ...     No   \n",
       "20  1. Both responses acknowledge the purpose of h...     No   \n",
       "21  1. Both responses start with a friendly greeti...     No   \n",
       "22  1. Both responses start with a friendly greeti...     No   \n",
       "23  1. Response 1 directly addresses the specific ...     No   \n",
       "24  1. The first response in Instruction 1 is more...     No   \n",
       "25  1. Response 1 provides a more detailed list of...     No   \n",
       "26  1. Both responses start with a friendly greeti...     No   \n",
       "\n",
       "                                                 Data  \n",
       "17  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "18  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "19  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "20  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "21  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "22  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "23  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "24  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "25  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  \n",
       "26  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instruction1</th>\n",
       "      <th>Response1</th>\n",
       "      <th>Instruction2</th>\n",
       "      <th>Response2</th>\n",
       "      <th>Sampled</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Instruction1                           Response1 Instruction2  \\\n",
       "0               Hello! How can I assist you today?                \n",
       "\n",
       "                            Response2  \\\n",
       "0  Hello! How can I assist you today?   \n",
       "\n",
       "                                             Sampled Choice  \\\n",
       "0  1. Both responses are identical in content and...     No   \n",
       "\n",
       "                                                Data  \n",
       "0  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset#.iloc[166:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(best_message[0][\"content\"], raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(best_response, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! I'm just here to chat and answer any questions you may have. How can I help you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! I'm just here to chat and answer any questions you may have. How can I help you today?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Response 1 directly addresses the user's potential questions or concerns, showing a proactive approach to assisting them.\n",
       "2. Response 2 does not directly address the user's potential questions or concerns, instead focusing on chatting and answering questions.\n",
       "\n",
       "Based on the direct approach and focus on addressing questions or concerns in Response 1, it is better than Response 2.\n",
       "\n",
       "Yes\n",
       "\n",
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "NaTType does not support strftime",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/jupyter_client/session.py:95\u001b[0m, in \u001b[0;36mjson_packer\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(\n\u001b[1;32m     96\u001b[0m         obj,\n\u001b[1;32m     97\u001b[0m         default\u001b[38;5;241m=\u001b[39mjson_default,\n\u001b[1;32m     98\u001b[0m         ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     99\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    100\u001b[0m     )\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Fallback to trying to clean the json before serializing\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    235\u001b[0m     skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    236\u001b[0m     check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    237\u001b[0m     separators\u001b[38;5;241m=\u001b[39mseparators, default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys,\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39mencode(obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/json/encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/json/encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _iterencode(o, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Out of range float values are not JSON compliant: nan",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[369], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m dataset[dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChoice\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     display_markdown(entry, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/display.py:145\u001b[0m, in \u001b[0;36mdisplay_markdown\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay_markdown\u001b[39m(\u001b[38;5;241m*\u001b[39mobjs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Displays the Markdown representation of an object.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m        Metadata to be associated with the specific mimetype output.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     _display_mimetype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext/markdown\u001b[39m\u001b[38;5;124m'\u001b[39m, objs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/display.py:86\u001b[0m, in \u001b[0;36m_display_mimetype\u001b[0;34m(mimetype, objs, raw, metadata)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# turn list of pngdata into list of { 'image/png': pngdata }\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     objs \u001b[38;5;241m=\u001b[39m [ {mimetype: obj} \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objs ]\n\u001b[0;32m---> 86\u001b[0m display_functions\u001b[38;5;241m.\u001b[39mdisplay(\u001b[38;5;241m*\u001b[39mobjs, raw\u001b[38;5;241m=\u001b[39mraw, metadata\u001b[38;5;241m=\u001b[39mmetadata, include\u001b[38;5;241m=\u001b[39m[mimetype])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/display_functions.py:296\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objs:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw:\n\u001b[0;32m--> 296\u001b[0m         publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m         format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m(obj, include\u001b[38;5;241m=\u001b[39minclude, exclude\u001b[38;5;241m=\u001b[39mexclude)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/display_functions.py:93\u001b[0m, in \u001b[0;36mpublish_display_data\u001b[0;34m(data, metadata, source, transient, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[1;32m     91\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transient\n\u001b[0;32m---> 93\u001b[0m display_pub\u001b[38;5;241m.\u001b[39mpublish(\n\u001b[1;32m     94\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m     95\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     97\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py:130\u001b[0m, in \u001b[0;36mZMQDisplayPublisher.publish\u001b[0;34m(self, data, metadata, transient, update)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# type:ignore[unreachable]\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_socket,\n\u001b[1;32m    132\u001b[0m     msg,\n\u001b[1;32m    133\u001b[0m     ident\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic,\n\u001b[1;32m    134\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/jupyter_client/session.py:852\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapt_version:\n\u001b[1;32m    851\u001b[0m     msg \u001b[38;5;241m=\u001b[39m adapt(msg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapt_version)\n\u001b[0;32m--> 852\u001b[0m to_send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserialize(msg, ident)\n\u001b[1;32m    853\u001b[0m to_send\u001b[38;5;241m.\u001b[39mextend(buffers)\n\u001b[1;32m    854\u001b[0m longest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m to_send])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/jupyter_client/session.py:721\u001b[0m, in \u001b[0;36mSession.serialize\u001b[0;34m(self, msg, ident)\u001b[0m\n\u001b[1;32m    719\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnone\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 721\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpack(content)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;66;03m# content is already packed, as in a relayed message\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/jupyter_client/session.py:104\u001b[0m, in \u001b[0;36mjson_packer\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(\n\u001b[1;32m     96\u001b[0m         obj,\n\u001b[1;32m     97\u001b[0m         default\u001b[38;5;241m=\u001b[39mjson_default,\n\u001b[1;32m     98\u001b[0m         ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     99\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    100\u001b[0m     )\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Fallback to trying to clean the json before serializing\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     packed \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(\n\u001b[0;32m--> 104\u001b[0m         json_clean(obj),\n\u001b[1;32m    105\u001b[0m         default\u001b[38;5;241m=\u001b[39mjson_default,\n\u001b[1;32m    106\u001b[0m         ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    108\u001b[0m     )\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage serialization failed with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupporting this message is deprecated in jupyter-client 7, please make \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msure your message is JSON-compliant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    114\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m packed\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/jupyter_client/jsonutil.py:185\u001b[0m, in \u001b[0;36mjson_clean\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    183\u001b[0m     out \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 185\u001b[0m         out[\u001b[38;5;28mstr\u001b[39m(k)] \u001b[38;5;241m=\u001b[39m json_clean(v)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, datetime):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/jupyter_client/jsonutil.py:185\u001b[0m, in \u001b[0;36mjson_clean\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    183\u001b[0m     out \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 185\u001b[0m         out[\u001b[38;5;28mstr\u001b[39m(k)] \u001b[38;5;241m=\u001b[39m json_clean(v)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, datetime):\n",
      "    \u001b[0;31m[... skipping similar frames: json_clean at line 185 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/jupyter_client/jsonutil.py:185\u001b[0m, in \u001b[0;36mjson_clean\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    183\u001b[0m     out \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 185\u001b[0m         out[\u001b[38;5;28mstr\u001b[39m(k)] \u001b[38;5;241m=\u001b[39m json_clean(v)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, datetime):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/jupyter_client/jsonutil.py:189\u001b[0m, in \u001b[0;36mjson_clean\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, datetime):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mstrftime(ISO8601)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# we don't understand it, it's probably an unserializable object\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt clean for JSON: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m obj)\n",
      "File \u001b[0;32mnattype.pyx:54\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.nattype._make_error_func.f\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: NaTType does not support strftime"
     ]
    }
   ],
   "source": [
    "for entry in dataset[dataset[\"Choice\"]==\"Yes\"].iloc[-1]:\n",
    "    display_markdown(entry, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instruction1</th>\n",
       "      <th>Response1</th>\n",
       "      <th>Instruction2</th>\n",
       "      <th>Response2</th>\n",
       "      <th>Sampled</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>1. Both responses are identical in content and...</td>\n",
       "      <td>No</td>\n",
       "      <td>{'spec': {0: {'completion_fns': ['gpt-3.5-turb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Instruction1                           Response1 Instruction2  \\\n",
       "0               Hello! How can I assist you today?                \n",
       "\n",
       "                            Response2  \\\n",
       "0  Hello! How can I assist you today?   \n",
       "\n",
       "                                             Sampled Choice  \\\n",
       "0  1. Both responses are identical in content and...     No   \n",
       "\n",
       "                                                Data  \n",
       "0  {'spec': {0: {'completion_fns': ['gpt-3.5-turb...  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user',\n",
       "   'content': \"Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\"}],\n",
       " [{'role': 'user', 'content': 'Hello! How can I assist you today?'}],\n",
       " [{'role': 'system', 'content': 'Hello! How can I assist you today?'}],\n",
       " [{'role': 'user',\n",
       "   'content': \"Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\"}],\n",
       " [{'role': 'user',\n",
       "   'content': \"Hello! I'm here to help with any questions you have. What would you like to know?\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"Hello! I'm here to help with any questions you have. What would you like to know?\"}],\n",
       " [{'role': 'user', 'content': ''}],\n",
       " [{'role': 'system', 'content': ''}],\n",
       " [{'role': 'user',\n",
       "   'content': \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\"}],\n",
       " [{'role': 'user',\n",
       "   'content': 'I have a question about my recent order. Can you help me with that?'}],\n",
       " [{'role': 'system',\n",
       "   'content': 'I have a question about my recent order. Can you help me with that?'}],\n",
       " [{'role': 'user',\n",
       "   'content': \"I can help with a variety of topics such as general information, recommendations, definitions, explanations, and more. Just let me know what you're curious about!\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"I can help with a variety of topics such as general information, recommendations, definitions, explanations, and more. Just let me know what you're curious about!\"}]]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fdbe172e46cfba2329a5e8d5b64cdf2d12f4dfd7d9bcea153ecef62d1d51933b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
