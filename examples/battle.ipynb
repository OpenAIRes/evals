{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a BATTLE Eval\n",
    "\n",
    "This notebook shows how to:\n",
    "- Build and run an eval\n",
    "- Load the results and into a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = True\n",
    "initial_message = [{\"role\": \"user\", \"content\": \"\"}]\n",
    "battles_generation = \"dense\"      # methods: dense, only-new\n",
    "roles = \"system-user\"             # methods: system-user, system, user\n",
    "\n",
    "#!cd evals\n",
    "#!git lfs fetch --all\n",
    "#!git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import yaml\n",
    "#import datetime\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "#api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "#client = OpenAI()\n",
    "\n",
    "# Install Evals if you haven't already\n",
    "# %pip install -e ../.\n",
    "# pip install --upgrade openai\n",
    "# %pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths. Assuming this notebook is in examples/\n",
    "\n",
    "evals_path = os.path.join(os.getcwd(), \"..\", \"evals\")\n",
    "\n",
    "registry_path = os.path.join(evals_path, \"registry\", \"evals\", \"battles.yaml\")\n",
    "\n",
    "data_path = os.path.join(evals_path, \"registry\", \"data\", \"battles\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "data_path = os.path.join(data_path, \"samples.jsonl\")\n",
    "\n",
    "json_logs_path = os.path.join(os.getcwd(), \"logs\")\n",
    "os.makedirs(json_logs_path, exist_ok=True)\n",
    "json_logs_path = os.path.join(json_logs_path, \"logs\")\n",
    "\n",
    "df_path = os.path.join(evals_path, \"evallogs\", \"df\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "dataset_path = os.path.join(df_path, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registry yaml\n",
    "\n",
    "registry_yaml = {}\n",
    "\n",
    "registry_yaml[\"battles\"] = {\n",
    "    \"id\": \"battles.test.v1\",\n",
    "    \"metrics\": [\"accuracy\"]\n",
    "}\n",
    "registry_yaml[\"battles.test.v1\"] = {\n",
    "    \"class\": \"evals.elsuite.modelgraded.classify:ModelBasedClassify\",\n",
    "    \"args\": {\n",
    "        \"samples_jsonl\": \"battles/samples.jsonl\",\n",
    "        \"eval_type\": \"cot_classify\",\n",
    "        \"modelgraded_spec\": \"battle\"\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(registry_path), \"w\") as f:\n",
    "    yaml.dump(registry_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial data\n",
    "if new:\n",
    "    dataset = []\n",
    "    best_message = initial_message\n",
    "else:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        dataset = pd.read_json(f, lines=True)\n",
    "    if dataset.iloc[-1][\"Choice\"] == \"No\":\n",
    "        best_message = dataset.iloc[-1][\"Response2\"]\n",
    "    else:\n",
    "        best_message = dataset.iloc[-1][\"Response1\"]\n",
    "candidate_messages = [best_message]\n",
    "next_candidate_messages = []\n",
    "generation_distance = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def battle(best_message, candidate_message):\n",
    "\n",
    "    dataset = [{\"input1\": candidate_message, \"input2\": best_message}]\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_json(data_path, orient=\"records\", lines=True)\n",
    "\n",
    "    !oaieval gpt-3.5-turbo battles --record_path logs/logs\n",
    "    \n",
    "    with open(json_logs_path, \"r\") as f:\n",
    "        df = pd.read_json(f, lines=True)\n",
    "\n",
    "    #current_time = datetime.datetime.now()\n",
    "    #formatted_time = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #df.to_json(os.path.join(df_path, formatted_time), lines=True, orient=\"records\")\n",
    "\n",
    "    instruction1 = candidate_message[0][\"content\"]\n",
    "    instruction2 = best_message[0][\"content\"]\n",
    "\n",
    "    battle_prompt_content = df[\"data\"].iloc[-2][\"prompt\"][0][\"content\"]\n",
    "    response1 = battle_prompt_content.split(\"\\n[Response 1]\\n\",)[1].split(\"\\n\\n[Instruction 2]\\n\")[0]\n",
    "    response1 = response1.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    response2 = battle_prompt_content.split(\"\\n[Response 2]\\n\",)[1].split(\"\\n\\n\\nIs the first response better than the second?\")[0]\n",
    "    response2 = response2.replace(\"\\\\'\", \"'\").replace(\"\\\\n\", \"\\n\")\n",
    "    #print(f\"response1: {response1}\")\n",
    "    #print(f\"response2: {response2}\")\n",
    "\n",
    "    sampled = df[\"data\"].iloc[-2][\"sampled\"][0]\n",
    "\n",
    "    choice = df[\"data\"].iloc[-1][\"choice\"]\n",
    "\n",
    "    data = {'Instruction1': instruction1, 'Response1': response1, 'Instruction2': instruction2, 'Response2': response2, 'Sampled': sampled, 'Choice': choice, 'Data': df.to_dict()}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_system_and_user(message):\n",
    "    new_message = []\n",
    "    if message[0][\"role\"] == \"system\":\n",
    "        new_message.append([{\"role\": \"user\", \"content\": message[0][\"content\"]}])\n",
    "    else:\n",
    "        new_message.append([{\"role\": \"system\", \"content\": message[0][\"content\"]}])\n",
    "    return new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parents(content, dataset):\n",
    "    print (f\"finding parents {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Response1\"] == content]\n",
    "    parents = dataset[\"Instruction1\"].unique()\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_children(content, dataset):\n",
    "    print (f\"finding children {content}\")\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset = dataset[dataset[\"Instruction1\"] == content]\n",
    "    children = dataset[\"Response1\"].unique()\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_candidate_messages(dataset, best_message, generation_distance):\n",
    "    best_content = best_message[0][\"content\"]\n",
    "    last_up = [best_content]\n",
    "    last_down = [best_content]\n",
    "    list_of_contents = [best_content]\n",
    "\n",
    "    next_up = []\n",
    "    next_down = []\n",
    "    for i in range(generation_distance):\n",
    "        #print (f\"starting level {i}, generation distance {generation_distance}\")\n",
    "        for content in last_up:\n",
    "            #print(f\"last_up: {last_up}, now {content}\")\n",
    "            next_up.extend(find_parents(content, dataset))\n",
    "        for content in last_down:\n",
    "            #print(f\"last_up: {last_down}, now {content}\")\n",
    "            next_down.extend(find_children(content, dataset))\n",
    "        #print (f\"behind for loops\")\n",
    "        list_of_contents.extend(next_up)\n",
    "        list_of_contents.extend(next_down)\n",
    "        last_up = next_up.copy()\n",
    "        last_down = next_down.copy()\n",
    "        #print(f\"endind level {i}\")\n",
    "        \n",
    "\n",
    "    list_of_contents = pd.array(list_of_contents).unique().tolist()\n",
    "    \n",
    "    #best_message_index = list_of_contents.index(best_message[0][content])\n",
    "    #start = max(best_message_index - generation_distance, 0)\n",
    "    #stop = min(len(list_of_contents))\n",
    "    #stop = len(list_of_contents) - 1\n",
    "\n",
    "    messages = []\n",
    "    for content in list_of_contents:\n",
    "        if roles == \"system-user\" or \"user\":\n",
    "            messages.append([{\"role\":\"user\",\"content\":content}])\n",
    "        if roles == \"system-user\" or \"system\":\n",
    "            messages.append([{\"role\":\"system\",\"content\":content}])\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding parents Hello! I'm here to help with any questions you have. What would you like to know?\n",
      "finding children Hello! I'm here to help with any questions you have. What would you like to know?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user',\n",
       "   'content': \"Hello! I'm here to help with any questions you have. What would you like to know?\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"Hello! I'm here to help with any questions you have. What would you like to know?\"}],\n",
       " [{'role': 'user',\n",
       "   'content': \"Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\"}],\n",
       " [{'role': 'user',\n",
       "   'content': \"Hello! I'm an AI digital assistant here to help you with any questions you may have. How can I assist you today?\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"Hello! I'm an AI digital assistant here to help you with any questions you may have. How can I assist you today?\"}],\n",
       " [{'role': 'user', 'content': 'Hello! How can I assist you today?'}],\n",
       " [{'role': 'system', 'content': 'Hello! How can I assist you today?'}]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_candidate_messages(dataset, best_message, generation_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-07 23:00:00,781] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:00:01,794] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:00:01,797] [oaieval.py:215] \u001b[1;35mRun started: 240807210001HVA63USL\u001b[0m\n",
      "[2024-08-07 23:00:01,800] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:00:01,870] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:00:01,871] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:00:01,871] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:00:01,906] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.70s/it]\n",
      "[2024-08-07 23:00:05,617] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:00:05,617] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 122\n",
      "prompt_tokens: 240\n",
      "total_tokens: 362\n",
      "[2024-08-07 23:00:05,618] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 122, 'usage_prompt_tokens': 240, 'usage_total_tokens': 362}. Logged to logs/logs\n",
      "[2024-08-07 23:00:05,618] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:00:05,619] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-07 23:00:05,619] [oaieval.py:235] score: 0.0\n",
      "[2024-08-07 23:00:05,619] [oaieval.py:235] usage_completion_tokens: 122\n",
      "[2024-08-07 23:00:05,619] [oaieval.py:235] usage_prompt_tokens: 240\n",
      "[2024-08-07 23:00:05,619] [oaieval.py:235] usage_total_tokens: 362\n",
      "[2024-08-07 23:00:05,622] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=2.003ms\n",
      "[{'role': 'user', 'content': 'Hello! How can I assist you today?'}]\n",
      "[2024-08-07 23:00:07,803] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:00:08,720] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:00:08,721] [oaieval.py:215] \u001b[1;35mRun started: 240807210008KRJF3QD6\u001b[0m\n",
      "[2024-08-07 23:00:08,723] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:00:08,781] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:00:08,782] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:00:08,782] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:00:08,806] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]\n",
      "[2024-08-07 23:00:11,762] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:00:11,762] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 96\n",
      "prompt_tokens: 222\n",
      "total_tokens: 318\n",
      "[2024-08-07 23:00:11,766] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 96, 'usage_prompt_tokens': 222, 'usage_total_tokens': 318}. Logged to logs/logs\n",
      "[2024-08-07 23:00:11,766] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:00:11,767] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-07 23:00:11,767] [oaieval.py:235] score: 0.0\n",
      "[2024-08-07 23:00:11,767] [oaieval.py:235] usage_completion_tokens: 96\n",
      "[2024-08-07 23:00:11,767] [oaieval.py:235] usage_prompt_tokens: 222\n",
      "[2024-08-07 23:00:11,767] [oaieval.py:235] usage_total_tokens: 318\n",
      "[2024-08-07 23:00:11,772] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=2.190ms\n",
      "[{'role': 'system', 'content': 'Hello! How can I assist you today?'}]\n",
      "[2024-08-07 23:00:15,372] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:00:16,944] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:00:16,946] [oaieval.py:215] \u001b[1;35mRun started: 240807210016K52TU3PU\u001b[0m\n",
      "[2024-08-07 23:00:16,951] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:00:17,079] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:00:17,080] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:00:17,081] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:00:17,163] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "[2024-08-07 23:00:20,692] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:00:20,692] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 118\n",
      "prompt_tokens: 204\n",
      "total_tokens: 322\n",
      "[2024-08-07 23:00:20,693] [record.py:371] Final report: {'counts/Yes': 1, 'score': 1.0, 'usage_completion_tokens': 118, 'usage_prompt_tokens': 204, 'usage_total_tokens': 322}. Logged to logs/logs\n",
      "[2024-08-07 23:00:20,693] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:00:20,693] [oaieval.py:235] counts/Yes: 1\n",
      "[2024-08-07 23:00:20,693] [oaieval.py:235] score: 1.0\n",
      "[2024-08-07 23:00:20,693] [oaieval.py:235] usage_completion_tokens: 118\n",
      "[2024-08-07 23:00:20,693] [oaieval.py:235] usage_prompt_tokens: 204\n",
      "[2024-08-07 23:00:20,693] [oaieval.py:235] usage_total_tokens: 322\n",
      "[2024-08-07 23:00:20,703] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=6.849ms\n",
      "[{'role': 'user', 'content': ''}]\n",
      "[2024-08-07 23:00:23,410] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:00:24,330] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:00:24,333] [oaieval.py:215] \u001b[1;35mRun started: 240807210024D2GK2DA6\u001b[0m\n",
      "[2024-08-07 23:00:24,335] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:00:24,398] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:00:24,399] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:00:24,399] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:00:24,417] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "[2024-08-07 23:00:26,962] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:00:26,962] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 69\n",
      "prompt_tokens: 169\n",
      "total_tokens: 238\n",
      "[2024-08-07 23:00:26,962] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 69, 'usage_prompt_tokens': 169, 'usage_total_tokens': 238}. Logged to logs/logs\n",
      "[2024-08-07 23:00:26,963] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:00:26,963] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-07 23:00:26,963] [oaieval.py:235] score: 0.0\n",
      "[2024-08-07 23:00:26,963] [oaieval.py:235] usage_completion_tokens: 69\n",
      "[2024-08-07 23:00:26,963] [oaieval.py:235] usage_prompt_tokens: 169\n",
      "[2024-08-07 23:00:26,963] [oaieval.py:235] usage_total_tokens: 238\n",
      "[2024-08-07 23:00:26,966] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=1.931ms\n",
      "[{'role': 'system', 'content': ''}]\n",
      "[2024-08-07 23:00:29,172] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:00:30,024] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:00:30,026] [oaieval.py:215] \u001b[1;35mRun started: 2408072100306LNJG6OE\u001b[0m\n",
      "[2024-08-07 23:00:30,027] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:00:30,053] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:00:30,054] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:00:30,054] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:00:30,070] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:06<00:00,  6.88s/it]\n",
      "[2024-08-07 23:00:36,952] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:00:36,953] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 108\n",
      "prompt_tokens: 221\n",
      "total_tokens: 329\n",
      "[2024-08-07 23:00:36,953] [record.py:371] Final report: {'counts/Yes': 1, 'score': 1.0, 'usage_completion_tokens': 108, 'usage_prompt_tokens': 221, 'usage_total_tokens': 329}. Logged to logs/logs\n",
      "[2024-08-07 23:00:36,953] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:00:36,953] [oaieval.py:235] counts/Yes: 1\n",
      "[2024-08-07 23:00:36,953] [oaieval.py:235] score: 1.0\n",
      "[2024-08-07 23:00:36,954] [oaieval.py:235] usage_completion_tokens: 108\n",
      "[2024-08-07 23:00:36,954] [oaieval.py:235] usage_prompt_tokens: 221\n",
      "[2024-08-07 23:00:36,954] [oaieval.py:235] usage_total_tokens: 329\n",
      "[2024-08-07 23:00:36,957] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=2.082ms\n",
      "[{'role': 'user', 'content': \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\"}]\n",
      "[2024-08-07 23:00:39,374] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:00:40,219] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:00:40,221] [oaieval.py:215] \u001b[1;35mRun started: 240807210040XRP3XHRD\u001b[0m\n",
      "[2024-08-07 23:00:40,223] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:00:40,270] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:00:40,270] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:00:40,271] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:00:40,293] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|████████████████████████████████████████████| 1/1 [01:44<00:00, 104.56s/it]\n",
      "[2024-08-07 23:02:24,867] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:02:24,867] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 105\n",
      "prompt_tokens: 273\n",
      "total_tokens: 378\n",
      "[2024-08-07 23:02:24,869] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 105, 'usage_prompt_tokens': 273, 'usage_total_tokens': 378}. Logged to logs/logs\n",
      "[2024-08-07 23:02:24,869] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:02:24,869] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-07 23:02:24,869] [oaieval.py:235] score: 0.0\n",
      "[2024-08-07 23:02:24,869] [oaieval.py:235] usage_completion_tokens: 105\n",
      "[2024-08-07 23:02:24,869] [oaieval.py:235] usage_prompt_tokens: 273\n",
      "[2024-08-07 23:02:24,869] [oaieval.py:235] usage_total_tokens: 378\n",
      "[2024-08-07 23:02:24,875] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=2.577ms\n",
      "[{'role': 'system', 'content': \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\"}]\n",
      "[2024-08-07 23:02:27,504] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:02:28,580] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:02:28,583] [oaieval.py:215] \u001b[1;35mRun started: 2408072102287UIUWK7B\u001b[0m\n",
      "[2024-08-07 23:02:28,586] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:02:28,633] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:02:28,633] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:02:28,634] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:02:28,671] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.11s/it]\n",
      "[2024-08-07 23:02:31,794] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:02:31,794] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 116\n",
      "prompt_tokens: 282\n",
      "total_tokens: 398\n",
      "[2024-08-07 23:02:31,795] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 116, 'usage_prompt_tokens': 282, 'usage_total_tokens': 398}. Logged to logs/logs\n",
      "[2024-08-07 23:02:31,796] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:02:31,796] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-07 23:02:31,796] [oaieval.py:235] score: 0.0\n",
      "[2024-08-07 23:02:31,796] [oaieval.py:235] usage_completion_tokens: 116\n",
      "[2024-08-07 23:02:31,796] [oaieval.py:235] usage_prompt_tokens: 282\n",
      "[2024-08-07 23:02:31,796] [oaieval.py:235] usage_total_tokens: 398\n",
      "[2024-08-07 23:02:31,800] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=2.282ms\n",
      "[{'role': 'user', 'content': \"Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\"}]\n",
      "[2024-08-07 23:02:34,127] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:02:35,145] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:02:35,147] [oaieval.py:215] \u001b[1;35mRun started: 240807210235MHYURN6S\u001b[0m\n",
      "[2024-08-07 23:02:35,149] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:02:35,185] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:02:35,185] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:02:35,186] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:02:35,215] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:04<00:00,  4.99s/it]\n",
      "[2024-08-07 23:02:40,213] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:02:40,214] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 117\n",
      "prompt_tokens: 278\n",
      "total_tokens: 395\n",
      "[2024-08-07 23:02:40,215] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 117, 'usage_prompt_tokens': 278, 'usage_total_tokens': 395}. Logged to logs/logs\n",
      "[2024-08-07 23:02:40,215] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:02:40,215] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-07 23:02:40,215] [oaieval.py:235] score: 0.0\n",
      "[2024-08-07 23:02:40,215] [oaieval.py:235] usage_completion_tokens: 117\n",
      "[2024-08-07 23:02:40,215] [oaieval.py:235] usage_prompt_tokens: 278\n",
      "[2024-08-07 23:02:40,215] [oaieval.py:235] usage_total_tokens: 395\n",
      "[2024-08-07 23:02:40,219] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=2.336ms\n",
      "[{'role': 'system', 'content': \"Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\"}]\n",
      "[2024-08-07 23:02:42,368] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:02:43,419] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:02:43,422] [oaieval.py:215] \u001b[1;35mRun started: 2408072102435BCFNZLL\u001b[0m\n",
      "[2024-08-07 23:02:43,429] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:02:43,479] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:02:43,480] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:02:43,480] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:02:43,506] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "[2024-08-07 23:02:46,678] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:02:46,678] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 105\n",
      "prompt_tokens: 276\n",
      "total_tokens: 381\n",
      "[2024-08-07 23:02:46,679] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 105, 'usage_prompt_tokens': 276, 'usage_total_tokens': 381}. Logged to logs/logs\n",
      "[2024-08-07 23:02:46,679] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:02:46,679] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-07 23:02:46,679] [oaieval.py:235] score: 0.0\n",
      "[2024-08-07 23:02:46,679] [oaieval.py:235] usage_completion_tokens: 105\n",
      "[2024-08-07 23:02:46,679] [oaieval.py:235] usage_prompt_tokens: 276\n",
      "[2024-08-07 23:02:46,679] [oaieval.py:235] usage_total_tokens: 381\n",
      "[2024-08-07 23:02:46,684] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=2.464ms\n",
      "[{'role': 'user', 'content': \"Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\"}]\n",
      "[2024-08-07 23:02:48,787] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:02:49,829] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:02:49,834] [oaieval.py:215] \u001b[1;35mRun started: 240807210249PYBVHN62\u001b[0m\n",
      "[2024-08-07 23:02:49,836] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:02:49,884] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:02:49,885] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:02:49,885] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:02:49,903] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "[2024-08-07 23:02:53,216] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:02:53,216] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 124\n",
      "prompt_tokens: 269\n",
      "total_tokens: 393\n",
      "[2024-08-07 23:02:53,217] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 124, 'usage_prompt_tokens': 269, 'usage_total_tokens': 393}. Logged to logs/logs\n",
      "[2024-08-07 23:02:53,217] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:02:53,217] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-07 23:02:53,217] [oaieval.py:235] score: 0.0\n",
      "[2024-08-07 23:02:53,217] [oaieval.py:235] usage_completion_tokens: 124\n",
      "[2024-08-07 23:02:53,217] [oaieval.py:235] usage_prompt_tokens: 269\n",
      "[2024-08-07 23:02:53,217] [oaieval.py:235] usage_total_tokens: 393\n",
      "[2024-08-07 23:02:53,222] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=2.597ms\n",
      "[{'role': 'system', 'content': \"Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\"}]\n",
      "[2024-08-07 23:02:55,402] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:02:56,226] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:02:56,228] [oaieval.py:215] \u001b[1;35mRun started: 240807210256XWNMRPTR\u001b[0m\n",
      "[2024-08-07 23:02:56,231] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:02:56,257] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:02:56,257] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:02:56,258] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:02:56,289] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:04<00:00,  4.91s/it]\n",
      "[2024-08-07 23:03:01,202] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:03:01,203] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 141\n",
      "prompt_tokens: 278\n",
      "total_tokens: 419\n",
      "[2024-08-07 23:03:01,203] [record.py:371] Final report: {'counts/Yes': 1, 'score': 1.0, 'usage_completion_tokens': 141, 'usage_prompt_tokens': 278, 'usage_total_tokens': 419}. Logged to logs/logs\n",
      "[2024-08-07 23:03:01,204] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:03:01,204] [oaieval.py:235] counts/Yes: 1\n",
      "[2024-08-07 23:03:01,204] [oaieval.py:235] score: 1.0\n",
      "[2024-08-07 23:03:01,204] [oaieval.py:235] usage_completion_tokens: 141\n",
      "[2024-08-07 23:03:01,204] [oaieval.py:235] usage_prompt_tokens: 278\n",
      "[2024-08-07 23:03:01,204] [oaieval.py:235] usage_total_tokens: 419\n",
      "[2024-08-07 23:03:01,207] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=1.893ms\n",
      "[{'role': 'user', 'content': \"Hello! I'm here to help with any questions you have. What would you like to know?\"}]\n",
      "[2024-08-07 23:03:03,571] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/evals\n",
      "[2024-08-07 23:03:04,563] [registry.py:271] Loading registry from /Users/janvotava/.evals/evals\n",
      "[2024-08-07 23:03:04,568] [oaieval.py:215] \u001b[1;35mRun started: 2408072103043UG552LP\u001b[0m\n",
      "[2024-08-07 23:03:04,570] [registry.py:271] Loading registry from /Users/janvotava/Desktop/evals/evals/registry/modelgraded\n",
      "[2024-08-07 23:03:04,608] [registry.py:271] Loading registry from /Users/janvotava/.evals/modelgraded\n",
      "[2024-08-07 23:03:04,608] [data.py:94] Fetching /Users/janvotava/Desktop/evals/evals/registry/data/battles/samples.jsonl\n",
      "[2024-08-07 23:03:04,609] [eval.py:36] Evaluating 1 samples\n",
      "[2024-08-07 23:03:04,630] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "[2024-08-07 23:03:07,957] [oaieval.py:275] Found 3/3 sampling events with usage data\n",
      "[2024-08-07 23:03:07,958] [oaieval.py:283] Token usage from 3 sampling events:\n",
      "completion_tokens: 118\n",
      "prompt_tokens: 272\n",
      "total_tokens: 390\n",
      "[2024-08-07 23:03:07,959] [record.py:371] Final report: {'counts/No': 1, 'score': 0.0, 'usage_completion_tokens': 118, 'usage_prompt_tokens': 272, 'usage_total_tokens': 390}. Logged to logs/logs\n",
      "[2024-08-07 23:03:07,959] [oaieval.py:233] Final report:\n",
      "[2024-08-07 23:03:07,959] [oaieval.py:235] counts/No: 1\n",
      "[2024-08-07 23:03:07,959] [oaieval.py:235] score: 0.0\n",
      "[2024-08-07 23:03:07,959] [oaieval.py:235] usage_completion_tokens: 118\n",
      "[2024-08-07 23:03:07,959] [oaieval.py:235] usage_prompt_tokens: 272\n",
      "[2024-08-07 23:03:07,959] [oaieval.py:235] usage_total_tokens: 390\n",
      "[2024-08-07 23:03:07,963] [record.py:360] Logged 4 rows of events to logs/logs: insert_time=1.910ms\n",
      "[{'role': 'system', 'content': \"Hello! I'm here to help with any questions you have. What would you like to know?\"}]\n",
      "going to list candidate messages\n",
      "candidate messages listed\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "for candidate_message in candidate_messages:\n",
    "    data = battle(best_message, candidate_message)\n",
    "    dataset.append(data)\n",
    "    pd.DataFrame(dataset).to_json(os.path.join(df_path, \"dataset\"), lines=True, orient=\"records\")\n",
    "    if data[\"Choice\"] == \"Yes\":\n",
    "        best_message = candidate_message\n",
    "        if battles_generation == \"dense\":\n",
    "            generation_distance = 0\n",
    "    print(candidate_message)\n",
    "\n",
    "    if battles_generation == \"only-new\":\n",
    "        new_message = [{\"role\": candidate_message[0][\"role\"], \"content\":data[\"Response1\"]}]\n",
    "        if new_message not in next_candidate_messages:\n",
    "            next_candidate_messages.append(new_message)\n",
    "            if roles == \"system-user\":\n",
    "                next_candidate_messages.append(switch_system_and_user(new_message))\n",
    "\n",
    "if battles_generation == \"only-new\":\n",
    "    candidate_messages = next_candidate_messages\n",
    "    next_candidate_messages = []\n",
    "if battles_generation == \"dense\":\n",
    "    print(\"going to list candidate messages\")\n",
    "    candidate_messages = list_candidate_messages(dataset, best_message, generation_distance)\n",
    "    generation_distance += 1\n",
    "    print(\"candidate messages listed\")\n",
    "print(\"all done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user',\n",
       "   'content': \"Hello! I'm here to help with any questions you have. What would you like to know?\"}],\n",
       " [{'role': 'system',\n",
       "   'content': \"Hello! I'm here to help with any questions you have. What would you like to know?\"}]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"Hello! I'm here to help with any questions you have. What would you like to know?\"}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " \"Hello! I'm just here to chat and answer any questions you may have. How can I help you today?\",\n",
       " 'Hello! How can I assist you today?',\n",
       " \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\",\n",
       " 'Hello! How can I assist you today?',\n",
       " \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\",\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " \"Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\",\n",
       " \"Hello! I'm here to help with any questions you have. What would you like to know?\",\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you today.\",\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " \"Hello! I'm here to assist you with any questions or concerns you may have. How can I help you today?\",\n",
       " \"Hello! I'm here to help with any questions you have. What would you like to know?\",\n",
       " 'I have a question about my recent order. Can you help me with that?',\n",
       " 'Hello! How can I assist you today?',\n",
       " \"Hello! I'm an AI digital assistant here to help you with any questions you may have. How can I assist you today?\",\n",
       " 'Hello! How can I assist you today?']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset)[\"Response1\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\",\n",
       " 'Hello! How can I assist you today?',\n",
       " 'Hello! How can I assist you today?',\n",
       " \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\",\n",
       " '1. Both responses start with a friendly greeting, which is good.\\n2. Response 1 directly asks how the speaker can assist, which is clear and to the point.\\n3. Response 2 first states that the speaker is there to help, then asks how they can assist, which may be slightly redundant.\\n\\nNo\\n\\nNo',\n",
       " 'No',\n",
       " {'spec': {0: {'completion_fns': ['gpt-3.5-turbo'],\n",
       "    'eval_name': 'battles.test.v1',\n",
       "    'base_eval': 'battles',\n",
       "    'split': 'test',\n",
       "    'run_config': {'completion_fns': ['gpt-3.5-turbo'],\n",
       "     'eval_spec': {'cls': 'evals.elsuite.modelgraded.classify:ModelBasedClassify',\n",
       "      'registry_path': '/Users/janvotava/Desktop/evals/evals/registry',\n",
       "      'args': {'eval_type': 'cot_classify',\n",
       "       'modelgraded_spec': 'battle',\n",
       "       'samples_jsonl': 'battles/samples.jsonl'},\n",
       "      'key': 'battles.test.v1',\n",
       "      'group': 'battles'},\n",
       "     'seed': 20220722,\n",
       "     'max_samples': None,\n",
       "     'command': '/opt/anaconda3/bin/oaieval gpt-3.5-turbo battles --record_path logs/logs',\n",
       "     'initial_settings': {'visible': True}},\n",
       "    'created_by': '',\n",
       "    'run_id': '240807205834OAOIVXUB',\n",
       "    'created_at': '2024-08-07 20:58:34.433947'},\n",
       "   1: nan,\n",
       "   2: nan,\n",
       "   3: nan,\n",
       "   4: nan,\n",
       "   5: nan},\n",
       "  'final_report': {0: nan,\n",
       "   1: {'counts/No': 1,\n",
       "    'score': 0.0,\n",
       "    'usage_completion_tokens': 101,\n",
       "    'usage_prompt_tokens': 256,\n",
       "    'usage_total_tokens': 357},\n",
       "   2: nan,\n",
       "   3: nan,\n",
       "   4: nan,\n",
       "   5: nan},\n",
       "  'run_id': {0: nan,\n",
       "   1: '240807205834OAOIVXUB',\n",
       "   2: '240807205834OAOIVXUB',\n",
       "   3: '240807205834OAOIVXUB',\n",
       "   4: '240807205834OAOIVXUB',\n",
       "   5: '240807205834OAOIVXUB'},\n",
       "  'event_id': {0: nan, 1: nan, 2: 0.0, 3: 1.0, 4: 2.0, 5: 3.0},\n",
       "  'sample_id': {0: nan,\n",
       "   1: nan,\n",
       "   2: 'battles.test.0',\n",
       "   3: 'battles.test.0',\n",
       "   4: 'battles.test.0',\n",
       "   5: 'battles.test.0'},\n",
       "  'type': {0: nan,\n",
       "   1: nan,\n",
       "   2: 'sampling',\n",
       "   3: 'sampling',\n",
       "   4: 'sampling',\n",
       "   5: 'metrics'},\n",
       "  'data': {0: nan,\n",
       "   1: nan,\n",
       "   2: {'prompt': [{'role': 'system',\n",
       "      'content': \"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\"}],\n",
       "    'sampled': ['Hello! How can I assist you today?'],\n",
       "    'model': 'gpt-3.5-turbo-0125',\n",
       "    'usage': {'completion_tokens': 9,\n",
       "     'prompt_tokens': 33,\n",
       "     'total_tokens': 42}},\n",
       "   3: {'prompt': [{'role': 'user',\n",
       "      'content': 'Hello! How can I assist you today?'}],\n",
       "    'sampled': [\"Hello! I'm here to help with any questions or tasks you may have. Just let me know how I can assist you.\"],\n",
       "    'model': 'gpt-3.5-turbo-0125',\n",
       "    'usage': {'completion_tokens': 26,\n",
       "     'prompt_tokens': 16,\n",
       "     'total_tokens': 42}},\n",
       "   4: {'prompt': [{'role': 'user',\n",
       "      'content': 'You are comparing two responses to the following two instructions.\\n\\n[Instruction 1]\\nHello! I\\'m here to help with any questions or tasks you may have. Just let me know how I can assist you.\\n[Response 1]\\nHello! How can I assist you today?\\n\\n[Instruction 2]\\nHello! How can I assist you today?\\n[Response 2]\\nHello! I\\'m here to help with any questions or tasks you may have. Just let me know how I can assist you.\\n\\n\\nIs the first response better than the second? You must provide one answer based on your subjective view.\\n\\nFirst, write out in a step by step manner your reasoning to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset. Then print only a single choice from \"Yes\" or \"No\" (without quotes or punctuation) on its own line corresponding to the correct answer. At the end, repeat just the answer by itself on a new line.\\n\\nReasoning:'}],\n",
       "    'sampled': ['1. Both responses start with a friendly greeting, which is good.\\n2. Response 1 directly asks how the speaker can assist, which is clear and to the point.\\n3. Response 2 first states that the speaker is there to help, then asks how they can assist, which may be slightly redundant.\\n\\nNo\\n\\nNo'],\n",
       "    'model': 'gpt-3.5-turbo-0125',\n",
       "    'usage': {'completion_tokens': 66,\n",
       "     'prompt_tokens': 207,\n",
       "     'total_tokens': 273}},\n",
       "   5: {'choice': 'No', 'score': 0.0}},\n",
       "  'created_by': {0: nan, 1: nan, 2: '', 3: '', 4: '', 5: ''},\n",
       "  'created_at': {0: NaT,\n",
       "   1: NaT,\n",
       "   2: Timestamp('2024-08-07 20:58:35.304198+0000', tz='UTC'),\n",
       "   3: Timestamp('2024-08-07 20:58:36.220818+0000', tz='UTC'),\n",
       "   4: Timestamp('2024-08-07 20:58:37.552572+0000', tz='UTC'),\n",
       "   5: Timestamp('2024-08-07 20:58:37.552659+0000', tz='UTC')}}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset).loc[16].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion = client.chat.completions.create(\n",
    "    #messages = [{\"role\":\"system\", \"content\":\"Hello! How can I assist you today?\"}],\n",
    "    #model = \"gpt-3.5-turbo\",\n",
    "    #temperature = 0,\n",
    "    #seed = 20220722\n",
    "#)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fdbe172e46cfba2329a5e8d5b64cdf2d12f4dfd7d9bcea153ecef62d1d51933b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
